Matching graphs with unique node labels A special class of graphs is introduced in this paper. The graphs belonging to this class are characterised by the existence of unique node labels. A number of matching algorithms for graphs with unique node labels are developed. It is shown that problems such as graph isomorphism, subgraph isomorphism, maximum common subgraph (MCS) and graph edit distance (GED) have a computational complexity that is only quadratic in the number of nodes. Moreover, computing the median of a set of graphs is only linear in the cardinality of the set. In a series of experiments, it is demonstrated that the proposed algorithms run very fast in practice. The considered class makes the matching of large graphs, consisting of thousands of nodes, computationally tractable. We also discuss an application of the considered class of graphs and related matching algorithms to the classification and detection of abnormal events in computer networks. DRMR: Dynamic-ring-based multicast routing protocol for Ad hoc networks Recently a number of multicast routing protocols for ad hoc networks have been proposed, however, most of them do not provide proper tradeoffs between effectiveness, efficiency and scalability. In this paper, a novel multicast routing protocol is presented for ad hoc networks. The protocol, termed as dynamic-ring-based multicast routing protocol (DRMR), uses the concept of dynamic ring whose radius can be adjusted dynamically and DRMR configures this type of ring for all group member nodes. According to the principle of zone routing, two nodes whose rings overlap can create route to each other, thus, when the ring graph composed of all rings is connected, each member node has one or more routes to others. DRMR uses the method of expanding ring search (ERS) to maintain the connected ring graph, and also can decrease the radius of the ring to reduce the overhead. The performances of DRMR were simulated and evaluated with NS2, and results show that DRMR has a high data packet delivery ratio, low control overhead and good scalability. Authorization administration in a distributed multi-application environment To meet the authorization administration requirements in a distributed computer network environment, this paper extends the role-based access control model with multiple application dimensions and establishes a new access control model ED-RBAC(Extended Role Based Access Control Model) for the distributed environment. We propose an extendable hierarchical authorization assignment framework and design effective role-registering, role-applying and role-assigning protocol with symmetric and asymmetric cryptographic systems. The model can be used to simplify authorization administration in a distributed environment with multiple applications. Data Protection and Data Sharing in Telematics Automotive telematics may be defined as the information-intensive applications enabled for vehicles by a combination of telecommunications and computing technology. Telematics by its nature requires the capture, storage, and exchange of sensor data to obtain remote services. Such data likely include personal, sensitive information, which require proper handling to protect the driver's privacy. Some existing approaches focus on protecting privacy through anonymous interactions or by stopping information flow altogether. We complement these by concentrating instead on giving different stakeholders control over data sharing and use. In this paper, we identify several data protection challenges specifically related to the automotive telematics domain, and propose a general data protection framework to address some of those challenges. The framework enables data aggregation before data is released to service providers, which minimizes the disclosure of privacy sensitive information. We have implemented the core component, the privacy engine, to help users manage their privacy policies and to authorize data requests based on policy matching. The policy manager provides a flexible privacy policy model that allows data subjects to express rich constraint-based policies, including event-based, and spatio-temporal constraints. Thus, the policy engine can decide on a large number of requests without user assistance and causes no interruptions while driving. A performance study indicates that the overhead is stable with an increasing number of data subjects. Striping and scheduling for large scale multimedia servers When designing a multimedia server, several things must be decided: which scheduling scheme to adopt, how to allocate multimedia objects on storage devices, and the round length with which the streams will be serviced. Several problems in the designing of large-scale multimedia servers are addressed, with the following contributions: (1) a striping scheme is proposed that minimizes the number of seeks and hence maximizes the performance; (2) a simple and efficient mechanism is presented to find the optimal striping unit size as well as the optimal round length, which exploits both the characteristics of VBR streams and the situation of resources in the system; and (3) the characteristics and resource requirements of several scheduling schemes are investigated in order to obtain a clear indication as to which scheme shows the best performance in realtime multimedia servicing. Based on our analysis and experimental results, the CSCAN scheme outperforms the other schemes. It is believed that the results are of value in the design of effective large-scale multimedia servers. A novel framework for IP DiffServ over optical burst switching networks This paper presents a novel framework for IP Differentiated Services (DiffServ) over optical burst switching (OBS), namely, DS-OBS. The network architecture, functional model of edge nodes and core nodes, the control packet format, a novel burst assembly scheme at ingress nodes and scheduling algorithm of core nodes are presented. The basic idea is to apply DiffServ capable burst assembly at ingress nodes and perform different per hop behavior (PHB) electronic treatments for control packets of different QoS class services at core nodes. Simulation results show that the proposed schemes can provide the best differentiated service for expedited forwarding (EF), assured forwarding (AF) and best effort (BE) services in terms of end-to-end delay, throughput and IP packet loss probability. Semantic and structural analysis of TV diving programs Automatic content analysis of sports videos is a valuable and challenging task. Motivated by analogies between a class of sports videos and languages, the authors propose a novel approach for sports video analysis based on compiler principles. It integrates both semantic analysis and syntactic analysis to automatically create an index and a table of contents for a sports video. Each shot of the video sequence is first annotated and indexed with semantic labels through detection of events using domain knowledge. A grammar-based parser is then constructed to identify the tree structure of the video content based on the labels. Meanwhile, the grammar can be used to detect and recover errors during the analysis. As a case study, a sports video parsing system is presented in the particular domain of diving. Experimental results indicate the proposed approach is effective. Spatial and Temporal Variation of LURR and its Implication for the Tendency of Earthquake Occurrence in Southern California  — Based on the theory of LURR and its recent development, spatial and temporal variation of Y/Yc (value of LURR/critical value of LURR) in the Southern California region during the period from 1980 through March, 2001 was studied. According to the previous study on the fault system and stress field in Southern California, we zoned the Southern California region into 11 parts in each of which the stress field is almost uniform. With the time window of one year, time moving step of three months, space window of a circle region with a radius of 100 km and space moving step of 0.25 degree in latitude and longitude direction, the evolution of Y/Yc were snapshot. The scanning results show that obvious Y/Yc anomalies occurred before 5/6 of strong earthquakes considered with a magnitude of 6.5 or greater. The critical regions of Y/Yc are near the epicenters of the strong earthquakes and the Y/Yc anomalies occur months to years prior to the earthquakes. The tendency of earthquake occurrence in the California region is briefly discussed on the basis of the examination of Y/Yc. Distributed oblivious function evaluation and its applications This paper is about distributed oblivious function evaluation (DOFE). In this setting one party (Alice) has a functionf(x), and the other party (Bob) with an input α wants to learnf(α) in an oblivious way with the help of a set of servers. What Alice should do is to share her secret functionf(x) among the servers. Bob obtains what he should get by interacting with the servers. This paper proposes the model and security requirements for DOFE and analyzes three distributed oblivious polynomial evaluation protocols presented in the paper. Integrated differentiated survivability in IP over WDM networks The problem of differentiated Multi-Layer Integrated Survivability (MLIS) in IP over WDM networks is studied, which is decomposed into three sub-problems: survivable strategies design (SSD), spare capacity dimensioning (SCD), and dynamic survivable routing (DSR). A related work of network survivability in IP over WDM networks is firstly provided, and adaptive survivable strategies are also designed. A new Integrated Shared Pool (ISP) approach for SCD is then proposed, which is formulated by using integer-programming theory. Moreover, a novel survivable routing scheme called Differentiated Integrated Survivability Algorithm (DISA) for DSR is developed. Simulation results show that the proposed integrated survivability scheme performs much better than other solutions (e.g., “highest layer recovery” and “lowest layer recovery” schemes) in terms of traffic blocking ratio, spare resource requirement, and average traffic recovery ratio in IP over WDM networks. Load-Unload Response Ratio (LURR), Accelerating Moment/Energy Release (AM/ER) and State Vector Saltation as Precursors to Failure of Rock Specimens  — In order to verify some precursors such as LURR (Load/Unload Response Ratio) and AER (Accelerating Energy Release) before large earthquakes or macro-fracture in heterogeneous brittle media, four acoustic emission experiments involving large rock specimens under tri-axial stress, have been conducted. The specimens were loaded in two ways: monotonous or cycling. The experimental results confirm that LURR and AER are precursors of macro-fracture in brittle media. A new measure called the state vector has been proposed to describe the damage evolution of loaded rock specimens. New approach to WLAN security with synchronized pseudo random Wireless transmission is becoming increasing ubiquitous, but there is a big black hole in the security of this kind of network. Although IEEE 802.11 provides an optionalWired Equivalent Privacy (WEP), to implement the authentication and confidentiality, it leaves a lot of vulnerabilities and threats. This paper proposes a protocol called SPRNG for wireless data-link layer security. SPRNG is based on the sender and receiver who generate in a synchronized way a pseudo-random number sequence. In each transmission, the sender and receiver use a pair of random numbers, one for data frame authentication, and the other for encryption key. The random numbers are used as “one-time passwords” for sender authentication and as fresh encryption keys for each frame. SPRNG is designed to be compatible with the existing 802.11 products. Like WEP, the current 802.11 security protocol, SPRNG uses a symmetric key as its seed. SPRNG has already been simulated and tested in experiment, it shows that SPRNG has stronger security than WEP because it reveals little information for attackers. The key problem of SPRNG, synchronization loss problem, is also presented. Though motivated by wireless security, SPRNG is generic for many other applications, especially in the point to point communication. Memorizable interactive proof and zero-knowledge proof systems Interactive proof and zero-knowledge proof systems are two important concepts in cryptography and complexity theory. In the past two decades, a great number of interactive proof and zero-knowledge proof protocols have been designed and applied in practice. In this paper, a simple memorizable zero-knowledge protocol is proposed for graph non-isomorphism problem, based on the memorizable interactive proof system, which is extended from the original definition of interactive proof and is more applicable in reality. Energy-Aware Broadcast Trees in Wireless Networks In this paper we address the problem of broadcasting in wireless networks, so that the power consumed by any node is as small as possible. This approach is motivated by the fact that nodes in such networks often use batteries and, hence, it is important to conserve energy individually, so that they remain operational for a long time. We formulate the problem as a lexicographic node power optimization one. The problem is in general NP-complete. We provide an optimal algorithm which runs in polynomial time in certain cases. We also provide a heuristic algorithm whose performance relative to the optimal one is fairly satisfactory. We next show that these algorithms can also be used to solve the problem of broadcasting so that the residual energy of any node after the broadcast process is as large as possible. Finally, we discuss the issues of implementing the above algorithms distributively, as well as their multicast extensions. Semantic Web: A road to the knowledge infrastructure on the internet In this article, I describe the basic technologies for Semantic Web and relationship between Semantic Web and Knowledge Representation in Artificial Intelligence. Semantic Web is planned as an extension of the current web in order to help cooperation between computers and humans, i.e., computers and humans are expected to understand each other in the knowledge level. I first describe the vision of the Semantic Web, then introduce the current Semantic Web technologies, i.e., RDF, RDFS, and OWL. I describe relationship between the trend of Semantic Web and Knowledge Representation, and clarify challenges and difficulties of Semantic Web from the point of view of Knowledge Representation. Use of Computer-Mediated Communication in a Teaching Practicum Course 
This study investigates how Computer-Mediated Communication (CMC) can be effectively used in a teaching practicum course to enhance preservice teachers’ learning. We constructed a web-based CMC system and used it in a Teaching Practicum course. Computer science preservice teachers and experienced secondary school computer teachers, who served as mentors, participated in the study. The research findings indicate that the preservice teachers considered the CMC system helpful for supporting their learning. The findings also indicate that some initiating/follow-up discussion styles of the mentors were more effective than others in promoting interactions in the discussion forum. It was also found that a teaching-video-enhanced CMC environment is valuable in improving quality of mentoring and in increasing preservice teachers’ reflection on teaching.
 Service Discovery in Agent-Based Pervasive Computing Environments Directory based service discovery mechanisms are unsuitable for ad-hoc m-commerce environments. Working towards finding an alternate mechanism, we developed Allia: a peer-to-peer caching based and policy-driven agent-service discovery framework that facilitates cross-platform service discovery in ad-hoc environments. Our approach achieves a high degree of flexibility in adapting itself to changes in ad-hoc environments and is devoid of common problems associated with structured compound formation in mobile commerce environments. Device capabilities and limitations, user preferences regarding device usage, application specifics with respect to mobile commerce are factors that our framework adapts to. We have described our initial implementation of Allia over ThinkPads and iPAQs by extending the LEAP Agent Platform and using Bluetooth as the underlying network protocol. In addition, we evaluated Allia's performance by running simulations of our protocol in Glomosim simulator. We also compared our framework against a structured compound-based architecture. Effects of User Request Patterns on a Multimedia Delivery System Because of their size, service times, and drain on server resources, multimedia objects require specialized replication systems in order to meet demand and ensure content availability. We present a novel method for creating replication systems where the replicated objects' sizes and/or per-object service times are large. Such replication systems are well-suited to delivering multimedia objects on the Internet. Assuming that user request patterns to the system are known, we show how to create replication systems that distribute read load to servers in proportion to their contribution to system capacity and experimentally show the positive load distribution properties of such systems. However, when user request patterns differ from what the system was designed for, system performance will be affected. Therefore, we also report on results that reveal (i) how server loads are affected and (ii) the impact two system design parameters (indicators of a system's load distribution qualities) have on server load when request patterns differ from that for which a system was designed. Thresholds: Workflow Oriented Network Management: A Web/Java Approach  Project scheduling with irregular costs: complexity, approximability, and algorithms .We address a generalization of the classical discrete time-cost tradeoff problem where the costs are irregular and depend on the starting and the completion times of the activities. We present a complete picture of the computational complexity and the approximability of this problem for several natural classes of precedence constraints. We prove that the problem is NP-hard and hard to approximate, even in case the precedence constraints form an interval order. For precedence constraints with bounded height, there is a complexity jump from height one to height two: For height one, the problem is polynomially solvable, whereas for height two, it is NP-hard and APX-hard. Finally, the problem is shown to be polynomially solvable if the precedence constraints have bounded width or are series parallel. Privacy in (mobile) Telecommunications Services Telecommunications services are for long subject to privacy regulations. At stake are traditionally: privacy of the communication and the protection of traffic data. Privacy of the communication is legally founded. Traffic data subsume under the notion of data protection and are central in the discussion. The telecommunications environment is profoundly changing. The traditionally closed markets with closed networks change into an open market with open networks. Within these open networks more privacy sensitive data are generated and have to be exchanged between growing numbers of parties. Also telecommunications and computer networks are rapidly being integrated and thus the distinction between telephony and computing disappears. Traditional telecommunications privacy regulations are revised to cover internet applications. In this paper telecommunications issues are recalled to aid the on-going debate. Cellular mobile phones have recently be introduced. Cellular networks process a particular category of traffic data namely location data, thereby introducing the issue of territorial privacy into the telecommunications domain. Location data are bound to be used for pervasive future services. Designs for future services are discussed and evaluated for their impact on privacy protection. Definition and Performance Evaluation of Network Services Deployed Over a Differentiated Services Network A vital requirement for next generation IP networks is the provision of services with differentiated behavior and characteristics. The basic reason for that is the need to provide Quality of Service (QoS) to the different types of user traffic produced by applications that are different in nature and behavior, analogously to the IP network services. The Differentiated Services (DiffServ) paradigm is still one of the major outcomes of the research community toward the provision of QoS to individual customer needs and applications. This paper addresses the definition and deployment of specific network services in a DiffServ environment. We reuse and extend the fundamental concepts of the Expedited Forwarding and Assured Forwarding per hop behaviors in order to define four new network services, apart from the well known Best Effort one, which introduce a specific traffic handling implementation along with an Admission Control methodology. These are analyzed and simulated in the paper in order to evaluate their performance and confirm the correctness of their fundamental principles. The MAUI Toolkit: Groupware Widgets for Group Awareness Group awareness is an important part of synchronous collaboration, and support for group awareness can greatly improve groupware usability. However, it is still difficult to build groupware that supports group awareness. To address this problem, we have developed the Multi-User Awareness UI toolkit (MAUI) toolkit, a Java toolkit with a broad suite of awareness-enhanced UI components. The toolkit contains both extensions of standard Swing widgets, and groupware-specific components such as telepointers. All components have added functionality for collecting, distributing, and visualizing group awareness information. The toolkit packages components as JavaBeans, allowing wide code reuse, easy integration with IDEs, and drag-and-drop creation of working group-aware interfaces. The toolkit provides the first ever set of UI widgets that are truly collaboration-aware, and provides them in a way that greatly simplifies the construction and testing of rich groupware interfaces. Performance Evaluation of the Impact of QoS Mechanisms in an IPv6 Network for IPv6-Capable Real-Time Applications This paper describes a Quality of Service (QoS) service on an IPv6 domain that aims to service aggregates of real-time traffic with minimum delay, jitter, and packet loss. It contains results from the tests that were performed in order to configure and evaluate the QoS mechanisms. As an actual example of real-time traffic, we have used the OpenH323 project, an open source H.323 implementation that has been ported to IPv6. The QoS mechanisms in IPv6 networks is still a field that has not been researched adequately, and we therefore present the results from the experiments in our IPv6 network that took advantage of the QoS mechanisms. This QoS service uses the Modular QoS CLI (MQC) mechanism and especially the Low Latency Queue feature (LLQ) in order to treat packets from real-time applications. A Pragmatic Evaluation of the Theory of Information Ethics It has been argued that moral problems in relation to Information Technology (IT) require new theories of ethics. In recent years, an interesting new theory to address such concerns has been proposed, namely the theory of Information Ethics (IE). Despite the promise of IE, the theory has not enjoyed public discussion. The aim of this paper is to initiate such discussion by critically evaluating the theory of IE. A Generalized Analytical Framework for SMPT in a Multicode CDMA Wireless System Simultaneous MAC Packet Transmission (SMPT) has recently been proposed for stabilizing the throughput over wireless links, which is one of the key challenges in providing high-quality wireless multimedia services. SMPT stabilizes the wireless link by transmitting multiple packets on multiple CDMA channels in parallel in response to packet drops due to wireless link errors. These parallel packet transmissions stabilize the link layer throughput, but they also increase the interference level in a given cell of a cellular network or cluster of an ad-hoc network, which in turn reduces the number of traffic flows that can be simultaneously supported in a cell/cluster. We have recently developed an analytical framework for the class of SMPT mechanisms for a simple Bernoulli packet generation process, which does not reflect the oftentimes bursty packet generation processes encountered in real networks. In this paper we develop a generalized analytical framework for SMPT, which accommodates bursty packet traffic (and also non-bursty Bernoulli traffic). This framework expresses the system dynamics in transition probabilities for a Markov chain and calculates the effects of the interference through an iterative approach. The numerical results from our analytical framework and verifying simulations indicate that SMPT provides a significant reduction in packet loss and buffer occupancies (and delay), especially for persistent traffic bursts, in exchange for a reduced number of supported flows. Our analytical framework quantifies these system trade-offs with good accuracy and can thus be employed for resource management. Channel Sounding of Industrial Sites in the 2.4 GHz ISM band The results of channel soundings taken on a selection of six different industrial sites are presented. These results focus on the RMS delay spreads calculated from the channel soundings and the distribution of these results for each site. The distribution of RMS delay spread values is analysed and forms the basis of a statistical description of the multipath propagation on the tested sites. In particular the distribution is used to define the expected propagation delay across the site. The relation between the RMS delay spread and the irreducible-BER is discussed and this is used to link the distribution of RMS delay spread values to bit error rate performance on industrial sites. It is seen that the environment surrounding sites is significant. An Improvement of Response Speed for Electronic Commerce Systems Now that the number of electronic commerce (hereunder called e-commerce) users has been explosively increasing, the consequent heavy network traffic leads to the delayed service of the e-commerce systems. This paper focuses on operational efficiency and response speed of the e-commerce systems. An e-commerce system, with a hierarchical structure based on the local server, is designed. And we proposed a web object replacement algorithm with heterogeneity of a web object. The algorithm is designed with a divided scope that considered size reference characteristic and reduced size heterogeneity on web object. The performances of the system and algorithm are analyzed with an experiment. With the experiment results, the algorithm is compared with previous replacement algorithms, and we confirm with 10–20% performance improvement of object-hit ratio gain. And we get with 15–30% performance improvement of response speed with proposed system. A treatise on order in engineering design research Engineering design research shows a rather fragmented, if not a chaotic, picture. But does it have a hidden order? Can we explore it, or should we impose a reasoning model? This paper looks for the answer in the purpose of engineering design. It is destined to sustain human existence and well being by virtual creation of artifacts and services for the society. To this end, the engineering design discipline should provide a proper body of knowledge. The design knowledge obtained by empirical exploration and/or rational comprehension should be transformed for practical/pragmatic deployment. It was assumed that this purposely streaming of design knowledge gives a unique rationale for engineering design research. Based on this, a framework of reasoning was constructed, including source, channel, and sink categories of knowledge and research of engineering design, respectively. Within each category, research domains, trajectories, and approaches were identified. The semantic relationships of domains, trajectories, and approaches form a hierarchical structure. The proposed framework enables a grounded argumentation about the order of engineering design research, as well as about the articulation of the engineering design knowledge. Association of influenza epidemics with global climate variability The reasons for the seasonality and annual changes in the impact of influenza epidemics remain poorly understood. We investigated the covariations between a major component of climate, namely the El Niño Southern Oscillation (ENSO), and indicators of the impact of influenza, as measured by morbidity, excess mortality and viral subtypes collected in France during the period 1971–2002. We show that both the circulating subtype and the magnitude of ENSO are associated with the impact of influenza epidemics. Recognition of this association could lead to better understanding of the mechanisms of emergence of influenza epidemics. Security in the wild: user strategies for managing security as an everyday, practical problem Ubiquitous and mobile technologies create new challenges for system security. Effective security solutions depend not only on the mathematical and technical properties of those solutions, but also on people’s ability to understand them and use them as part of their work. As a step towards solving this problem, we have been examining how people experience security as a facet of their daily life, and how they routinely answer the question, “is this system secure enough for what I want to do?” We present a number of findings concerning the scope of security, attitudes towards security, and the social and organizational contexts within which security concerns arise, and point towards emerging technical solutions. Mass screening for colorectal cancer: compliance in Almopea Region Colorectal cancer (CRC) is the second leading cause of cancer-related morbidity and mortality in Europe and the United States. Planning for a CRC screening began in co-operation with local authorities (Pella Prefecture sponsored test kits). Our aims were to develop a screening programme for colorectal cancer using the faecal occult blood test (FOBT) in Almopea province, and to investigate the compliance of local farmers population. Cancer statistics data from Almopea have been analysed and they showed higher colorectal cancer incidence compared to the rest of Greece. We designed a one-time FOBT screening programme on the Surgery Department computer Network, in which we listed 8963 subjects, over 50 years of age. From them, 4189 underwent 3 days FOBT, and the rest were our control group. The method of successive visits to each community by the medical team and educational meeting was chosen. For allocation and gathering of tests, teams of volunteers have been organised. In case of positive FOBT (176 subjects), total colonoscopy was performed. Seventeen (17) polypoids (in 15 patients) and 20 cases of diverticulosis were detected. The compliance of FOBT group was 49% (from 4189). Colonoscopy accepted 89% from 176 patients with positive test. We concluded that our study shows poor compliance of screening population. There is a need for co-operation of medical services, local authorities, media and volunteers support organising. AIMD-based online MPLS traffic engineering for TCP flows via distributed multi-path routing With this paper, we propose a distributed online traffic engineering architecture formpls networks. In this architecture, a primary and secondarympls lsp are established from an ingresslsr to every other egresslsr. We propose to split thetcp traffic between the primary and secondary paths using a distributed mechanism based onecn marking andaimd-based rate control. Inspired by the random early detection mechanism for active queue management, we propose a random early reroute scheme to adaptively control the delay difference between the primary and secondarylsps. Considering the adverse effect of packet reordering ontcp performance for packet-based load balancing schemes, we propose that thetcp splitting mechanism operates on a per-flow basis. Using flow-based models developed for Internet traffic and simulations, we show that flow-based distributed multi-path traffic engineering outperforms on a consistent basis the case of a single path in terms of per-flow goodputs. Due to the elimination of out-of-order packet arrivals, flow-based splitting also enhancestcp performance with respect to packet-based splitting especially for longtcp flows that are hit hard by packet reordering. We also compare and contrast two queuing architectures for differential treatment of data packets routed over primary and secondarylsps in thempls data plane, namely first-in-first-out and strict priority queuing. We show through simulations that strict priority queuing is more effective and relatively more robust with respect to the changes in the traffic demand matrix than first-in-first-out queuing in the context of distributed multi-path routing.FésuméCet article présente une architecture distribuée d’ingénierie du trafic des réseauxmpls (multi-protocollabelswitching ou commutation multiprotocole par étiquettes). Dans cette architecture, on établit un chemin commuté par étiquette (lsp:labelswitchedpath) primaire et un secondaire d’un routeur-commutateur (lsr:labelswitchrouter) d’entrée à un routeur-commutateur de sortie. On propose de partager le trafictcp entre les chemins primaire et secondaire en utilisant un mécanisme basé sur un marquageecn (explicitcongestionnotification: annonce explicite de congestion) et une commande basée sur l’algorithmeaimd (additiveincreasemultiplicativedecrease: croissance linéaire, diminution exponentielle). En s’inspirant des mécanismes de rejet aléatoire précoce (random early discard) de la gestion de files d’attente, on propose un mécanisme de reroutage précoce pour commander de manière adaptative la différence de délai entre les chemins primaire et secondaire. En considérant l’effet du réordonnancement des paquets sur la performance detcp, on propose que le mécanisme de partage de trafic s’appuie sur les flux de communication. En utilisant des modèles à base de flux développés pour le trafic de l’internet et des simulations, on montre que l’ingénierie du trafic multichemin distribuée à partir des flux permet de meilleurs résultats qu’avec un seul chemin. Et puisqu’on élimine l’arrivée de paquets dans le désordre, cette séparation des trafics à partir des flux est encore meilleure dans le cas des gros fluxtcp. On compare également deux architectures de files d’attente pour le traitement des paquets de données routés sur les chemins primaire et secondaire: la politique premier-entré permierservi et la politique de respect de priorité. On montre à l’aide de simulations qu’une politique de strict respect de priorité est plus efficace et relativement plus robuste dans le contexte de routage multichemin distribué. An adaptive mechanism to guarantee the bandwidth fairness of TCP flows End-to-end TCP (transmission control protocol) congestion control can cause unfairness among multiple TCP connections with different RTT (Round Trip Time). The throughput of TCP connection is inversely proportional to its RTT. To resolve this problem, researchers have proposed many methods. The existing proposals for RTT-aware conditioner work well when congestion level is low. However, they over-protect long RTT flows and starve short RTT flows when congestion level is high. Due to this reason, an improved method based on adaptive thought is proposed. According to the congestion level of networks, the mechanism can adaptively adjust the degree of the protection to long RTT flows. Extensive simulation experiments showed that the proposed mechanism can guarantee the bandwidth fairness of TCP flows effectively and outperforms the existing methods. RTP-packets' loss recovery scheme based on layered buffer-routers This paper introduces an RTP-packets' loss recovery scheme in MPEG-4 playback type multicast application model, which is based on retransmission scheme. Through the auxiliary and coordinated buffer playing scheme of layered “buffer-routers”, the RTP-packets' loss recovery in limited time is made possible. We consider in the scheme to handle retransmission request with buffer waiting when network congestion occurs. Thus, neither the degree of congestion will be worsened nor the retransmission request will be lost when sending the request to higher-level buffer router. The RTP-packets' loss recovery scheme suggested by us is not only applied to MPEG-4 multicast application in LAN, but also can be extended to more spacious WAN (wide area network) when user groups comparatively centralize in certain number of local areas. Experimental Setup for Measuring P Asymmetry in the Resonance Region of Elastic Pion–Proton Scattering The SPIN-P experimental setup was designed for measuring the P asymmetry during pion scattering into the backward hemisphere at a minimum differential cross section of elastic πpscattering. The physical grounds of the experiment and the results of its simulation by the Monte Carlo method are presented. The setup is composed of a polarized proton target in a superconducting solenoid with vertical polarization of free protons, wire track detectors, scintillation counters, electronics for data readout and processing, and an appropriate computer network. The experimental program has been under way since 2002 on the pion beam of the proton synchrotron at the Institute of Theoretical and Experimental Physics (Moscow). Experimental research on critical point hypothesis According to the critical point hypothesis (CPH), energy release would accelerate in power law before occurrence of large earthquakes or failure of brittle materials. In the paper, CPH was studied by acoustic emission experiments of large-scale rock samples. Three kinds of rock samples were used in the experiments. The tri-axial loading condition was applied under different loading histories. The released elastic energy (Acoustic emission) was recorded with acoustic emission technique as microcracks emerged and developed inside the rock samples. The experimental results gave a further verification on the CPH. The elastic energy release of rock samples would accelerate before the failure even under different experimental conditions. Primary studies were also made on medium-term earthquake prediction by using accelerating energy release (AER) in the paper. Numerical methods for analysis of multiflow queuing systems with virtual partition of a common buffer A new approach is proposed to studying queuing systems with request-specific channels and a common finite buffer for requests of different types. For sharing the common buffer, a virtual partitioning strategy is used. Explicit formulas for blocking probabilities of different requests are derived and optimization problems are solved. The results of numerical experiments are presented. Heuristic Algorithms for Grooming of Arbitrary Traffic in WDM Ring Networks In a wavelength division multiplexing (WDM) network, sub-wavelength traffic streams can be elaborately arranged in wavelength channels to minimize the number of required electronic end systems, known as the traffic grooming problem. In this paper, a modified genetic algorithm without crossover operation is proposed to solve the problem using a permutation-based chromosome representation and using a selection strategy of reproducing the best chromosomes, thereby minimizing the number of electronic devices and requiring less wavelengths. Then, three methods are developed to improve the performance of the algorithm and a hill-climbing algorithm is proposed for the same purpose. Computer simulations were performed with plenty of randomly generated traffic patterns in unidirectional rings. The results show that these methods can improve the algorithm considerably. The relationships between the minimized network cost and the number of nodes are also presented. Optimizing IP networks in a hybrid IGP/MPLS environment In this paper, we consider a traffic engineering (te) approach toip networks in a hybridigp/mpls environment. Thoughigp (Interior Gateway Protocol) routing has proven its scalability and reliability, effective traffic engineering has been difficult to achieve in public IP networks because of the limited functional capabilities of conventionalip technologies.mpls (Multi-Protocol Label Switching) on the one hand enhances the possibility to engineer traffic onip networks by allowing explicit routes. But on the other hand it suffers from the scalability (n-square) problem. Hybridigp/mpls approaches rely onip native routing as much as possible and usempls only if necessary. In this work we propose a novel hybrid traffic engineering method based on genetic algorithms, which can be considered as an offlinete approach to handle long or medium-term traffic variations in the range days, weeks or months. In our approach the maximum number of hops anlsp (Label Switched Path) may take and the number oflsps which are applied solely to improve the routing performance, are treated as constraints due to delay considerations and the complexity of management. We apply our method to the German scientific network (b-win) for which a traffic matrix is available and also to some other networks with a simple demand model. We will show results comparing this hybridigp/mpls routing scenario with the result of pureigp routing and that of a full meshmpls with and without traffic splitting.RésuméDans cet article, nous considérons une approche ingénierie du trafic (traffic engineering,te) des réseauxip dans un environnement hybrideigp/mpls. Bien que le routageigp (Interior Gateway Protocol) ait prouvé son extensibilité (scalability) et sa fiabilité, l’ingénierie du trafic n’a pas été réalisée efficacement dans les réseauxip classiques à cause des capacités fonctionnelles limitées d’ip. mpls (Multi-Protocol Label Switching) améliore les possibilités de l’ingénierie du trafic dans les réseauxip en permettant l’utilisation de routes explicites; par contre il souffre du problème d’extensibilité (N2). Des approches hybridesigp/mpls se basent sur le routage traditionnel d’ip autant que possible en utilisantmpls seulement si nécessaire. Dans ce travail, nous proposons une nouvelle méthode d’ingénierie du trafic basée sur l’algorithme génétique. Elle peut être considérée comme une approche offline permettant de gérer les variations de trafic à long ou moyen terme. Dans notre approche, le nombre maximal de sauts qu’unlsp (Label Switched Path) peut prendre et le nombre delsp utilisés seulement pour améliorer la performance de routage, sont traités comme des contraintes à cause de la complexité de gestion et du délai engendré. Nous appliquons notre méthode au réseau scientifique allemand (b-win) pour lequel une matrice de trafic est disponible et également à quelques autres réseaux avec un modèle de simple demande. Nous montrerons les résultats en comparant le scénario du routage hybrideigp/mpls à celui du routageigp pur et à celui d’un réseau maillémpls avec ou sans séparation de flux. A Linear Algebraic Approach to Metering Schemes A metering scheme is a method by which an audit agency is able to measure the interaction between servers and clients during a certain number of time frames. Naor and Pinkas (Vol. 1403 of LNCS, pp. 576–590) proposed metering schemes where any server is able to compute a proof (i.e., a value to be shown to the audit agency at the end of each time frame), if and only if it has been visited by a number of clients larger than or equal to some threshold h during the time frame. Masucci and Stinson (Vol. 1895 of LNCS, pp. 72–87) showed how to construct a metering scheme realizing any access structure, where the access structure is the family of all subsets of clients which enable a server to compute its proof. They also provided lower bounds on the communication complexity of metering schemes. In this paper we describe a linear algebraic approach to design metering schemes realizing any access structure. Namely, given any access structure, we present a method to construct a metering scheme realizing it from any linear secret sharing scheme with the same access structure. Besides, we prove some properties about the relationship between metering schemes and secret sharing schemes. These properties provide some new bounds on the information distributed to clients and servers in a metering scheme. According to these bounds, the optimality of the metering schemes obtained by our method relies upon the optimality of the linear secret sharing schemes for the given access structure. Connected and Disconnected? On the Impact of Internet Use on Social Connectedness Based on Durkheim's idea that social differentiation in modern societies leads to division of labour and to increasing alienation between individuals some authors argue that the use of new technologies like the Internet will promote social isolation. Such a tendency towards a decline in Social Capital has been reported for the U.S. while citing decreasing numbers of membership in diverse organisations. The paper investigates similar tendencies for Switzerland and discusses the appropriateness of respective measures of social capital. A Manifesto for Agent Technology: Towards Next Generation Computing The European Commission's eEurope initiative aims to bring every citizen, home, school, business and administration online to create a digitally literate Europe. The value lies not in the objective itself, but in its ability to facilitate the advance of Europe into new ways of living and working. Just as in the first literacy revolution, our lives will change in ways never imagined. The vision of eEurope is underpinned by a technological infrastructure that is now taken for granted. Yet it provides us with the ability to pioneer radical new ways of doing business, of undertaking science, and, of managing our everyday activities. Key to this step change is the development of appropriate mechanisms to automate and improve existing tasks, to anticipate desired actions on our behalf (as human users) and to undertake them, while at the same time enabling us to stay involved and retain as much control as required. For many, these mechanisms are now being realised by agent technologies, which are already providing dramatic and sustained benefits in several business and industry domains, including B2B exchanges, supply chain management, car manufacturing, and so on. While there are many real successes of agent technologies to report, there is still much to be done in research and development for the full benefits to be achieved. This is especially true in the context of environments of pervasive computing devices that are envisaged in coming years. This paper describes the current state-of-the-art of agent technologies and identifies trends and challenges that will need to be addressed over the next 10 years to progress the field and realise the benefits. It offers a roadmap that is the result of discussions among participants from over 150 organisations including universities, research institutions, large multinational corporations and smaller IT start-up companies. The roadmap identifies successes and challenges, and points to future possibilities and demands; agent technologies are fundamental to the realisation of next generation computing. Kernel-based data compression for internet-based manufacturing monitoring Global manufacturing chains have become common in the 21st century. To perform remote monitoring and diagnosis in such chains, real-time data compression has become a core factor in the efficient and effective exchange of information via computer networks. This paper presents a new technique for compressing data using a kernel-based method. Overcoming the drawbacks of support vector techniques – that is, fast decompression but slow compression – the new method exhibits high speed in both phases. In addition, the new method can also be applied for pattern classification. Based on strain signal, example tests derived from sheet metal stamping operations, the new method is shown to be very effective. The proposed technology has enormous potential in the application of advanced manufacturing processes monitoring and control through Internet or Intranet.  Integrity of Total Graphs via Certain Parameters Communication networks have been characterized by high levels of service reliability. Links cuts, node interruptions, software errors or hardware failures, and transmission failures at various points can interrupt service for long periods of time. In communication networks, greater degrees of stability or less vulnerability is required. The vulnerability of communication network measures the resistance of the network to the disruption of operation after the failure of certain stations or communication links. If we think of a graph G as modeling a network, many graph-theoretic parameters can be used to describe the stability of communication networks, including connectivity, integrity, and tenacity. We consider two graphs with the same connectivity, but with unequal orders of theirs largest components. Then these two graphs must be different in respect to stability. How can we measure that property? The idea behind the answer is the concept of integrity, which is different from connectivity. Total graphs constitute a large class of graphs. In this paper, we study the integrity of total graphs via some graph parameters. The formal specifications for protocols of decoders This paper presents a formal approach, FSPD (Formal Specifications for Protocols of Decoders), to specify decoder communication protocols. Based on axiomatic, FSPD is a precise language with which programmers could use only one suitable driver to handle various types of decoders. FSPD is helpful for programmers to get high adaptability and reusability of decoder-driver software. Secure SCTP – A Versatile Secure Transport Protocol The Stream Control Transmission Protocol (SCTP) is a new general purpose transport protocol defined by the IETF. Originally intended for the transport of voice signaling data (SS7) over IP networks, SCTP together with newly defined extensions is increasingly considered for other application scenarios as well. These require strong security solutions to authenticate the communication partners and protect sensitive data with respect to integrity and confidentiality. Proposals have been issued on how to protect SCTP transport by using standard security protocols such as TLS and IPsec. However, these solutions introduce limitations or inefficiencies und thus may not be able to fully exploit the capabilities of SCTP. Therefore, we propose a security extension to SCTP named Secure SCTP (S-SCTP) to solve these issues in an efficient and user-friendly way. e-Automation, an architecture for distributed industrial automation systems Due to the complexity of modern industrial systems, a conventional automation system is not capable of providing sufficient information management and high-level intelligent approaches, as achieving these functionalities requires the support of comprehensive data management and coordination between system devices and heterogenous information. This paper proposes the concept of e-Automation, in which computer networking and distributed intelligence agent technologies are applied to industrial automation systems, and presents a hardware and software architecture that implements this concept. An open infrastructure based on multi-agent systems is employed in the proposed architecture of e-Automation, which aims to allow the implementation of diverse tasks and to permit greater configurability than can be obtained from a traditional system. To evaluate our proposed e-Automation concept, this paper presents a case study of substation information management which adopts the proposed e-Automation architecture in power system domain. The Value of Temptation There is an implicit assumption in electronic commerce that induces the buyers to believe that their deals will be handled appropriately. However, after a seller has already committed to a buyer, he may be tempted by several requests though he will not be able to supply them all. We analyze markets in which a finite set of automated buyers interacts repeatedly with a finite set of automated sellers. These sellers can satisfy one buyer at a time, and they can be tempted to break a commitment they already have. We have found the perfect equilibria that exist in markets with a finite horizon, and with an unrestricted horizon. A significant result stemming from our study reveals that sellers are almost always tempted to breach their commitments. However, we also show that if markets' designers implement an external mechanism that restricts the automated buyers actions, then sellers will keep their commitments. MPI/FT: A Model-Based Approach to Low-Overhead Fault Tolerant Message-Passing Middleware Fault tolerance in parallel systems has traditionally been achieved through a combination of redundancy and checkpointing methods. This notion has also been extended to message-passing systems with user-transparent process checkpointing and message logging. Furthermore, studies of multiple types of rollback and recovery have been reported in literature, ranging from communication-induced checkpointing to pessimistic and synchronous solutions. However, many of these solutions incorporate high overhead because of their inability to utilize application level information.This paper describes the design and implementation of MPI/FT, a high-performance MPI-1.2 implementation enhanced with low-overhead functionality to detect and recover from process failures. The strategy behind MPI/FT is that fault tolerance in message-passing middleware can be optimized based on an application's execution model derived from its communication topology and parallel programming semantics. MPI/FT exploits the specific characteristics of two parallel application execution models in order to optimize performance. MPI/FT also introduces the self-checking thread that monitors the functioning of the middleware itself. User aware checkpointing and user-assisted recovery are compatible with MPI/FT and complement the techniques used here.This paper offers a classification of MPI applications for fault tolerant MPI purposes and MPI/FT implementation discussed here provides different middleware versions specifically tailored to each of the two models studied in detail. The interplay of various parameters affecting the cost of fault tolerance is investigated. Experimental results demonstrate that the approach used to design and implement MPI/FT results in a low-overhead MPI-based fault tolerant communication middleware implementation.