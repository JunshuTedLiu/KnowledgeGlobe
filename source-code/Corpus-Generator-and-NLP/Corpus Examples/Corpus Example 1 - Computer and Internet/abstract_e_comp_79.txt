Computers can replace maths for scientists, says Soviet professor  Electron image processing alysis, Enhancement and Interpretation.By D.L. Misell. Pp.305 (North-Holland: Amsterdam, New York and Oxford, 1978.) Paperback $60; Dfl. 135. Computer Techniques for Image Processing in Electron Microscopy. By W.O. Saxton. Pp. 289. (Academic: New York and London, 1978.) £15.15. Length and evolutionary stability of food chains Grazing food chains in natural ecosystems tend to be relatively short, usually involving no more than four or five trophic levels 1–3. Cohen4 describes 19 food webs with a total of 102 top predators. Recent independent analyses of these data by Cohen4 and Pimm (see ref. 5) show that most top predators occupy the third trophic level. However, as Slobodkin3 has observed, “It is possible to conceive of predators that are small enough and ferocious enough to attempt to live off the top of a trophic pyramid, and thereby become a seventh, or even an eighth, trophic level. It is by no means clear why this situation has not occurred.” Our answer, which we discuss here, incorporates energy transfer calculations introduced by Hutchinson1 and Odum and Odum2 within the framework of the evolutionarily stable strategy (ESS) developed by Maynard-Smith and Price 6,7. We argue that food chains should collapse to the shortest possible length compatible with biochemical and physiological constraints. This minimal length is frequently three, and is largely independent of primary productivity. E. coli ribosomal RNA contains sequences homologous to insertion sequences IS1 and IS2 The insertion sequence (IS) elements, IS1 and IS2, present in multiple copies in the Escherichia coli chromosome1–3, are transposable genetic elements of known nucleotide sequence4,5. These elements can modulate gene expression6–7, but it is not known whether they normally function in genetic control. To determine whether IS elements could exert control through specific RNA transcripts, we hybridised λ NNC1857r14 (carrying IS1) and pBR322 (carrying a portion of IS2) to Northern blots8 of E. coli RNA. Regions of homology between the IS elements and ribosomal RNA were observed. Computer analysis of reported nucleotide sequences detected large segments of homology between the IS elements and both 23S and 16S rRNA. Additional homologous sequences in ΦX174 and a leader region of a ribosomal protein gene cluster were also detected. The homologous sequence between IS2 and 16S rRNA is the same sequence in ΦX174 DNA which codes for the ends of the E and D gene and the start of J. The partial IS sequences may represent silent evolutionary remnants or they could modulate the expression of genes carrying these sequences. A network of microprocessors to execute reduction languages, part II This paper describes the architecture of a cellular processor capable of directly and efficiently executing reduction languages as defined by Backus. The processor consists of two interconnected networks of microprocessors, one of which is a linear array of identical cells, and the other a tree-structured network of identical cells. Both kinds of cells have modest processing and storage requirements. The processor directly interprets a high-level language, and its efficient operation is not restricted to any special class of problems. Memory space permitting, the processor accommodates the unbounded parallelism allowed by reduction languages in any single user program; it is also able to execute many user programs simultaneously. An order-algebraic definition of knuthian semantics This paper presents a formulation, within the framework of initial algebra semantics, of Knuthian semantic systems (K-systems) which contain both synthesized and inherited attributes. The approach is based on viewing the semantics of a derivation tree of a context-free grammar as a set of values, called an attribute valuation, assigned to the attributes of all its nodes. Any tree's attribute valuation which is consistent with the semantic rules of the K-system may be chosen as the semantics of that derivation tree.The set of attribute valuations of a given tree is organized as a complete partially ordered set such that the semantic rules define a continuous transformation on this set. The least fixpoint of this transformation is chosen as the semantics of a given derivation tree. The mapping from derivation trees to their least fixpoint semantics is a homomorphism between certain algebras. Thus, the semantics of a K-system is an application of the Initial Algebra Semantics Principle of Goguen and Thatcher. This formulation permits a precise definition of K-systems, and generalizes Knuth's original formulation by defining the meaning of recursive (circular) semantic specifications.The algebraic formulation of K-systems is applied to proving the equivalence of K-systems having the same underlying grammar. Such proofs may require verifying that a K-system possesses certain properties and to this end, a principle of structural induction on many-sorted algebras is formulated, justified, and applied. Complexity of some problems concerningL systems We determine the computational complexity of membership, emptiness and infiniteness for several types ofL systems. TheL systems we consider are ED0L, E0L, EDT0L, and ET0L, with and without empty productions. For each problem and each type of system we establish both upper and lower bounds on the time or memory required for solution by Turing machines. Chess 4.7 Gives Levy A Run For His Money  Finding a minimal set of base paths of a program An approach to finding a minimal set of base paths of a program is described. The program digraph is reduced to a weighted loopfree graph (WLFG) in which a node represents a subgraph of the program digraph that contains at most one outermost loop of the program. An algorithm for finding a maximal cutset of the WLFG is given such that (1) a maximal cutset does not contain two arcs that lie on a single path of the WLFG, and (2) its capacity is equal to the cardinality of a minimal set of base paths of the program. The algorithm repeatedly finds an eliminable arc and removes it from the WLFG until either the WLFG contains three nodes or no more eliminable arc can be found. An illustration is given for finding a maximal cutset and subsequently a minimal set of base paths. Cognitive/information processing psychology and instruction: Reviewing recent theory and practice With increasing frequency, constructs developed within the field of cognitive/information processing psychology are being employed in the development of instructional theory. This article attempts to organize a broad range of developments in instructional psychology which have this common origin. Particular emphasis is placed on the applicability of constructs such as data structures and procedures. Recent developments in instructional psychology are discussed relative to cognitive task analysis, individual difference variables, and cognitive models of interactive instructional decision-making. Implications for future theory and practice are considered. Cryptology: The Mathematics of Secure Communication onIf the model developed here for the abstract encryption/decryption channel is as general as is claimed, the discovery of asymmetric encryption techniques may be the ultimate revolution in cryptography. However, even if this should prove to be true, the impact on the practice of cryptography will continue for a very long time. For example, the mechanization of the encryption/decryption functions using computing elements, which began almost fifty years ago, has in just the past year progressed to a point where the NBS data encryption standard (DES) — a symmetric encryption scheme with a 64 bit key space [36,37] — is now offered on a single LSI chip by three manufacturers, and a two-chip MOS realization of the M.I.T. scheme with an eighty-decimal modulus has been designed. Since, in this article we were concerned more with the theory of secure communications than with the practice, no mention was made of the very significant fact that all of the asymmetric schemes which have been proposed thus far exact an extremely high price for their asymmetry — the increased amount of computation required in the encryption/decryption process cuts the channel capacity (bits per second of message information communicated) dramatically. In fact, at the moment no asymmetric scheme (to the best of the author’s knowledge) has been able to break theC1/2 bound, whereC is the channel capacity of a symmetric channel having the same cryptosecurity and using the same basic clock or bit manipulation rate. If this difference is genuine, as we believe it to be, and not just an artifact of the asymmetric schemes which happen to have been considered, then both symmetric and asymmetric encryption/decryption schemes will be needed depending on the requirements of each application — and asymmetric techniques will not supplant symmetric techniques in general.We said earlier that the investigation of the abstract encryption/decryption channel is the most important question in contemporary applied mathematics; others have characterized it as a multimillion dollar problem [38] awaiting solution. Irrespective of the accuracy of these judgements though, we would hope that a compelling case has been presented that contemporary cryptology is an exciting and important mathematical discipline opening challenging new problems in many areas of mathematics. Intelligence and experience: A neopiagetian approach An organismic process-structural approach to the classic and modern issues of intelligence and experience is outlined. A Theory of Constructive Operators (TCO) originally designed to explicate Piaget's metatheoretical notions of stages and of equilibration is presented. The theory describes a psychological organism which is a very active semantic-pragmatic system geared to assimilatory praxis. Its organization is bilevel: a situation-bound level of subjective operators (schemes) and a situation-free level constituted either by silent operators (mental effort, learning operators, field factors, affective factors, etc.) or by basic principles which describe the dynamic articulation of subjective and silent operators (the central articulation is a principle of schematic overdetermination of performance).The presentation emphasizes the TCO's epistemological foundations and Piagetian roots. The rules governing its main constructs are given. The presentation is therefore detailed enough to make possible the theory's use and its evaluation. Some of the theory's constructs as well as the illustration of mathematical models derivable from the theory in order to make quantitative predictions in many different types of tasks are however omitted. Experimental-developmental work supporting the TCO is not presented but reference to relevant papers and unpublished dissertations is provided. Relations of the TCO to some recent information-processing models of artificial intelligence and to task analysis are explained. Five basic aspects or conceptions of intelligence are recognized: genotypic (Hebb's intelligence A), phenotypic (Hebb's intelligence B), psychometric (Vernon's intelligence C), developmental (intelligence D) and computer-simulation (i.e., CS) intelligence. All five are briefly discussed and their relations with the TCO's explication of intelligence are briefly mentioned. In this manner we tacitly suggest how the understanding of these various aspects of the complex notion of intelligence can be advanced by means of the TCO. Detailed discussion of this last issue is however beyond the scope of the paper. Infinite trees in normal form and recursive equations having a unique solution A system of recursive equations isC-univocal if it has a unique solution modulo the equivalence associated with a classC of interpretations. This concept yields simplified proofs of equivalence of recursive program schemes and correctness criteria for the validity of certain program transformations, provided one has syntactic easily testable conditions forC-univocality.Such conditions are given for equational classes of interpretations. They rest upon another concept: thenormal form of an infinite tree with respect to a tree rewriting system. This concept yields a simplified construction of the Herbrand interpretation of certain equational classes of interpretations. Restricted one-counter machines with undecidable universe problems We show the undecidability of the universe problem for two restricted classes of nondeterministic one-counter machines. These classes are among the simplest known for which the universe problem can be shown unsolvable. P-selective sets, tally languages, and the behavior of polynomial time reducibilities onNP The notion ofp-selective sets, and tally languages, are used to study polynomial time reducibilities onNP. P-selectivity has the property that a setA belongs to the classP if and only if bothĀ ≤mpA andA isp-selective. We prove that for every tally language set inNP there exists a polynomial time equivalent set inNP that isp-selective. From this result it follows that if NEXT ≠ DEXT, then polynomial time Turing and many-one reducibilities differ onNP. An algorithm for least squares analysis of spectroscopic data This paper describes a variant of the Gauss-Newton-Hartley algorithm for nonlinear least squares, in which aQR implementation is used to solve the linear least squares problem. We follow Grey's idea of updating variables at intermediate stages of the orthogonalization. This technique, applied in partitions identified with known or suspected spectral lines, appears to be especially suited to the analysis of spectroscopic data. We suggest that this algorithm is an attractive candidate for the optimization role in Ekenberg's interactive computer graphics curve fitting program. Control sets on grammars using depth-first derivations Control sets on grammars are extended to depth-first derivations. It is proved that a context-free language is generated by the depth-first derivations of an arbitrary context-free grammar controlled by an arbitrary regular set. This result is sharpened to obtain a new characterization of the family of derivation-bounded languages: a languageL is derivation bounded if and only if it is generated by the depth-first derivations of a context-free grammarG controlled by a regular subsetR of the Szilard language ofG. The left-derivation-bounded languages are characterized analogously using leftmost derivations. It is proved that a grammarG is nonterminal bounded if and only if the Szilard language defined using only the depth-first derivations ofG is regular. Finally, it is proved that if a family of languagesC is a trio, a semi-AFL, an AFL, or an AFL closed under λ-free substitution, then the family of languages generated using arbitrary context-free grammars controlled by members ofC is full, is closed under reversal, and has the closure properties assumed ofC. An algorithm for minimizing a differentiable function subject to box constraints and errors We consider the problem of minimizing a differentiable function ofn parameters, with upper and lower bounds on the parameters. The motivation for this work comes from the optimization of the design of transient electrical circuits. In such optimization, the parameters are circuit elements, the bound constraints keep these parameters physically meaningful, and both the function and gradient evaluations contain errors. We describe a quasi-Newton algorithm for such problems. This algorithm handles the box constraints directly and approximates the given function locally by nonsingular quadratic functions. Numerical tests indicate that the algorithm can tolerate the errors, if the errors in the function and gradient are of the same relative size. A computer model of intermediate cerebellum dynamic operations in motor control An intermediate cerebellum theoretical model for processing central programming discharges and muscle force signals is described which can perform a correct motor task under different peripheral perturbations (loads). An indispensable condition is that the simulated interpositus nucleus cells controlling a given effector (muscle) are inhibited by impulses coming from that effector (negative feedback from muscle force detectors). The hypothesis is proposed that the intermediate cerebellum can act via the rubrospinal tract as an interface between programming and executing motor structures. More on permutation generation methods We study a class of recursive permutation generation methods which construct a sequence of alln! permutations ofn elements by repeatedly generating all permutations of the elements in the firstn−1 positions and exchanging one of them with the element in then-th position. We give a general principle which enables us to obtain a whole class of permutation generation methods. This class includes the well-known algorithms of Wells and Heap as special cases, but contains also many new simple algorithms. Moreover, we are able to produce permutation generation methods with prescribed properties concerning the change that should be made in order to skip a block ofm! permutations with fixed elements in positionsm+1, …,n. For any method in our class, this change is a single transposition for any oddm>1, and a cyclic shift along a cycle of lengthm for any evenm.ZusammenfassungWir untersuchen eine Klasse rekursiver Methoden zur Erzeugung von Permutationen, welche eine Folge allern! Permutationen vonn Elementen dadurch konstruieren, daß wiederholt alle Permutationen der Elemente in den erstenn−1-Positionen erzeugt werden und dann eines von ihnen mit dem Element in dern-ten Position vertauscht wird. Wir geben ein allgemeines Prinzip an, welches es uns ermöglicht, eine ganze Klasse von Methoden zur Erzeugung von Permutationen zu erhalten. Diese Klasse schließt die bekannten Algorithmen von Wells und Heap als Spezialfälle ein, enthält aber auch viele neue einfache Algorithmen. Darüber hinaus sind wir in der Lage, Methoden mit vorgegebenen Eigenschaften zu produzieren, welche die Änderung betreffen, die gemacht werden sollte, um einen Block vonm! Permutationen mit festen Elementen in den Positionenm+1, …,n zu überspringen. Für jede Methode in unserer Klasse ist diese Änderung eine einzelne Transposition, fallsm>1 ungerade ist, und eine zyklische Verschiebung entlang eines Zyklus' der Längem, fallsm gerade ist. A useful lemma for context-free programmed grammars We show that all quasi-realtime one-way multi-counter languages can be generated by a context-free ɛ-free programmed grammar (even under the free interpretation). The result can be used to obtain a new and almost trivial proof of the fundamental theorem that arbitrary context-free programmed grammars can generate all recursively enumerable languages. The proof of our result also yields the following, interesting characterization: the quasi-realtime one-way multi-counter languages are precisely the ɛ-limited homomorphic images of (free) context-free programmed production languages. It follows that the (free) derivation languages of context-free or even context-free programmed grammars, which were known to be context-sensitive, are in fact contained in the family of context-free ɛ-free programmed languages. On comparingLL(k) andLR(k) grammars A new and rigorous proof of the well-known fact thatLL(k) grammars areLR(k) grammars is provided. The proof is elementary in the sense that it is directly based on relations defining leftmost and rightmost derivations and no additional formalism is needed. A class of functions synthesized from a finite number of examples and a lisp program scheme We define a class of functions that can be synthesized from example problems. The algorithmic representation of these functions is the interpretation of a given scheme. The instantiation of the scheme variables is realized by a new method which uses pattern matching then if necessary generalization and further pattern matching. One can compute the number of examples necessary to characterize in a unique way a function of this class. One-sided k-height-balanced trees The purpose of this paper is to generalize the recent results on one-sided height-balanced trees (OSHB trees) to the case of one-sidedk-height-balanced trees, fork≥2. Surprisingly, this generalization leads to 0 (log2n) insertion and deletion algorithms, which are simpler than those available for OSHB trees, and thus we claim this generalization is of independent interest.ZusammenfassungIn dieser Arbeit werden die kürzlich erzielten Resultate über einseitig höhenbalanzierte Bäume (OSHB-Bäume) verallgemeinert auf den Fall einseitigk-höhenbalanzierter Bäume fürk≥2. Überraschenderweise führt die Verallgemeinerung zu 0(log2n) Einfüge- und Entferne-Algorithmen, die einfacher sind als die entsprechenden Algorithmen für OSHB-Bäume. Wir glauben daher, daß diese Verallgemeinerung an sich interessant ist. Some remarks on the symmetric rank-one update We consider the symmetric rank-one, quasi-Newton formula. The hereditary properties of this formula do not require quasi-Newton directions of search. Therefore, this formula is easy to use in constrained optimization algorithms; no explicit projections of either the Hessian approximations or the parameter changes are required. Moreover, the entire Hessian approximation is available at each iteration for determining the direction of search, which need not be a quasi-Newton direction. Theoretical difficulties, however, exist. Even for a positive-definite, quadratic function with no constraints, it is possible that the symmetric rank-one update may not be defined at some iteration. In this paper, we first demonstrate that such failures of definition correspond to either losses of independence in the directions of search being generated or to near-singularity of the Hessian approximation being generated. We then describe a procedure that guarantees that these updates are well-defined for any nonsingular quadratic function. This procedure has been incorporated into an algorithm for minimizing a function subject to box constraints. Box constraints arise naturally in the minimization of a function with many minima or a function that is defined only in some subregion of the space. Formal computations of non deterministic recursive program schemes We extend to non deterministic recursive program schemes the methods and results which permit definition of the semantics of such schemes in the deterministic case. Under natural hypothesis the set of finite and infinite trees generated by a scheme is proved to be the greatest fixed point of the functional mapping usually attached to this scheme. Program invariants as fixedpoints We argue that soundness and relative completeness theorems for Floyd-Hoare Axiom Systems ([3], [5], [18]) are really fixedpoint theorems. We give a characterization of program invariants as fixedpoints of functionals which may be obtained in a natural manner from the text of a program. We show that within the framework of this fixedpoint theory, soundness and relative completeness results have a particularly simple interpretation. Completeness of a Floyd-Hoare Axiom System is equivalent to the existence of a fixedpoint for an appropriate functional, and soundness follows from the maximality of this fixedpoint. The functionals associated with regular procedure declarations are similar to thepredicate transformers of Dijkstra; for nonregular recursions it is necessary to use a generalization of the predicate transformer concept which we call arelational transformer.ZusammenfassungEs wird dargelegt, daß die Sätze für Widerspruchsfreiheit und Vollständigkeit für Systeme, die auf Floyd-Hoare-Axiomen basieren ([3], [5], [18]), tatsächlich Fixpunktsätze sind. Die Programminvarianten werden als Fixpunkt-Funktionale charakterisiert, die man auf natürliche Weise vom Programmtext herleiten kann. Es wird gezeigt, daß innerhalb des Rahmen dieser Fixpunkttheorie die Ergebnisse bezüglich Widerspruchsfreiheit und Vollständigkeit eine besonders einfache Interpretation besitzen. Die Vollständigkeit eines Floyd-Hoare-Axiomensystems ist äquivalent zur Existenz eines Fixpunktes für eine geeignetes Funktional. Die Widerspruchsfreiheit folgt aus der Maximalität dieses Fixpunktes. Die Funktionale für reguläre Prozedurdeklarationen ähneln Dijkstras Prädikat-Transformern. Für nichtreguläre Rekursionen braucht man eine Verallgemeinerung des Prädikat-Transformer-Konzepts, das hier relationaler Transformer genannt wird. On relativizing auxiliary pushdown machines We consider relativizing the constructions of Cook in [4] characterizing space-bounded auxiliary pushdown automata in terms of timebounded computers. LetS(n) ≥ logn be a measurable space bound. LetDTA[NTA] be the class of setsS such that there exists a machineM such thatM with oracleA recognizes the setS andM is a deterministic [nondeterministic] oracle Turing machine acceptor that runs in time 2cS(n) for some constantc. LetDBiA[NBiA] be the class of setsS such that there exists a machineM such thatM with oracleA recognizes the setS andM is a deterministic [non-deterministic] oracle Turing machine acceptor with auxiliary pushdown that runs in spaceS(n) and never queries the oracle about strings longer than:S(n) ifi = 1, 2cS(n) for some constantc, ifi = 2, + ∞ ifi = 3.Then we prove the following results:
These contrast with Cook's (unrelativized) result:DT = NB = DB. Semantic equivalence of covering attribute grammars This paper investigates some methods for proving the equivalence of different language specifications that are given in terms of attribute grammars. Different specifications of the same language may be used for different purposes, such as language definition, program verification, or language implementation. The concept of syntactic coverings is extended to the semantic part of attribute grammars. Given two attribute grammars, the paper discusses several propositions that give sufficient conditions for one attribute grammar to be semantically covered by the other one. These tools are used for a comparison of two attribute grammars that specify syntax and semantics of mixed-type expressions. This example shows a trade-off between the complexity of syntactic and semantic specifications. Another example discussed is the equivalence of different attribute grammars for the translation of the while-statement, as used in compilers for top-down and bottom-up syntax analysis. On the depth complexity of formulas The problem of minimizing the depth of formulas by equivalence preserving transformations is formalized in a general algebraic setting. For a particular algebraic system ∑0 specific methods of a dynamic programming nature are developed for proving lower bounds on depth. Such lower bounds for ∑0 automatically imply the same results for the systems of (i) arithmetic computations with addition and multiplication only, and (ii) computations over finite languages using union and concatenation. The specific lower bounds obtained are (i) depth 2n−o(n) for the permanent, (ii) depth (0.25+o(1))log2n for the symmetric polynomials and (iii) depth 1.16logn for a problem of formula sizen. do considered od: A contribution to the programming calculus he utility of repetitive constructs is challenged. Recursive refinement is claimed to be semantically as simple, and superior for programming ease and clarity. Some programming examples are offered to support this claim. The relation between the semantics of predicate transformers and “least fixed point” semantics is presented. On the existence of optimal fixpoints The concept of optimal fixpoint was introduced by Manna and Shamir [6, 7] in order to extract the maximum amount of “useful” information from a recursive definition. In this paper, we extend the concept of optimal fixpoint to arbitrary posets and investigate conditions which guarantee their existence. We prove that if a poset is chain-complete and has bounded joins, then every monotonic function has an optimal fixpoint. We also provide a sort of converse which generalizes a Theorem of A. Davis [2]. If a lower semilattice has bounded joins and every monotonic function has a fixpoint, then it is chain-complete. Maximum likelihood estimation of Hawkes' self-exciting point processes  maximum likelihood estimation procedure of Hawkes' self-exciting point process model is proposed with explicit presentations of the log-likelihood of the model and its gradient and Hessian. A simulation method of the process is also presented. Some numerical results are given. Compact storage schemes for formatted files by spanning trees The use of spanning trees in the compression of data files is studied. A new upper bound for the length of the minimal spanning tree, giving the size of the compressed file, is derived. A special front compression technique is proposed for unordered files. The space demands are compared to an information theoretical lower bound of the file size. Dynoc—A dynamic optimal cluster-seeking technique A new technique for automatic clustering of multivariate data is proposed. In this approach a performance index for determining optimal clusters is introduced. This performance index is expressed in terms of the ratio of the minimum interset distance to maximum intraset distance. The optimal clusters are found when the performance index reaches a global maximum. If there are alternative groupings with equal number of clusters, the one with the largest performance index is chosen. Some remarks concerning the M.I.T. public-key cryptosystem Let a messageM be encrypted by raisingM to a powere moduloR, whereR ande are integers which are made public. The recipient of this encrypted form ofM can decipher it by raising the cipher text to a powerd moduloR. Only the recipient knows the values of the two large primesp1,p2 such thatR=p1p2; consequently, only he knowsd, ase is preselected such that (e, (p1 − 1)(p2 − 1))=1 anded ≡1 (mod (p1 − 1)(p2 − 1)).Recently several attacks have been made on the proposed security of this cryptosystem under iteration of the encryption procedure. In this paper we discuss methods of selecting the primesp1,p2 and the encryption exponente such that the possibility of breaking this cryptosystem by using an iteration procedure is minimized. Several numerical results are also presented. Compelled operations and operations of degreeP We definen-ary (n ≥ 1) operations compelled by an operator and operations of degreep, generalizations of Greibach's binary syntactic operations. We show that properties of binary syntactic operators remain right forn-ary operations (n ≥ 1) and further for idempotent operations. We obtain so hierarchy theorems among full semiAFLs and new properties about classical operations and classical families of languages. The new definitions and properties are illustrated by study of a family ofn-ary operations. Dynamic weighted binary search trees e present an algorithm which optimizes a weighted binary tree after an insertion or deletion. The resulting tree is nearly optimal. The algorithm needs O(n) space. In the case of an insertion the expected number of operations is equal to or less than the height of the tree. All results presented in this paper can also be found in [15]. A constructive generalization of the borel-cantelli lemma with application to the complexity of infinite strings This paper concerns a constructive adaptation of the classical Borel-Cantelli lemma which allows us to solve such decomposition problems as: when does there exist an infinite object that is decomposable into infinitely many parts that are maximally complex? A constructive proof is supplied of the key theorem and its degree is characterized. For completeness a classical (i.e., nonconstructive) proof is also provided. The problem of quasi sorting Given a setA and a total ordering relation defined on its elements, we consider a partial reconstruction of the ordering. IfS is the totally ordered sequence of the elements ofA, andk is positive integer, the problem ofquasi sorting is introduced as the one of generating ak-sorted sequenceP, where the position of each elementp inP is at a distance bounded byk from the position ofp inS. We present some properties ofk-sorted sequences, and pose the bases for the development of algorithms for generatingk-sorted sequences through element comparisons. Acceleration of the leastpth algorithm for minimax optimization with engineering applications Over the past few years a number of researchers in mathematical programming and engineering became very interested in both the theoretical and practical applications of minimax optimization. The purpose of the present paper is to present a new method of solving the minimax optimization problem and at the same time to apply it to nonlinear programming and to three practical engineering problems. The original problem is defined as a modified leastpth objective function which under certain conditions has the same optimum as the original problem. The advantages of the present approach over the Bandler-Charalambous leastpth approach are similar to the advantages of the augmented Lagrangians approach for nonlinear programming over the standard penalty methods. Relative complexity of operations on numeric and bit-string algebras Sets of primitive operations for algebras with numerical and bit string domains are classified according to their computational efficiency. The relative complexity of certain basic operations on such algebras is determined. Breast cancer in Israel: Laterality and survival aterality was examined in 10,702 cases of breast cancer in Israeli Jewish women. The overall left-right ratio was 1.04 and was higher in women over 60. The only population group with a left-right ratio less than 1 was the group of women born in Asian and Middle Eastern countries outside of Israel. There were no differences between the survival curves of women with right- or left-sided breast cancers at any stage. It is concluded that laterality of tumor is not an indicator of survival in breast cancer. APriori lithium dosage regimen using population characteristics of pharmacokinetic parameters The important problem of initiation of long-term lithium treatments tackled by means of the selection of an a prioridosage regimen based on the presumed efficacy of lithium and absence of toxicity. The pharmacokinetics of Li+ion is represented by a four-compartment open model including the supposed first-order processes for the release of the active compound from the dosage form and its absorption. Experimental protocols for measurements of serum concentrations and of urinary amounts after single and multiple dosing to healthy volunteers were derived with several oral dosage forms. Estimation of the pharmacokinetic parameters for each subject made it possible to validate the model for the various dosage forms. The interindividual variability of these parameters is taken into account by estimating the characteristics of the statistical distribution for the whole population. A dosage regimen is considered optimum when serum concentration profiles at steady state range from the threshold of efficacy (0.8 mmol/liter) to the threshold of toxicity (2.0 mmol/liter). When the number of daily intakes is fixed, the search for the optimum dose for the whole population is effected by minimizing the expected value of the random variable which characterizes the risks of excursion out of the therapeutic range. By this means universal dosages are shown to be unsatisfactory. However, certain dosage regimens individualized with respect to the renal clearance value of lithium and based on two or three daily intakes can give excellent results even when conventional dosage forms are used. Hydrolase production by Aspergillus niger in solid-state cultivation  production of macerating enzymes which liquefy and hydrolyze the mandarin orange peel was studied in a solid state cultivation of Aspergillus niger on wheat bran substrate. Solid state cultivation in a 2 ℓ drum fermenter capable of interchangeable operation under dynamic or static conditions were carried out maintaining the moisture content of the substrate at 32, 39, 46, 56, 67, and 74%. Biomass grown on the solid substrate was estimated on the basis of a constant value of glucosamine content of A. niger, 50 mg glucosamine/g cell. A linear relationship between oxygen uptake rate and growth rate observed in all the experiments gave an oxygen growth yield, YX/O, of 28.5 g cell/mol O2. The rate of macerating enzyme formation was also in proportion to the growth rate irrespective of the difference of the moisture content of the substrate.The enzyme accumulation on the solid substrate, the growth rate and oxygen uptake rate were maximum when the moisture content of the substrate was maintained at ca. 56% ascending from 32 to 56 and descending from 56 to 74. The average number of registers needed to evaluate a binary tree optimally n this paper we determine the number of binary trees with n leaves which can be evaluated optimally with less than or equal to k registers. Furthermore we obtain the result that this number is equal to the number of the binary trees with n leaves, using for traversal a maximum size of stack less than or equal to 2k+1−1. This fact is only a connection between the numbers of the trees and not between the sets of the trees. We compute also the average number ¯R(n) of registers needed to evaluate a binary tree optimally. We get for all ɛ>0: 
$$\bar R(n + 1) = 1d(\sqrt {n)}  + C + F(n) + O(n^{ -  0.5  +  \varepsilon } )$$
where C = 0.82574... is a constant and F(n) is a function with F(n) = F(4n) for all n>0 and −0.574<F(n)< −0.492. Storage representations for tree-like data structures Adata encoding is a formal counterpart of the “translation of a logical data structure into a physical storage structure". In this paper, both kinds of structures are represented by graphs; and an encoding is a type of embedding of the guest (logical structure) graph in the host (physical structure) graph. Thecost of an encoding is the average amount that the edges of the guest graph are stretched as they are replaced by paths in the host graph via the encoding; this “average” is weighted by an assignment of probabilities to the edges of the guest graph (called ausage pattern) that weights the edges according to their anticipated frequencies of traversals.This paper continues the study begun in [13] of encodings of data structures in the leaves of complete trees. The major thrust of the paper is to show that tree-hosts do not accommodate tree-like guests as congenially as they do array-like guests. Specifically, we study two encodings of tree-guests in tree-hosts, and three usage patterns for the guests. One of these usage patterns can be accommodated with cost independent of the size of the guest by one of the encodings but not by the other; the second usage pattern engenders the complementary situation; and the third usage pattern resists size-independent cost not only on the part of the two encodings studied here but also on the part ofany encoding of trees into trees. We do, however, find a third encoding of trees in trees whose cost relative to this intransigent usage pattern is exponentially smaller than the costs of our two encodings and is, in fact, optimal in rate of growth.Motivated by the demonstrated weaknesses of trees as hosts in data encodings, we introduce a new tree-like storage structure called adree; and we show that drees are quite congenial hosts for array-like and tree-like (and dree-like) guests.Throughout the paper, demonstrations of size-independence in the costs of encodings are accompanied by proofs of the (asympotic) near-optimality of the attained costs. Wavefunctions and oscillator strengths for MgIX, SiXI, ArXV, CaXVII and FeXXIII Configuration interaction wavefunctions for the 1s22s21S, 1s22s2p3P0,1p0 and 1s22p23P,1D,1S, states are calculated for MgIX, SiXI, ArXV, CaXVII and FeXXIII and are used to calculate oscillator strengths, both the length and velocity forms, for transitions between these states. Spatial firing patterns of auditory neuron network modelling by computer simulation This communication examines, in digital computer simulated network, input signals and response patterns established at excitatory neurons' level i.e. the membrane potential of neuron soma. It is restricted to spatial patterns of the auditory neuron networks and time factor for nervous conduction and transmission is neglected compared with long maintained membrane potentials of neuron somas. The model analyzes the change in the spatial patterns of the membrane potential in the two dimensional networks of the auditory system. In order to evaluate the contribution of the various parameters, it is started that the simplest model has only one parameter, lateral inhibition. The other parameters are then added, one at a time, to successive models. The lateral inhibition is a necessary condition in the auditory nervous system if any sharpening of the response areas in the single neurons is to occur. A necessary condition for the validity of the model is that it should be applicable to the other senses such as vision and chemical patterns, taste. The threshold feature of auditory neurons aids in producing a sharpening in the neuron of the auditory relay nuclei. It does this clipping the spatial response patterns in one dimensional arrays of excitatory neurons. Recurrent inhibition seems a necessary condition in the sensory nervous system that any kinds of input signals are to be preserved over a wide range of stimulus intensity. In other words, this network has a wide dynamic range against any kinds of input signals. A simple self-recurrent negative feedback does not contribute to the sharpening, but more complex socalled averaged type does. A neuron network is capable of responding stably to stimuli with a wide range of intensity and with any kind of spatial patterns if there is a simple negative feedback mechanism. When there is no negative feedback, input signals soon disappear or saturate in the neuron network. Therefore, recurrent inhibition is the most important mechanism. Spontaneous activity appears to aid in the sharpening by providing a kind of contrast, that is by reducting the amount of activity in neurons adjacent to the excitatory area. Moreover, the effect of spontaneous activity in the model seems to make repples around the excitatory area and suggests that an introduction of activity at any stage of the networks, from whatever source for example reticulum formation and thalamus, might appreciably alter the response patterns at subsequent neuron network. This suggests that the mechanism of the consciousness that might be controlled by the thalamus and or reticular formation. These two dimensional neuron networks may be expanded to three dimensional neuron networks. The former might simulate the auditory nervous system while the latter might simulate the visual system. Primary empty sella turcica in children The authors describe cranio-facial deformities found in two sisters and associated with spinal anomalies, short stature and delayed skeletal maturation. The principal radiological features were an enlarged J-shaped sella turcica and intrasellar cisternal herniation. Enlargement of optic foramina and internal acoustic canals were also present. These asymptomatic cases of “empty sella” seem to be part of a general dysplastic syndrome rather than a local disease.