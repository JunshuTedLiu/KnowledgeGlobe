In terms of computer graphics  European cooperation: All-optical computer in sight  Business in science  Direct observations of the dopant environment in fluorites using EXAFS Calcium fluoride (CaF2), like the important UO2 phase, is a defect system having the remarkable property that large concentrations of trivalent rare-earth dopants can be accommodated within its structure with no loss of structural integrity. Using extended X-ray absorption fine structure (EXAFS), we have observed the way in which the local structural environment of the impurity alters with the size of the rare-earth ion and can distinguish, by computer lattice simulation studies, between dimer and hexamer configurations for light and heavy dopants, respectively. Building the modern main-frame uter Comes of Age: The People, the Hardware, and the Software.By R. Moreau. Translated by Jack Howlett. MIT Press: 1984. Pp.227. $19.95, £20.85. Spectroscopy and spectrometry on and computer-links are the main themes among the latest in spectrophotometers and spectrometers A VLSI design for the parallel finite state automaton and its performance evaluation as a hardware scanner Recent developments in VLSI technology have made it possible to design and implement smaller, cheaper, faster, and more reliable computer components. In addition, these advances have been a major drive for the design and development of the so-called “suitable algorithm” for VLSI implementation.The finite state automaton, its concept, computational power, and applications have been under investigation since the early 60's. Most of the studies have addressed the deterministic model of the finite state automaton with no degree of parallelism in the operations.This paper introduces a hardware architecture and VLSI design of the parallel finite state model. In addition, it addresses the time and space complexities of the proposed organization. Moreover, the paper represents the performance evaluation of the proposed architecture as a special purpose hardware recognizer device capable of performing pattern matching and text retrieval operations.The proposed model simulates a parallel finite state automaton by utilization of a number of identical and independent units called “CELLs,” which have associative capability. Each cell represents a state and transitions out of that state. Dance in computer technology: A survey of applications and capabilities onDance has made major incursions into the area of computer technology over the past 10 years. In this respect, it has more than rivalled the other arts and, in addition, has an even greater potential for reaching beyond current constraints and into the realm of vanishing horizons. Through computer and video technologies, dance has gained a potential and accelerated access to home audiences. Computer technology has also provided the art of dance with increased opportunities for creativity and experimentation, for literacy and for learning. In sum, and as a result, dance exemplifies the integration of artistic concerns and technological advances in today's world. The use of hoare logic in the verification of horizontal microprograms In recent years, much effort has been devoted to the design and implementation of microprogramming languages that support the production of highly reliable yet efficient run time microcode. One of the goals for such languages is to facilitate the formal verification of microprograms using Hoare's inductive assertion method. Essential to the use of this method is an axiomatic definition of the microprogramming language.In this paper, we describe the axiomatization of a machine dependent microprogramming language called S*(QM-1)(1). This language is an instantiation of the machine independent language schema S*(2,3) based on the Nanodata QM-1 “nanolevel” architecture, and is designed for the development and specification ofhorizontal microprograms. We discuss the rationale underlying the design and axiomatization of this language and we show, using S*(QM-1) as a case study, some of the important points in which the verification of firmware differs from software verification. Computer technology for autistic students The first purpose of this article is to review the literature related to the use of computers with autistic individuals. Although only a limited number of applications have been reported, the potential of the computer to facilitate the progress of autistic persons is promising. The second purpose is to identify specific learning problems or styles associated with autism from the research literature and link these with the unique aspects of computer-based instruction. For example, the computer's role in improving the motivation of autistic individuals is related to its capacity to analyze the reinforcing qualities of a particular event interactively and immediately for each user. Finally, recommendations that may enable computers to be maximally beneficial in assessing the learning process and remediating learning problems are offered. Two such recommendations are selecting appropriate software and integrating computer instruction within the classroom environment. New lower bound techniques for VLSI In this paper, we use crossing number and wire area arguments to find lower bounds on the layout area and maximum edge length of a variety of new and computationally useful networks. In particular, we describe1)anN-node planar graph which has layout area θ(NlogN) and maximum edge length θ(N1/2/log1/2N),2)anN-node graph with anO(x1/2)-separator which has layout area θ(Nlog2N) and maximum edge length θ(N1/2logN/loglogN), and3)anN-node graph with anO(x1−1/r)-separator which has maximum edge length θ(N1−1/r) for anyr ≥ 3. Parity, circuits, and the polynomial-time hierarchy A super-polynomial lower bound is given for the size of circuits of fixed depth computing the parity function. Introducing the notion of polynomial-size, constant-depth reduction, similar results are shown for the majority, multiplication, and transitive closure functions. Connections are given to the theory of programmable logic arrays and to the relativization of the polynomial-time hierarchy. Efficient algorithms for agglomerative hierarchical clustering methods Whenevern objects are characterized by a matrix of pairwise dissimilarities, they may be clustered by any of a number of sequential, agglomerative, hierarchical, nonoverlapping (SAHN) clustering methods. These SAHN clustering methods are defined by a paradigmatic algorithm that usually requires 0(n3) time, in the worst case, to cluster the objects. An improved algorithm (Anderberg 1973), while still requiring 0(n3) worst-case time, can reasonably be expected to exhibit 0(n2) expected behavior. By contrast, we describe a SAHN clustering algorithm that requires 0(n2 logn) time in the worst case. When SAHN clustering methods exhibit reasonable space distortion properties, further improvements are possible. We adapt a SAHN clustering algorithm, based on the efficient construction of nearest neighbor chains, to obtain a reasonably general SAHN clustering algorithm that requires in the worst case 0(n2) time and space.Whenevern objects are characterized byk-tuples of real numbers, they may be clustered by any of a family of centroid SAHN clustering methods. These methods are based on a geometric model in which clusters are represented by points ink-dimensional real space and points being agglomerated are replaced by a single (centroid) point. For this model, we have solved a class of special packing problems involving point-symmetric convex objects and have exploited it to design an efficient centroid clustering algorithm. Specifically, we describe a centroid SAHN clustering algorithm that requires 0(n2) time, in the worst case, for fixedk and for a family of dissimilarity measures including the Manhattan, Euclidean, Chebychev and all other Minkowski metrics. A set-theoretic semantics for Clear  semantics for the Clear specification language is given. The language of set theory is employed to present constructions corresponding to Clear's specification-combining operations, which are then used as the basis for a denotational semantics. This is in contrast to Burstall and Goguen's 1980 semantics which described the meanings of these operations more abstractly via concepts from category theory. The paging drum queue: A uniform perspective and further results  uniform perspective for the performance analysis of drums organised around the sector concept under Poisson input is presented which allows further results on their operating characteristics to be naturally derived. Closed-form expressions are provided for (i) the mean device service time, (ii) the device utilisation, (iii) the drum efficiency, (iv) the mean device busy period, and (v) the mean number of page transfers per busy period. Both the FCFS and SLTF scheduling disciplines are studied. When the number of sectors per track is large, it is shown that some of the above quantities could be approximated by extremely simple asymptotic formulae if a suitable time unit is adopted. Generalisations of some of these results which are applicable to the performance analysis of solid-state secondary memory and certain computer communications systems — the polling server and the token ring — are also presented. Polyvariant mixed computation for analyzer programs  polyvariant mixed computation algorithm for low-level non-structured programs is presented. A subclass of so called analyser programs has been chosen for which all partial computation that becomes possible during mixed computation is defined over a finite domain of nonsuspended variables. This not only provides termination of mixed computation but allows also to embody in the residual program a control structure encoded in the data. A fair calculus of communicating systems n this paper we are concerned with an operational approach to fairness, the problem of defining and generating the fair execution sequences of a concurrent language. One solution invokes two semantic levels: one level (the positive) prescribes the finite and infinite execution sequences without regard to their fairness while the other (the negative) filters out the unfair ones. The first level is given as a set of generative rules whereas the second is encoded as a definition of fair execution sequence. Entirely positive approaches have been proposed which appeal to random assignment. Here we offer an alternative positive approach for a subset of Milner's CCS. We show that rules can be given for generating just the fair sequences which avoid random assignment. On implementing Prolog in functional programming This report surveys techniques for implementing the programming language Prolog. It focuses on explaining the procedural semantics of the language in terms of functional programming constructs. The techniquessuccess continuations andproof streams are introduced, and it is shown how Horn clause interpreters can be built upon them. Continuations are well known from denotational semantics theory, in this paper it is shown that they are viable constructs in actual programs.Other issues include implementation of logical variables, structure sharing vs. structure copying, determinacy, builtin predicates, andcut. Calendar of events  A note on the complexity of program evaluation A simple problem concerning evaluation of programs is shown to be nonelementary recursive. The problem is the following: Given an input-free programP (i.e. all variables are initially 0) without nested loops using only instructions of the formx ← 1, x ← x + y,
$$x \leftarrow x\dot  - y$$
,do x... end, doesP output 0? This problem has time complexity
$$2^{2^{ {\mathinner{\mkern2mu\raise1pt\hbox{.}\mkern2mu \raise4pt\hbox{.}\mkern2mu\raise7pt\hbox{.}\mkern1mu}} ^2 } } $$
}cn-levels for some constantc. Other results are presented which show how the complexity of the 0-evaluation problem changes when the nonlooping instructions are varied. For example, it is shown that 0-evaluation is PSPACE-complete even for the case when the nonlooping instructions are onlyx ← x + 1,if x = 0then y ←y
$$y \leftarrow y\dot  - 1$$
. Towards separating nondeterminism from determinism The main result of this paper is a separation result: there is a positive integerk such that for all well-behaving functionst(n), there is a language accepted by a nondeterministic (multi-tape) Turing machine in timet(n) which cannot be accepting by any deterministic (multitape) Turing machine in timeO(t(n)) and simultaneously spaceo((t(n))1/k). This implies, for example that for any positive integer,l,l ≠k, there is a language accepted by anl time bounded NDTM which cannot be accepted by a DTM in time and spaceO(nl) andO((logn)l′) respectively for anyl′. Such a result is not provable by direct diagonalization because we do not have time to “simulate and do the opposite". We devise a different method for accomplishing the result: We first use an alternating Turing machine to speed up the simulation of a time and space bounded DTM and then argue that if our separation result did not hold, every NDTM can itself be simulated faster by another NDTM producing a contradiction to the standard hierarchy results. Some other applications of this method are also presented. Efficient Prolog memory management for flexible control strategies A Prolog interpreter can be viewed as a process that searches a tree in order to produce the sets of terms at certain successful leaves. It does this by constructing the set of terms for each node in the tree. Moving from one node to another requires (re)construction of the set of terms at that node. The choice of representation of sets of terms influences the kind of tree search that can be supported.The most efficient Prolog implementations represent terms by using chains of pointers through activation records. This is efficient because it allows much sharing of representation. However, it does constrain any search algorithm using these representations to be depth-first. There are various reasons why search orders other than depth-first might be desirable, not the least of which is to support a multiprocessor tree search. This paper describes a representation for terms that is comparable in efficiency to the best known, and yet supports arbitrary orders of tree search. A time-space tradeoff for language recognition We define a languageL and show that its time and space complexitiesT andS must satisfyT2S ≥cn3 even allowing machines with multiple (non random) access to the input. Towards a pipelined Prolog processor This paper describes the design of a Prolog machine architecture and organization. Our objective was to determine the maximum performance attainable by a sequential Prolog machine for “reasonable” cost. The paper compares the organization to both general purpose micro-coded machines and reduced instruction set machines. Hand timings indicate a peak performance rate of 450 K LIPS (logical inferences per second) is well within current technology limitations and 1 M LIPS is potentially feasible. A knowledge assimilation method for logic databases In this paper we consider a deductive question-answering system for relational databases as a logic database system, and propose a knowledge assimilation method suitable for such a system. The concept of knowledge assimilation for deductive logic is constructed in an implementable form based on the notion of amalgamating object language and metalanguage. This concept calls for checks to be conducted on four subconcepts, provability, contradiction, redundancy, independency, and their corresponding internal database updates. We have implemented this logic database knowledge assimilation program in PROLOG, a logic programming language, and have found PROLOG suitable for knowledge assimilation implementation. Guest editor’s preface  Clark’s “learning from media”: A critique In the Winter 1983 issue ofReview of Educational Research, Richard Clark published the article “Reconsidering Research on Learning From Media.” This article presented a particular point of view on media research that is of interest to educational technologists and has aroused some debate. In their critique of Clark’s article, Petkovich and Tennyson take issue with some of Clark’s points. Clark’s reply to this critique follows immediately after it. The qualitative comparative analysis of the visual field using computer assisted, semi-automated and manual instrumentation: II Statistical analysis A comparative evaluation of the Octopus automated perimeter (Programmes 21 and 31), the Goldmann Bowl perimeter, the Bjerrum Screen and the Friedmann VFAs Mk I and Mk II was carried out on a heterogenous sample of 75 patients. The results for the sample as a whole were analysed statistically in terms of the scoring system developed by Flanagan, Wild, Barnes, Gilmartin, Good and Crews (1984a). Statistically significant differences between the instruments were found at each of the 4 levels of analysis. Surjections and coverings This paper determines the necessary and sufficient condition under which a collection of sequence covers on a finite set can be induced by a surjection. The relationship of sequence covers and surjections to generalized decomposition of an automaton allowing feedback, is the same as the relationship of partitions and bijections to series-parallel decompositions. The condition determined is a natural, but complex generalization of the known condition for the series-parallel case. The occur-check problem in Prolog We present a method for preprocessing Prolog programs so that their operational semantics will be given by the first-order predicate calculus. Most Prolog implementations do not use a full unification algorithm, for efficiency reasons. The result is that it is possible to create terms having loops in them, whose semantics is not adequately described by first-order logic. Our method finds places where such loops may be created, and adds tests to detect them. This should not appreciably slow down the execution of most Prolog programs. Special FOCS issue—twenty-second annual IEEE symposium on foundations of computer science  A theory of computer rational numbers A numberp is defined to be “computer rational” when it can be well approximated bym/n wherem andn are integers andn is not greater than a fixed numberN. Probability of a randomly chosenp in (0, 1) being “computer rational” is discussed in a great detail. The probability distribution tends to a limiting distribution asN→∞. Generally speaking, it can be said that “computer rational” numbers are very rare in comparison with “computer irrational” numbers for most cases of application. In the process of theoretical treatments of the probability, number theoretical arguments are used extensively and an important lemma is derived and used about the distribution of “prime points”, those points (n, m) withn andm mutually prime. Software for young children Due to the pervasive nature of computers in all areas of our society, it comes as no surprise that they are creeping into the world of preschoolers. The issue is no longer whether or not it is appropriate to use computers with very young children, but rather how they can be used effectively with them. Specification of data restructuring software based on the attribute method The idea that abstract software specification is an essential phase in developing large and complex software has been widely accepted. In this paper, we specify in an abstract, but precise way, software for restructuring data structures based on the flat file and hierarchical data models. Our specification contains also the case that a target data structure is constructed from many source data structures. In data restructuring data structures are transformed. We propose the use of the attribute method for these kinds of translation oriented specification situations in the data base area. We apply the attribute method in the context of abstract syntax instead of a concrete one. An assessment of the physiological significance of cimetidine interactions with copper and zinc in biofluids as based on the computer-simulated distribution of the involved complexes at therapeutic levels of the drug The hypothesis was formerly put forward that the main therapeutic action of cimetidine (the histamine H2-receptor antagonist marketed as Tagamet®) as well as some of its side effects might be mediated by its interactions with essential metal ions.The present paper reports the potentiometric study of the coordination of the drug with copper(II) and zinc(II) in NaCl 0.15 mol dm−3 at 37°C. Special attention was paid to copper complexes, due to (i) the involvement of cimetidine in rheumatoid arthritis evolution which could be related to the well-established role of copper against this disease, (ii) the anti-ulcer and anti-inflammatory properties of copper. In particular, the copper-cimetidine-histamine and copper-cimetidine-histidine ternary systems were investigated.Computer simulations of the distribution of cimetidine, zinc and copper in blood plasma were performed at therapeutic levels of the drug. No influence can be expected from cimetidine on the bioavailability of these metal ions, the opposite being also true. The mediation of copper in the action of cimetidine on rheumatoid arthritis should thus be ruled out, the influence of the drug being rather interpretable in terms of reduction of histamine release. Similarly, the sexual dysfunctions due to cimetidine administration are unlikely to arise from the interactions of drug with zinc in blood plasma.The possible involvement of copper and zinc in cimetidine gastrointestinal absorption is also discussed. Poking the Giant’s Eye Out  The qualitative comparative analysis of the visual field using computer assisted, semi-automated and manual instrumentation: III Clinical analysis A comparative evaluation of the Octopus automated perimeter (Programmes 21 and 31), the Goldmann Bowl perimeter, the Bjerrum Screen and the Friedmann VFAs Mk I and Mk II was carried out on a heterogenous sample of 75 patients. Field loss was categorized using a modification of the classifications proposed by Greve (1982). The results were analysed using the Level 4 analysis developed by Flanagan, Wild, Barnes, Gilmartin, Good and Crews (1984a). The performance of the various test logics was found to differ between the categories of field defect. Secant relations versus positive definiteness in quasi-Newton methods The effect of using a nonsymmetric and nonpositive-definite matrix for approximation of the Hessian inverse in unconstrained optimization is investigated. To this end, a new algorithm, which may be viewed as a member of the Huang family, is derived. The proposed algorithm possesses the quadratic termination property without exact line search. It seems from the numerical results that it is not essential to use a symmetric and positive-definite matrix. A computationally efficient approximation to the nearest neighbor interchange metric The nearest neighbor interchange (nni) metric is a distance measure providing a quantitative measure of dissimilarity between two unrooted binary trees with labeled leaves. The metric has a transparent definition in terms of a simple transformation of binary trees, but its use in nontrivial problems is usually prevented by the absence of a computationally efficient algorithm. Since recent attempts to discover such an algorithm continue to be unsuccessful, we address the complementary problem of designing an approximation to the nni metric. Such an approximation should be well-defined, efficient to compute, comprehensible to users, relevant to applications, and a close fit to the nni metric; the challenge, of course, is to compromise these objectives in such a way that the final design is acceptable to users with practical and theoretical orientations. We describe an approximation algorithm that appears to satisfy adequately these objectives. The algorithm requires O(n) space to compute dissimilarity between binary trees withn labeled leaves; it requires O(n logn) time for rooted trees and O(n2 logn) time for unrooted trees. To help the user interpret the dissimilarity measures based on this algorithm, we describe empirical distributions of dissimilarities between pairs of randomly selected trees for both rooted and unrooted cases. Finite complete rewriting systems and the complexity of the word problem t is well known that the word problem for a finite complete rewriting system is decidable. Here it is shown that in general this result cannot be improved. This is done by proving that each sufficiently rich complexity class can be realized by the word problem for a finite complete rewriting system. Further, there is a gap between the complexity of the word problem for a finite complete rewriting system and the complexity of the least upper bound for the lengths of the chains generated by this rewriting system, and this gap can get arbitrarily large. Thus, the lengths of these chains do not give any information about the complexity of the word problem. Finally, it is shown that the property of allowing a finite complete rewriting system is not an invariant of finite monoid presentations. A Prolog technology theorem prover An extension of Prolog, based on the model elimination theorem-proving procedure, would permit production of a logically complete Prolog technology theorem prover capable of performing inference operations at a rate approaching that of Prolog itself. A regional planning system based on artificial intelligence concepts In the paper we present a logic-based system that makes possible the comparison of the requirements of particular sectors (e.g. agriculture, industry, construction, mining, energy) and social requirements (e.g. living conditions, employment, education, culture) at the level of the territorial system. It is based on a hierarchical model of national, county and district level activities. Every level has its own goals and the problem is to find an acceptable solution for these goals. Its implementation depends upon a special extension of the logic-based programming language PROLOG, known as TSPROLOG. The basic function of a territorial system can be viewed as the reproduction of social resources on an increasing scale. The task (the basic activity) of the system is the ‘production’ of the territorial conditions of living and of the way of life. During this process of production, the system takes up raw material, energy and information from its environment. The processes that take place in the system are determined by natural/human resources, social activities, markets of technical elements and technically utilized areas. The external and internal relations of the system are regulated by the market of transport activities. Space sweep solves intersection of convex polyhedra lane-sweep algorithms form a fairly general approach to two-dimensional problems of computational geometry. No corresponding general space-sweep algorithms for geometric problems in 3- space are known. We derive concepts for such space-sweep algorithms that yield an efficient solution to the problem of solving any set operation (union, intersection, ...) of two convex polyhedra. Our solution matches the best known time bound of O(n log n), where n is the combined number of vertices of the two polyhedra. Mitochondrial fluorescence patterns in rhodamine 6G-stained myocardial cells in vitro Cellular fluorescence in vitro has been studied employing a low light-level video system interfaced with a real-time image array-processing computer system. Changes in cytoplasmic (mitochondrial) fluorescence in myocytes employing the probe rhodamine 6G have been studied over real time with the aid of several computer-based programs. An oscillating pattern of fluorescence is observed that appears to reflect localized variations in mitochondrial activity. The low light level video computer system used in this study compares favorably with laser-stimulated microspot fluorescence photon-counting techniques for the detection of subcellular fluorescence. An optimal algorithm for computing the minimum vertex distance between two crossing convex polygons LetP={p1,p2, ...,pm} andQ={q1,q2, ...,qn} be two intersecting convex polygons whose vertices are specified by their cartesian coordinates in order. An optimalO(m+n) algorithm is presented for computing the minimum euclidean distance betweena vertexpi inP and a vertexqj inQ.ZusammenfassungSeienP={p1,p2, ...,pm} undQ={q1,q2, ...,qn} zwei sich überschneidende konvexe Polygone, deren Ecken durch die kartesischen Koordinaten in der richtigen Reihenfolge festgelegt sind. Wir geben einen optimalenO(m+n)-Algorithmus für die Berechnung der minimalen euklidischen Distanz zwischen einer Eckepi inP und einer Eckeqj inQ an. Regular prefix relations We define a class ofn-ary relations on strings called the regular prefix relations, and give four alternative characterizations of this class:1.the relations recognized by a new type of automaton, the prefix automata,2.the relations recognized by tree automata specialized to relations on strings,3.the relations between strings definable in the second order theory ofk successors,4.the smallest class containing the regular sets and the prefix relation, and closed under the Boolean operations, Cartesian product, projection, explicit transformation, and concatenation with Cartesian products of regular sets.
We give concrete examples of regular prefix relations, and a pumping argument for prefix automata. An application of these results to the study of inductive inference of regular sets is described. Computer aided design of inverted strip dielectric waveguide millimeter wave ring-resonator and coupler A computer aided design technique has been developed for the design of millimeter-wave ring resonator and hybrid-ring coupler using inverted strip dielectric waveguides. The scattering matrix analysis for hybrid-ring coupler has also been developed. Numerical results for these components at f0=80 GHZ with 3-dB coupling have been presented along with the variation of width, spacing, and radii with frequency. On dos languages and dos mappings Roughly speaking,DOS systems formalize the notion of generatively deterministic context free grammars. We explore the containment relationships among the class of languages generated byDOS systems and other subclasses of the class of context free languages. Leaving the axiom of aDOS system unspecified yields aDOS scheme, which defines a mapping from words to languages over a given alphabet. We explore the algebraic properties ofDOS mappings and obtain an algebraic characterization of a fundamental subclass of theDOS mappings generated byDOS schemes which are propagating (non erasing) and have no cycles of derivability among letters of the alphabet. We apply this characterization to show that the mapping equivalence problem for propagatingDOS schemes is decidable. Recurrent words for substitution A wordw is called recurrent with respect to a substitution if any descendant of it can regeneratew itself by iterations of the substitution. The set of recurrent words with respect to a regular (resp. context free) substitution is a regular (resp. context free) language. The set of recurrent words which are the descendants of a single fixed word with respect to a context free substitution is context free. Computers as administrative assistants Computers are now making a major impact in the field of education and hold great potential for those who provide care for children. The advent of the personal computer has made the computer easily available to and affordable for many individuals and centers. Andpersonal meanspersonal. Learning to operate this new generation of computers is similiar to first experiences with an electric typewriter, a copying machine, or a microwave oven. It takes determination and practice but proves very worthwhile.