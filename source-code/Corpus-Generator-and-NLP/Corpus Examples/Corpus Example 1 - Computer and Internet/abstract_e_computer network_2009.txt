Problem Solving of Low Data Throughput on Mobile Devices by Artefacts Prebuffering The paper deals with a problem of low data throughput on wirelessly connected mobile devices and a possibility to solve this problem by prebuffering of selected artefacts. The basics are in determining the problem parts of a mobile device and solve the problem by a model of data prebuffering-based system enhancement for locating and tracking users inside the buildings. The framework uses a WiFi network infrastructure to allow the mobile device determine its indoor position. User location is used for data prebuffering and for pushing information from a server to PDAs. All server data are saved as artefacts with its indoor position information. Accessing prebuffered data on a mobile device can significantly improve a response time needed to view large multimedia data. The solution was tested on a facility management information system built on purpose with a testing collection of about hundred large size artefacts. Spectrum sharing in iterated Prisoner’s Dilemma game based on evolutionary strategies for Cognitive Radios We study a spectrum sharing problem where multiple systems coexist and interfere with each other. First, an analysis is proposed for distributed spectrum sharing based on Prisoners’ Dilemma (PD) in Cognitive Radios (CRs). In one-shot game, selfish and rational CRs greedily full spread their own spectrum space in order to maximize their own rates, which leads to Nash Equilibrium (N.E.). But with long term interaction, i.e., Iterated Prisoner’s Dilemma (IPD), CRs can come to cooperate and acquire the social optimal point by using different evolutionary strategies such as Tit For Tat (TFT), Generous TFT (GTFT), etc. Also we compare the performances of the different evolutionary strategies in noise-free and noisy environments for two-player games. Finally, N-player IPD (N-IPD) is simulated to verify our conclusions that TFT is a good strategy for spectrum sharing in CRs. Defense against collusion scheme based on elliptic curve cryptography for wireless sensor networks Wireless Sensor Networks (WSNs) are being deployed for a wide variety of applications and the security problems of them have received considerable attention. Considering the limitations of power, computation capability and storage resources, this paper proposed an efficient defense against collusion scheme based on elliptic curve cryptography for wireless sensor networks in order to solve the problems that sensor node-key leaking and adversaries make compromised nodes as their collusions to launch new attack. In the proposed scheme, the group-key distribution strategy is employed to compute the private key of each sensor node, and the encryption and decryption algorithms are constructed based on Elliptic Curve Cryptography (ECC). The command center (node) only needs to broadcast a controlling header with three group elements, and the authorized sensor node can correctly recover the session key and use it to decrypt the broadcasting message. Analysis and proof of the proposed scheme’s efficiency and security show that the proposed scheme can resist the k-collusion attack efficiently. Cyclostationary property based spectrum sensing algorithms for primary detection in cognitive radio systems To implement the primary signal without interference in cognitive radio systems, cognitive radios can detect the presence of the primary user in low SNR. Currently, energy detector is the most common way of spectrum sensing because of its low computational complexity. However, performance of the method will be possibly degraded due to the uncertainty noise. This paper illustrates the benefits of one-order and two-order cyclostationary properties of primary user’s signals in time domain. These feature detection techniques in time domain possess the advantages of simple structure and low computational complexity comparing with spectral feature detection methods. Furthermore, performance of the one-order and two-order feature detection is studied and the analytical results are given. Our analysis and numerical results show that the sensing performance of the one-order feature detection is improved significantly comparing with conventional energy detector since it is robust to noise. Meanwhile, numerical results show that the two-order feature detection technique is better than the one-order feature detection. However, this benefit comes at the cost of hardware burdens and power consumption due to the additional multiplying algorithm. Uplink User Signal Separation for OFDMA-Based Cognitive Radios Spectrum awareness of orthogonal frequency division multiple access- (OFDMA-) based cognitive radios (CRs) can be improved by enabling them to separate the primary user signals in the uplink (UL). Assuming availability of information about the basic parameters of the primary system as well as time synchronization to the first arriving user signal, two algorithms are proposed in this paper. The first one targets estimating the size of the frequency allocation block of the primary system. The performance of this algorithm is compared with the results of a Gaussian approximation-based approach that aims to determine the probability of correct block size estimation theoretically. The second one is a semiblind user separation algorithm, which estimates the carrier frequency offsets and time delays of each block by exploiting the cross-correlations over pilot subcarriers. A two-dimensional clustering method is then employed to group the estimates, where each group belongs to a different user. It is shown that the proposed algorithms can improve the spectrum opportunity detection of cognitive radios. Feasibility of the algorithms is proved through practical simulations. Ambient Intelligence and Persuasive Technology: The Blurring Boundaries Between Human and Technology The currently developing fields of Ambient Intelligence and Persuasive Technology bring about a convergence of information technology and cognitive science. Smart environments that are able to respond intelligently to what we do and that even aim to influence our behaviour challenge the basic frameworks we commonly use for understanding the relations and role divisions between human beings and technological artifacts. After discussing the promises and threats of these technologies, this article develops alternative conceptions of agency, freedom, and responsibility that make it possible to better understand and assess the social roles of Ambient Intelligence and Persuasive Technology. The central claim of the article is that these new technologies urge us to blur the boundaries between humans and technologies also at the level of our conceptual and moral frameworks. Intra-domain traffic engineering with shortest path routing protocols Throughout the last decade, extensive deployment of popular intra-domain routing protocols such as open shortest path first and intermediate system–intermediate system, has drawn an ever increasing attention to Internet traffic engineering. This paper reviews optimization techniques that have been deployed for managing intra-domain routing in networks operated with shortest path routing protocols, and the state-of-the-art research that has been carried out in this direction. Experimental investigations. The characteristic of a specific object of study This paper describes the experimental investigation carried out according to the complex system for protection (CSP) of the university’s distributed local computer network (DLCN) using the example of the Dubna International University of Nature, Society, and Man. The laborious task of perfecting the system of the structure, initial data, composition of information protection instruments, characteristics of these instruments, their potential, and the prevention of unauthorized access to a network is considered. Parameter estimation for product-form distributions of queueing networks Basic parameters of a queueing network are its routing matrix, arrival flow rate, and service rates at network nodes. To estimate these parameters, one has to solve a system of balance equations. In turn, a product-form limiting distribution of the number of customers at the network nodes is defined through loading factors. Therefore, in the paper we propose to estimate loading factors through estimates of the limiting distribution based on observations of the number of customers at the nodes. This makes it possible to avoid solving a system of balance equations. This algorithm is realized for Jackson networks: classical, in a random environment, with blocked transitions. Medical Diagnosis Using Adaptive Perceptive Particle Swarm Optimization and Its Hardware Realization using Field Programmable Gate Array The paper proposes to develop a field programmable gate array (FPGA) based low cost, low power and high speed novel diagnostic system that can detect in absence of the physician the approaching critical condition of a patient at an early stage and is thus suitable for diagnosis of patients in the rural areas of developing countries where availability of physicians and availability of power is really scarce. The diagnostic system could be installed in health care centres of rural areas where patients can register themselves for periodic diagnoses and thereby detect potential health hazards at an early stage. Multiple pathophysiological parameters with different weights are involved in diagnosing a particular disease. A novel variation of particle swarm optimization called as adaptive perceptive particle swarm optimization has been proposed to determine the optimal weights of these pathophysiological parameters for a more accurate diagnosis. The FPGA based smart system has been applied for early detection of renal criticality of patients. For renal diagnosis, body mass index, glucose, urea, creatinine, systolic and diastolic blood pressures have been considered as pathophysiological parameters. The detection of approaching critical condition of a patient by the instrument has also been validated with the standard Cockford Gault Equation to verify whether the patient is really approaching a critical condition or not. Using Bayesian analysis on the population of 80 patients under study an accuracy of up to 97.5% in renal diagnosis has been obtained. Structured P2P technologies for distributed command and control The utility of Peer-to-Peer (P2P) systems extends far beyond traditional file sharing. This paper provides an overview of how P2P systems are capable of providing robust command and control for Distributed Multi-Agent Systems (DMASs). Specifically, this article presents the evolution of P2P architectures to date by discussing supporting technologies and applicability of each generation of P2P systems. It provides a detailed survey of fundamental design approaches found in modern large-scale P2P systems highlighting design considerations for building and deploying scalable P2P applications. The survey includes unstructured P2P systems, content retrieval systems, communications structured P2P systems, flat structured P2P systems and finally Hierarchical Peer-to-Peer (HP2P) overlays. It concludes with a presentation of design tradeoffs and opportunities for future research into P2P overlay systems. Deception in Business Networks: Is It Easier to Lie Online? This article synthesizes research presented in several models of unethical behavior to develop propositions about the factors that facilitate and mitigate deception in online business communications. The work expands the social network perspective to incorporate the medium of communication as a significant influence on deception. We go beyond existing models by developing seven propositions that identify how social network and issue moral intensity characteristics influence the probability of deception in online business communication in comparison to traditional communication channels. Remedies to detect and discourage deception in online business networks are also offered, as well as limitations and future research directions. Special Issue on “Wireless Sensor Networks”  Low-energy excitations in the three-dimensional random-field Ising model The random-field Ising model (RFIM), one of the basic models for
quenched disorder, can be studied numerically with the help of efficient
ground-state algorithms. In this study, we extend these algorithm by
various methods in order to analyze low-energy excitations for the
three-dimensional
RFIM with Gaussian distributed disorder that appear in the form of
clusters of connected spins. We analyze several
properties of these clusters. Our results support
the validity of the droplet-model description for the RFIM.
 VHDL Design for Real Time Motion Estimation Video Applications The VHDL design code and its implementation using 0.25 μm technology have been demonstrated for the real time video applications. The processing time of a frame running at 400 MHz was estimated to be 8.1 ms for QCIF and CIF Sequences, which accommodates more than 120 frames per second, and this warrant real time video codec. The design was validated and simulated using ModelSim from Mentor Graphics tools, and then verified using both the VHDL testbench and the Matlab® Image processing toolbox. Various alternate search algorithms have been proposed and simulated using Matlab for their real time processing. Skipping “every other column” (SC), and skipping “every other row and column” (SRC) algorithm, “optimal local neighborhood search” (OLNS), and limited-optimal neighborhood search (L-OLNS) have been demonstrated. The microprocessor as a controller is based on RISC processor and it uses pipelining to gain clocking efficiency. Making Knowledge in Synthetic Biology: Design Meets Kludge Synthetic biology is an umbrella term that covers a range of aims, approaches, and techniques. They are all brought together by common practices of analogizing, synthesizing, mechanicizing, and kludging. With a focus on kludging as the connection point between biology, engineering, and evolution, I show how synthetic biology’s successes depend on custom-built kludges and a creative, “make-it-work” attitude to the construction of biological systems. Such practices do not fit neatly, however, into synthetic biology’s celebration of rational design. Nor do they straightforwardly embody Richard Feynman’s “last blackboard” statement (1988) that without creating something it cannot be understood. Reflecting further on the relationship between synthetic construction and knowledge making gives philosophy of science new avenues of insight into scientific practice. Business process management with the user requirements notation A number of recent initiatives in both academia and industry have sought to achieve improvements in e-businesses through the utilization of Business Process Management (BPM) methodologies and tools. However there are still some inadequacies that need to be addressed when it comes to achieving alignment between business goals and business processes. The User Requirements Notation (URN), recently standardized by ITU-T, has some unique features and capabilities beyond what is available in other notations that can help address alignment issues. In this paper, a URN-based framework and its supporting toolset are introduced which provide business process monitoring and performance management capabilities integrated across the BPM lifecycle. The framework extends the URN notation with Key Performance Indicators (KPIs) and other concepts to measure and align processes and goals. An example process for controlling access to a healthcare data warehouse is used to illustrate and evaluate the framework. Early results indicate the feasibility of the approach. Web 2.0 Social Networks: The Role 
of Trust Online social networks (OSNs) have gained enormous popularity in recent years. Hundreds of millions of social network users reveal great amounts of personal information in the Web 2.0 environment that is largely devoid of security standards and practices. The central question in this article is why so many social network users are being so trusting. The focus is on theory-building on trust as a critical issue in OSNs. A theoretical framework is developed, which facilitates a multi-level and multi-dimensional analysis of research problems related to trust in OSNs. First, the structural and relational underpinnings of trust in OSNs are investigated from a governance perspective that integrates concepts of social network theory, social capital and the role of value in relational exchanges. Subsequently, the focus moves to the individual’s decision to trust and to processes through which trust actually emerges. Different types and sources of trust from the trust literature and their importance for trust-related decisions and behaviours in OSNs are discussed. Several research propositions are presented, which contribute to a better understanding of the role of trust and the relevance of facets of trust and social capital in OSNs. Performance evaluation of a discovery and scheduling protocol for multihop ad hoc mobile grids Despite the many research efforts addressing the integration of mobile nodes into grids, only a few of them have considered the establishment of mobile grids over wireless ad hoc networks (hereafter,mobile ad hoc grids). Clearly, such grids need specialized resource discovery and scheduling mechanisms. To the best of our knowledge, though, the research on these mechanisms for mobile ad hoc grids is still preliminary. Besides, and more importantly, it has approached discovery and scheduling as separate mechanisms, which, we argue, is not suitable for mobile ad hoc grids. In this paper, we propose the integration of resource discovery and scheduling for mobile ad hoc grids into a single protocol called DICHOTOMY (Discovery and sCHeduling prOTOcol for MobilitY). This protocol allows computational tasks to be distributed appropriately in a mobile ad hoc grid, while mitigating the overhead of discovery messages exchanged among the nodes. Our experiments show that the protocol: (i) does proper scheduling, allowing an efficient load balancing among the nodes and helping with lowering the average completion time of tasks; (ii) keeps the discovery efficiency at acceptable levels in mobility scenarios and (iii) scales very well with respect to an increasing number of nodes, both in the total amount of energy savings due to packet transmissions and the distribution of such savings among the nodes. Clone detection via structural abstraction This paper describes the design, implementation, and application of a new algorithm to detect cloned code. It operates on the abstract syntax trees formed by many compilers as an intermediate representation. It extends prior work by identifying clones even when arbitrary subtrees have been changed. These subtrees may represent structural rather than simply lexical code differences. In several hundred thousand lines of Java and C# code, 20–50% of the clones that we find involve these structural changes, which are not accounted for by previous methods. Our method also identifies cloning in declarations, so it is somewhat more general than conventional procedural abstraction. Optimal monitoring system for a distributed intrusion detection system Distributed intrusion detection systems, which consist of spatially distributed monitoring elements, may be applied to detect intrusions in a real-time manner based on the analysis of collected data. This article will present and discuss some selected aspects of the architecture and efficiency of detection systems. The first part considers intrusion detection capabilities as being dependent on different distributed computer communication system parameters. The aim of the second part is to present an idea of the hierarchical architecture of distributed intrusion detection systems, and to assess the quality of monitoring performed in the lower layer of the hierarchical architecture of a distributed intrusion detection system. Moden und Trends in Wirtschaftsinformatik und Information Systems fassungIn der Wirtschaftsinformatik (WI), die in den deutschsprachigen Ländern dominiert, ist eine zunehmende Tendenz zur Internationalisierung festzustellen, wobei die von den USA ausgehende Fachrichtung Information Systems (IS) oftmals als Vorbild herangezogen wird. Untersuchungen zeigen, dass sich die WI in der Vergangenheit wiederholt mit modischen Themen auseinandergesetzt hat – für die IS liegen keine Befunde vor, die Aussagen zur Verbreitung von Moden machen. Mit unserer Studie wollen wir dazu beitragen, diese Forschungslücke zu schließen. Es wurde eine Literaturanalyse durchgeführt, die Aufschluss über die Entwicklung von Themen und Begriffen in der WI und IS im Zeitraum 1994 bis 2007 gibt. Titel, Abstract und Keywords von 2.564 Beiträgen aus drei WI-Zeitschriften und 5.647 Beiträgen aus fünf IS-Zeischriften wurden analysiert. Die Ergebnisse zeigen, dass die WI thematisch vielfältiger und konkreter ist als die IS und der Anteil an Moden in der WI höher ist. Wir räumen ein, dass die Auseinandersetzung mit Moden nicht ausschließlich negativ zu betrachten ist – insbesondere kann sie einen wirksamen Beitrag zur Praxisnähe und Relevanz der Forschung leisten. Nichtsdestoweniger ist zu beachten, dass eine zu starke Orientierung an Moden den kumulativen Erkenntnisfortschritt negativ beeinflussen kann. Im Fazit wird daher festgestellt, dass aus Sicht der WI und IS, die sowohl ein theoretisches als auch ein pragmatisches Erkenntnisziel verfolgen, ein ausgewogenes Verhältnis an kurz- und langfristigen Themen zweckmäßig erscheint.AbstractThe business and information systems engineering (BISE) discipline, dominating in the German-speaking countries, where it is called Wirtschaftsinformatik, is currently undergoing a phase of increasing internationalization and the U.S.-based Information Systems (IS) discipline is often considered an ideal. Studies show that BISE has often dealt with fads in the past – for IS there are no findings reporting on the diffusion of fads. The objective of the paper is to close this research gap. We conducted a literature analysis that investigates the development of topics and terms in BISE and IS from 1994 to 2007. Titles, abstracts and keywords of 2,564 articles in three BISE journals and 5,647 articles in five IS journals were analyzed. The results show that BISE is topically more diverse and concrete than IS. In addition, the rate of fads is higher in BISE than IS. We concede that being engaged in fads is not necessarily negative – rather, it may considerably contribute to the relevance of research. However, it has to be considered that an overly intense orientation on fads may negatively influence a cumulative research progress. Hence, we conclude that for BISE and IS, which both have a theoretical and pragmatic mission, a balanced ratio of short- and long-term topics seems appropriate. Genetic testing for Lynch syndrome in the first year of colorectal cancer: a review of the psychological impact An increasing number of patients with colorectal cancer (CRC) receive genetic counselling within 1 year after diagnosis. Little is known whether specific subgroups are more vulnerable for genetic testing related distress. A literature review was conducted to identify the psychological impact of CRC in the first year, and the additional impact of genetic testing. The electronic databases of PubMed, PsychInfo, Embase and the Cochrane Library were searched to identify all reports published between January 1997 and October 2007 on the psychological impact of (1) CRC-diagnosis up to 1 year after treatment and of (2) genetic testing for Lynch syndrome in patients with CRC. Studies on the psychological impact of genetic testing in newly diagnosed patient with CRC were not available. Either CRC patients diagnosed several years ago were studied and the focus was also often on the psychological impact of genetic testing prior to DNA-test disclosure. They show that limitations in emotional and social functioning can persist up to 1 year after CRC treatment, especially in those with a stoma or diagnosed before age 60. Female patients and male patients diagnosed before age 50 appear to be more vulnerable to genetic test-related distress. It is well known that being treated for CRC has great impact on psychological functioning. Little is known about the psychological impact during the first year after diagnosis and very little is known about the additional psychological effect of genetic testing for hereditary cancer in this period. We found presumptive evidence that specific subgroups of patients with CRC are more vulnerable for genetic-testing-related distress. Analyzing Accessibility Dimension of Urban Quality of Life: Where Urban Designers Face Duality Between Subjective and Objective Reading of Place The subject of urban quality of life and the promotion of its concept in particular, has always been the central focus of urban designers. This term is a multi-conceptual and dimensions. However most of the scholars have agreed that the concept consisted from two main dimensions; objective and subjective which these two approaches are used for its measuring. One of the important goals of urban designers is to create urban environment that all citizens have easy access to urban services, as accessibility reflects the quality of an urban environment. The present research intends to measure the public space accessibility by using objective approach in first and then by using the subjective approach for measuring in the study area to compare the results. The results revealed that there are considerable differences between objective and subjective measuring of urban quality of life in a urban space, therefore urban designers can not rely only on the results of objective measuring to understand such spaces for planning, if so, their attitudes towards urban spaces could not be an appropriate guide for explaining the quality of life for urban residents. Spectral affinity in protein networks BackgroundProtein-protein interaction (PPI) networks enable us to better understand the functional organization of the proteome. We can learn a lot about a particular protein by querying its neighborhood in a PPI network to find proteins with similar function. A spectral approach that considers random walks between nodes of interest is particularly useful in evaluating closeness in PPI networks. Spectral measures of closeness are more robust to noise in the data and are more precise than simpler methods based on edge density and shortest path length.ResultsWe develop a novel affinity measure for pairs of proteins in PPI networks, which uses personalized PageRank, a random walk based method used in context-sensitive search on the Web. Our measure of closeness, which we call PageRank Affinity, is proportional to the number of times the smaller-degree protein is visited in a random walk that restarts at the larger-degree protein. PageRank considers paths of all lengths in a network, therefore PageRank Affinity is a precise measure that is robust to noise in the data. PageRank Affinity is also provably related to cluster co-membership, making it a meaningful measure. In our experiments on protein networks we find that our measure is better at predicting co-complex membership and finding functionally related proteins than other commonly used measures of closeness. Moreover, our experiments indicate that PageRank Affinity is very resilient to noise in the network. In addition, based on our method we build a tool that quickly finds nodes closest to a queried protein in any protein network, and easily scales to much larger biological networks.ConclusionWe define a meaningful way to assess the closeness of two proteins in a PPI network, and show that our closeness measure is more biologically significant than other commonly used methods. We also develop a tool, accessible at http://xialab.bu.edu/resources/pnns, that allows the user to quickly find nodes closest to a queried vertex in any protein network available from BioGRID or specified by the user. Connectivity-Based Reliable Multicast MAC Protocol for IEEE 802.11 Wireless LANs We propose the efficient reliable multicast MAC protocol based on the connectivity information among the recipients. Enhancing the BMMM (Batch Mode Multicast MAC) protocol, the reliable multicast MAC protocol significantly reduces the RAK (Request for ACK) frame transmissions in a reasonable computational time and enhances the MAC performance. By the analytical performance analysis, the throughputs of the BMMM protocol and our proposed MAC protocol are derived. Numerical examples show that our proposed MAC protocol increases the reliable multicast MAC performance for IEEE 802.11 wireless LANs. Fads and Trends in Business and Information Systems Engineering and Information Systems Research – A Comparative Literature Analysis The business and information systems engineering (BISE) discipline, dominating in the German-speaking countries, where it is called“Wirtschaftsinformatik”, is currently undergoing a phase of increasing internationalization and the U.S.-based Information Systems (IS) discipline is often considered an ideal. Studies show that BISE has often dealt with fads in the past – for IS there are no findings reporting on the diffusion of fads. The objective of the paper is to close this research gap. The authors conducted a literature analysis to investigate the development of topics and terms in BISE and IS from 1994 to 2007. Titles, abstracts and keywords of 2,564 articles in three BISE journals and 5,647 articles in five IS journals were analyzed. The results show that BISE is topically more diverse and concrete than IS. In addition, the rate of fads is higher in BISE than IS. Being engaged in fads is not necessarily negative – rather, it may considerably contribute to the relevance of research. However, it has to be considered that an overly intense orientation on fads may negatively influence a cumulative research progress. Hence, the authors conclude that for BISE and IS, which both have a theoretical and pragmatic mission, a balanced ratio of short- and long-term topics seems appropriate. Testing an improved cymbal hydrophone Cymbal hydrophones have small volume and high sensitivity, but their reception is not stable enough, and their reception is in too narrow a frequency band. In order to overcome these inadequacies, the structure of the cymbal hydrophone was improved. The single ceramic piezoelectric element was replaced with a double one, the radius of the ceramic piezoelectric element was reduced, and a parallel circuit was added. A static analysis of this new structure was developed, and then simulations were made of both the traditional and new hydrophone structure using finite element software. Tests were then conducted in a tank. The results showed that the improved hydrophone has reception in a wider frequency band, reception performance is stable within this frequency band, and sensitivity is still high.摘 要钹式水听器体积小, 灵敏度高, 但其接收性能不够稳定, 接收频带较窄. 为了克服这些弱点, 对其结构进行改进. 运用双片陶瓷并联代替单片陶瓷, 并缩小陶瓷半径. 再通过有限元仿真实验和水池实验, 对改进前后的钹式水听器进行测试, 结果表明, 改进后的钹式水쳽器接收性能更加稳定, 接收频带也明显增加, 同时其灵敏度依然较高. Scheduling Heterogeneous Wireless Systems for Efficient Spectrum Access The spectrum scarcity problem emerged in recent years, due to unbalanced utilization of RF (radio frequency) bands in the current state of wireless spectrum allocations. Spectrum access scheduling addresses challenges arising from spectrum sharing by interleaving the channel access among multiple wireless systems in a TDMA fashion. Different from cognitive radio approaches which are opportunistic and noncollaborative in general, spectrum access scheduling proactively structures and interleaves the channel access pattern of heterogeneous wireless systems, using collaborative designs by implementing a crucial architectural component—the base stations on software defined radios (SDRs). We discuss our system design choices for spectrum sharing from multiple perspectives and then present the mechanisms for spectrum sharing and coexistence of GPRS+WiMAX and GPRS+WiFi as use cases, respectively. Simulations were carried out to prove that spectrum access scheduling is an alternative, feasible, and promising approach to the spectrum scarcity problem. Software platform virtualization in chemistry research and university teaching BackgroundModern chemistry laboratories operate with a wide range of software applications under different operating systems, such as Windows, LINUX or Mac OS X. Instead of installing software on different computers it is possible to install those applications on a single computer using Virtual Machine software. Software platform virtualization allows a single guest operating system to execute multiple other operating systems on the same computer. We apply and discuss the use of virtual machines in chemistry research and teaching laboratories.ResultsVirtual machines are commonly used for cheminformatics software development and testing. Benchmarking multiple chemistry software packages we have confirmed that the computational speed penalty for using virtual machines is low and around 5% to 10%. Software virtualization in a teaching environment allows faster deployment and easy use of commercial and open source software in hands-on computer teaching labs.ConclusionSoftware virtualization in chemistry, mass spectrometry and cheminformatics is needed for software testing and development of software for different operating systems. In order to obtain maximum performance the virtualization software should be multi-core enabled and allow the use of multiprocessor configurations in the virtual machine environment. Server consolidation, by running multiple tasks and operating systems on a single physical machine, can lead to lower maintenance and hardware costs especially in small research labs. The use of virtual machines can prevent software virus infections and security breaches when used as a sandbox system for internet access and software testing. Complex software setups can be created with virtual machines and are easily deployed later to multiple computers for hands-on teaching classes. We discuss the popularity of bioinformatics compared to cheminformatics as well as the missing cheminformatics education at universities worldwide. Algebraic operations on graphs preserving the degree sequence A finite state automaton implementation of an algorithm for transforming a given graph to another one with preservation of the degree sequence is considered. The algorithm studied here can be used for optimization of computer networks with a given set of providers and restrictions posed on their communication capability. In this case it is sufficient to know only local characteristics of a network, but not global ones, as is required in the algorithm of V. Havel and S. Hakimi. A Closed-Loop Control Traffic Engineering System for the Dynamic Load Balancing of Inter-AS Traffic Inter-AS outbound traffic engineering (TE) is a set of techniques for controlling inter-AS traffic exiting an autonomous system (AS) by assigning the traffic to the best egress points (i.e. routers or links) from which the traffic is forwarded to adjacent ASes towards the destinations. In practice, changing network conditions such as inter-AS traffic demand variation, link failures and inter-AS routing changes occur dynamically. These changes can make fixed outbound TE solutions inadequate and may subsequently cause inter-AS links to become congested. In order to overcome this problem, we propose the deployment of a closed-loop control traffic engineering system that makes outbound traffic robust to inter-AS link failures and adaptive to changing network conditions. The objective is to keep the inter-AS link utilization balanced under unexpected events while reducing service disruptions and reconfiguration overheads. Our evaluation results show that the proposed system can successfully achieve better load balancing with less service disruption and re-configuration overhead in comparison to alternative approaches. Downlink Scheduling for Multiclass Traffic in LTE We present a design of a complete and practical scheduler for the 3GPP Long Term Evolution (LTE) downlink by integrating recent results on resource allocation, fast computational algorithms, and scheduling. Our scheduler has low computational complexity. We define the computational architecture and describe the exact computations that need to be done at each time step (1 milliseconds). Our computational framework is very general, and can be used to implement a wide variety of scheduling rules. For LTE, we provide quantitative performance results for our scheduler for full buffer, streaming video (with loose delay constraints), and live video (with tight delay constraints). Simulations are performed by selectively abstracting the PHY layer, accurately modeling the MAC layer, and following established network evaluation methods. The numerical results demonstrate that queue- and channel-aware QoS schedulers can and should be used in an LTE downlink to offer QoS to a diverse mix of traffic, including delay-sensitive flows. Through these results and via theoretical analysis, we illustrate the various design tradeoffs that need to be made in the selection of a specific queue-and-channel-aware scheduling policy. Moreover, the numerical results show that in many scenarios strict prioritization across traffic classes is suboptimal. A formal logic approach to firewall packet filtering analysis and generation Recent years have seen a significant increase in the usage of computers and their capabilities to communicate with each other. With this has come the need for more security and firewalls have proved themselves an important piece of the overall architecture, as the body of rules they implement actually realises the security policy of their owners. Unfortunately, there is little help for their administrators to understand the actual meaning of the firewall rules. This work shows that formal logic is an important tool in this respect, because it is particularly apt at modelling real-world situations and its formalism is conductive to reason about such a model. As a consequence, logic may be used to prove the properties of the models it represents and is a sensible way to go in order to create those models on computers to automate such activities. We describe here a prototype which includes a description of a network and the body of firewall rules applied to its components. We were able to detect a number of anomalies within the rule-set: inexistent elements (e.g. hosts or services on destination components), redundancies in rules defining the same action for a network and hosts belonging to it, irrelevance as rules would involve traffic that would not pass through a filtering device, and contradiction in actions applied to elements or to a network and its hosts. The prototype produces actual firewall rules as well, generated from the model and expressed in the syntax of IPChains and Cisco’s PIX. Estimating the feasibility of transition paths in extended finite state machines There has been significant interest in automating testing on the basis of an extended finite state machine (EFSM) model of the required behaviour of the implementation under test (IUT). Many test criteria require that certain parts of the EFSM are executed. For example, we may want to execute every transition of the EFSM. In order to find a test suite (set of input sequences) that achieves this we might first derive a set of paths through the EFSM that satisfy the criterion using, for example, algorithms from graph theory. We then attempt to produce input sequences that trigger these paths. Unfortunately, however, the EFSM might have infeasible paths and the problem of determining whether a path is feasible is generally undecidable. This paper describes an approach in which a fitness function is used to estimate how easy it is to find an input sequence to trigger a given path through an EFSM. Such a fitness function could be used in a search-based approach in which we search for a path with good fitness that achieves a test objective, such as executing a particular transition, and then search for an input sequence that triggers the path. If this second search fails then we search for another path with good fitness and repeat the process. We give a computationally inexpensive approach (fitness function) that estimates the feasibility of a path. In order to evaluate this fitness function we compared the fitness of a path with the ease with which an input sequence can be produced using search to trigger the path and we used random sampling in order to estimate this. The empirical evidence suggests that a reasonably good correlation (0.72 and 0.62) exists between the fitness of a path, produced using the proposed fitness function, and an estimate of the ease with which we can randomly generate an input sequence to trigger the path. Dynamic Session Control Over IMS for Cross-Layer Optimization of Multi-Stream Video Cross-layer optimization is an evolutional approach via optimal source and channel resource combinations. It is generally understood that bitstreams can be constructed according to visual importance using multi-stream video in which the base and enhancement layers simultaneously contain visual information of varying importance. In accordance with their importance, radio resources are allocated to each layer for maximal perceptual visual quality using unequal error protection. Nevertheless, a framework for network signalling, which configures each layer using Quality-of-Service (QoS) parameters, has not been presented. This paper proposes a dynamic session control protocol over the IP Multimedia Subsystem (IMS) for network adaptation of multi-stream video where the coding mode can be dynamically changed during the duration of service according to the wireless channel dynamics. Cross-Layer, Energy-Efficient Design for Supporting Continuous Queries in Wireless Sensor Networks: A Quorum-Based Approach Power saving and query processing are two major concerns in a wireless sensor network. Each of these two issues has been intensively studied separately in the literature. In this work, we are interested in linking the asynchronous power-saving protocol and the continuous query-processing problem together. A cross-layer solution is proposed. On the MAC layer, we propose to use the grid-quorum system (Tseng et al., Computer Networks, 43(3):317–337, 2003) to serve as the underlying power-saving framework. On the network layer, we propose to find query paths based on the power cost incurred by grid quorums used by nodes along a path. We show how these two layers interwork with each other to support continuous queries in an energy-efficient way. A Cross Layer Routing Protocol for Multihop Cellular Networks We propose a cross-layer routing protocol for a Code Division Multiple Access (CDMA) Multihop Cellular Network (MCN). In designing the routing protocol for MCN, multiple constraints are imposed on intermediate relay node selection and end-to-end path selection. The constraints on relay nodes include willingness for cooperation, sufficient neighbourhood connectivity and the level of interference offered on the path. Path constraints include end-to-end throughput and end-to-end delay. A facile incentive mechanism is presented to motivate the cooperation between nodes in call forwarding. In addition, we present a route resilience scheme in the event of dynamic call dropping. In particular, a fast neighbour detection scheme for route resilience is proposed. Instead of using periodic HELLO messages as in traditional ad-hoc routing, the proposed neighbour detection scheme adopts an explicit handshake mechanism to reduce neighbour detection latency. We conclude the paper by demonstrating the superior performance of the proposed routing protocol compared with the other well known routing algorithms. TCP-Aware Call Admission Control in High Altitude Platforms Using Cross-Layer Design In this paper, a new cross-layer design is proposed employing the predictability of rain faded channels to guarantee QoS requirements in High Altitude Platform (HAP) networks. Both a centralized and a distributed scheme are proposed for call admission control of packet-switched HAP wireless networks using a cross-layer approach aiming at keeping the call dropping probability below a predefined threshold. In both schemes, a new call is accepted if there are sufficient resources for the ongoing calls and for the new one to guarantee their QoS requirements for their whole connection. The performance of the proposed schemes is investigated using markov chain analysis and bounds of the call blocking probability are determined analytically. Incentive mechanisms for trustworthy routing based on game model of the strategies of nodes in P2P networks The trustworthiness and security of routing in the existing Peer-to-Peer (P2P) networks can not be ensured because of the diversity of the strategies of P2P nodes. This paper firstly uses game theory to establish game model of the strategies and profits of various types of routing nodes. Then, two incentive mechanisms for the corresponding stages of P2P trustworthy routing are proposed, namely trust associated mechanism and trust compensated mechanism. Simulation results show that the incentive mechanisms proposed in this paper will encourage cooperation actions of good nodes and restrain malicious actions of bad nodes, which ensure the trustworthiness of routing consequently. Cross-layer Scheduling Algorithms for IEEE 802.16 Based Wireless Mesh Networks Wireless mesh network (WMN) is emerging as an important networking architecture for future wireless communications. The mesh mode supported in IEEE 802.16 protocol provides a TDMA solution for WMN, in which scheduling is an important issue. In this paper, we discuss the issues on how to satisfy a set of bandwidth requests in IEEE 802.16 WMNs using minimal radio resources (or solving minimal schedule length problem). In consideration of transmission overhead and adaptive modulation and coding (AMC), two cross-layer scheduling algorithms are proposed, namely max-transmission and priority-based algorithms. In particular, they are proposed based on a physical interference model, instead of a protocol interference model as suggested in the literature. For the priority-based algorithm, we study several priority criteria based on different cross-layer information. An iterative scheme for QoS traffic is introduced to guarantee fairness when traffic load exceeds the network capacity. Simulation results show that our algorithms outperform the existing schemes based on protocol model, and they also ensure better fairness among different nodes. An Intrusion Detection System based on evidence theory and Rough Set Theory In this paper, we propose a novel Intrusion Detection System (IDS) architecture utilizing both the evidence theory and Rough Set Theory (RST). Evidence theory is an effective tool in dealing with uncertainty question. It relies on the expert knowledge to provide evidences, needing the evidences to be independent, and this make it difficult in application. To solve this problem, a hybrid system of rough sets and evidence theory is proposed. Firstly, simplification are made based on Variable Precision Rough Set (VPRS) conditional entropy. Thus, the Basic Belief Assignment (BBA) for all evidences can be calculated. Secondly, Dempster’s rule of combination is used, and a decision-making is given. In the proposed approach, the difficulties in acquiring the BBAs are solved, the correlativity among the evidences is reduced and the subjectivity of evidences is weakened. An illustrative example in an intrusion detection shows that the two theories combination is feasible and effective. Cross-Layer QoS Scheduling for Layered Multicast Streaming in OFDMA Wireless Networks The conventional multicast scheme of wireless networks, though establishing a bandwidth-saving means for point-to-multipoint transmission, is very conservative by limiting the throughput of short-range communications. The multicast performance can be significantly improved if some low-rate users are pruned. In this paper, we investigate the subchannel assignment mechanism of multicast streaming services in the emerging WiMax/802.16e systems, where each multimedia stream is composed of a basic layer and an enhancement layer. The former affords a low-resolution video image to all the subscribers, while the latter only serves those with preferable channel states. Optimization frameworks are formulated to characterize the QoS requirements of multicast flows: pruned proportional rate ratio (PPRR), pruned stream rate guarantee (PSRG) and pruned user proportional fairness (PUPF). Three cross-layer algorithms are presented to perform channel assignment for different QoS requirements. Analytical study shows that the proposed algorithms have polynomial-time computational complexity. Numerical experiments validate that our proposals significantly outperform the conventional peer schedulers in terms of system throughput. CLEAR: A Cross-Layer Enhanced and Adaptive Routing Framework for Wireless Mesh Networks Wireless Mesh Networks (WMNs) provide a new and promising solution for broadband Internet services. The distinguishing features and the wide range of WMNs’ applications have attracted both academic and industrial communities. Routing protocols play a crucial role in the functionality and the performance of WMNs due to their direct effect on network throughput, connectivity, supported Quality of Service (QoS) levels, etc. In this paper, a cross-layer based routing framework for multi-interface/multi-channel WMNs, called Cross-Layer Enhanced and Adaptive Routing (CLEAR), is proposed. This framework embodies optimal as well as heuristic solutions. The major component of CLEAR is a new bio-inspired routing protocol called Birds’ Migration Routing protocol (BMR). BMR adopts a newly developed routing metric called Multi-Level Routing metric (MLR) to efficiently utilize the advantages of both multi-radio/multi-channel WMNs and cross-layer design. We also provide an exact solution based on dynamic programming to solve the optimal routing problem in WMNs. Simulation results show that our framework outperforms other routing schemes in terms of network throughput, end-to-end delay, and interference reduction, in addition to being the closest one to the optimal solution. The Japanese sense of information privacy We analyse the contention that privacy is an alien concept within Japanese society, put forward in various presentations of Japanese cultural norms at least as far back as Benedict in The chrysanthemum and the sword: patterns of Japanese culture. Houghton Mifflin, Boston, 1946. In this paper we distinguish between information privacy and physical privacy. As we show, there is good evidence for social norms of limits on the sharing and use of personal information (i.e. information privacy) from traditional interactions in Japanese society, as well as constitutional evidence from the late 19th century (in the Meiji Constitution of 1889). In this context the growing awareness of the Japanese public about problems with networked information processing by public sector and commercial organisations from the 1980s (when a law governing public sector use of personal information was first passed) to recent years (when that law was updated and a first law governing commercial use of personal information was adopted) are not the imposition or adoption of foreign practices nor solely an attempt to lead Japanese society into coherence with the rest of the OECD. Instead they are drawing on the experience of the rest of the developed world in developing legal responses to the breakdown of social norms governing interchange and use of personal information, stressed by the architectural changes wrought by networked information processing capabilities. This claim is supported by consideration of standard models of Japanese social interactions as well as of Supreme Court judgements declaring reasonable expectations of protection of privacy to hold in Japan. The impact of network and recency effects on the adoption of e-collaboration technologies in online communities This study investigates the impact that network and recency effects have on the adoption of e-collaboration technologies (ECT). The network effect is a widely documented phenomenon affecting the adoption of technology in the real world. However, its impact in virtual workspaces remains relatively underexplored. We know little about whether the observed network effect in offline settings also applies to online contexts. In this study we argue that co-membership is one of the most important mechanisms through which online social networks are built, and the network effect is salient for the adoption of ECT. We also document a recency effect with respect to ECT adoptions. Specifically, contrary to traditional wisdom, we find that recent adoptions, rather than more distant ones, are more powerful in affecting subsequent adoptions. Moreover, recent adoptions positively reinforce the impact of the network effect on subsequent adoptions. To illustrate theory and test hypotheses, we examine the adoption of the latest open source software (OSS) version control technology using a panel dataset obtained from SourceForge.net. By addressing the causality and heterogeneity issues between network structure and adoption decision, we show a more compelling connection between online social networks and technology adoption. Investigating the usability of real-time scheduling theory with the Cheddar project This article deals with real-time critical systems modelling and verification. Real-time scheduling theory provides algebraic methods and algorithms in order to make timing constraints verifications of these systems. Nevertheless, many industrial projects do not perform analysis with real-time scheduling theory even if demand for use of this theory is large and the industrial application field is wide (avionics, aerospace, automotive, autonomous systems, …). The Cheddar project investigates why real-time scheduling theory is not used and how its usability can be increased. The project was launched at the University of Brest in 2002. In Lecture Notes on Computer Sciences, vol. 5026, pp. 240–253, 2008, we have presented a short overview of this project. This article is an extended presentation of the Cheddar project, its contributions and also its ongoing works. Comparison of Conventional and Cross-Layer Multimedia Transport Schemes for Wireless Networks Three competing schemes have been proposed for multimedia transport over broadband wireless channels: (a) traditional UDP (Postel, The User Datagram Protocol, 1980 [1]), (b) semi-cross-layer UDP-Lite (The Lightweight User Datagram Protocol, 2004 [2]), and (c) cross-layer header estimation (Khayam et al., IEEE Transactions on Multimedia 9(2):377–385, 2007 [3]; Khayam and Radha, IEEE Transactions on Wireless Communications 6(11):3946–3954, 2007 [4]). In all these schemes, corrupted and lost packets are recovered using FEC at the application layer. In this paper, we analytically and experimentally compare the performances of these broadband wireless multimedia schemes. First, we derive lower bounds on the excepted FEC redundancy required by ideal cross-layer header estimation, UDP and UDP-Lite over an arbitrary-order Markov wireless channel. We show that under realistic wireless channel conditions, the cross-layer header estimation scheme always requires lesser redundancy than UDP and UDP-Lite. We then propose a practical minimum distance decoding (MDD) header estimation scheme, which is receiver-based, low complexity and highly accurate. Trace-driven multimedia experiments over wireless LANs demonstrate that MDD header estimation requires significantly lesser FEC redundancy and renders better video quality than existing schemes. Performance Optimization with Efficient Polling Mechanism in IEEE 802.16 Networks with Cross-Layer Consideration IEEE 802.16 standard suite defines a reservation-based bandwidth allocation mechanism. A SS (Subscriber Station) has to be polled to request bandwidth reservation before transmits uplink data to a BS (Base Station). In this mechanism exist two main polling modes: the unicast polling mode and the contention-based polling mode. The different polling operations in MAC (Medium Access Control) result in different PHY (PHYsical layer) frame structure that deeply affect the performance. Therefore, there should be an optimal scheme to adopt these two polling modes in order to optimize the performance. Although the standard defines five service classes to adaptively use the polling modes to fit the QoS (Quality of Service) requirements of different applications, it does not specify exactly a scheme to adopt these two polling modes efficiently and fairly during the polling process. In~this paper, we investigate the polling mechanisms in IEEE 802.16 networks, and focus the attention on the performance caused by different adoption schemes. We also propose a simple but efficient polling mechanism to optimize the performance. The simulation results verify that the performance is conditioned to the fulfillment of the polling mechanisms and our proposed optimal polling scheme can allocate bandwidth more efficient and achieve better performance. Assessment and optimization of e-commerce websites of fish culture sector Fishculture has been flourishing during the last decades in Greece and EU. Many enterprises in fishfarming sector have already proceeded in employing e-commerce and they have created their websites. This paper aims to assess websites of commercial purpose within fishculture sector and identify their optimum group. As a case study it was selected the paradigm of Greece. Qualitative and quantitative content characteristics were identified in the retrieved websites that were further ranked according to 13 content characteristics/criteria using the multicriteria method of PROMETHEE II. Finally, the retrieved websites were classified in groups, aiming to identify the optimum group of websites concerning content characteristics. The optimum group of fishculture websites will be a useful standard while designing for a fish culture enterprise aiming to initially or further expand their e-commerce activities.