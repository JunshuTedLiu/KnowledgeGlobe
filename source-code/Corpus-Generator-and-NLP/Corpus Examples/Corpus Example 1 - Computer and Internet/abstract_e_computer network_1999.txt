The SGF metadata framework and its support for social awareness on the World Wide Web The widespread use of metadata is transforming the WWW into an information space that can be accessed not only by humans, but also by software agents. In this article, one application for metadata is more closely examined: the description of Web sites structures in a machine understandable way. The Structured Graph Format (SGF) is introduced as an XML‐based format supporting the description of Web spaces as structured graphs. The SGF framework, built around this format specification, is then described. This integrated and extensible set of software components supports the generation, the distribution and the processing of SGF metadata. Three approaches to the problem of generating SGF metadata are compared and highlight a tradeoff between quality and cost. SGF consumers are then presented as components that process the metadata for some purpose. An SGF consumer that uses the metadata to dynamically generate interactive site maps is presented. The discussion then argues for the need to increase social awareness on the WWW. In other words, it raises the issue of monitoring the activity occurring within Web sites. The notion of awareness is first introduced and situated in the context of Computer Supported Cooperative Work (CSCW). Different ways to apply awareness to the WWW are then reviewed. Finally, the SGF framework is described as a valuable foundation for building awareness systems on the Web, with two main advantages. First, because SGF metadata supports the definition of regions within a Web site, at different granularities, it ensures the scalability of monitoring systems. It thus gives users of these systems a very flexible way to define regions of interest and to monitor activity in more meaningful ways. Second, the site maps generated on the basis of SGF metadata provide an efficient way to represent the activity occurring within the monitored site. These explicit representations, which are useful to analyze activity, are contrasted with abstract representations, which are useful to maintain peripheral awareness about ongoing activity on the Web. Agent-based Drivers’ Information Assistance System “Drivers’ Information Assistance System (DIA system)” is an ITS (Intelligent Transport Systems) application framework that provides agent-based information assistance to drivers through car navigation systems or on-board PCs.DIA system enables flexible information retrieval over the Internet using intelligent mobile agent, and incorporates a high-speed event delivery facility that makes real-time information service possible. The goal of the system is to provide up to the minute information and services related to driver needs, such as parking lot vacancy information. Crucial to making this a practical operation is the agent-based ability to access the network while the vehicle is in motion. A Comparison of Survey Data Collected by Regular Mail and Electronic Mail Questionnaires A survey was conducted by the National Council on Measurement in Education (NCME) to examine the telecommunications needs of the organization's membership. A component of this study permitted an examination of two response modalities (regular mail and e-mail) across a number of variables. Separate samples of 585 were drawn to take the survey. The first sample consisted of all those organization members who had registered their e-mail address with the organization while the second sample was randomly selected from those members who did not list an e-mail address. The first group was sent a nine question instrument via e-mail while the second group was asked to fill out a ten question instrument via regular mail. Overall response rates were low and significantly different [30% for the e-mail group and 36% for the regular mail group, χ2 (1) = 10.42, p < .01], though not uncommon for institutional surveys. Individual item response rates, however, were statistically significantly higher for the e-mail group across a number of dimensions. The results suggest that for some organizations, e-mail questionnaires may be a viable mechanism for conducting surveys. Suggestions are made on how to improve overall response rates. New Heuristics for the Multidimensional Vote Assignment Problem .Vote assignments are being used for the design of fault tolerant systems. They work in such a way that every node in a computer network gets assigned a certain number of votes. Furthermore, a quorum is defined. A transaction can only take place if the number of votes collected is greater than or equal to the quorum. These single dimensional vote assignments provide a compact representation of certain antichains, namely those which consist of the minimal sets of nodes achieving the quorum. Multidimensional (MD) vote assignments are a generalization of single dimensional vote assignments. In contrast to single dimensional vote assignments, MD vote assignments have the important property that every antichain has a corresponding MD vote assignment and vice versa. For the efficient design of fault tolerant systems, it is important that the dimension of a MD vote assignment is as small as possible. We introduce some new heuristics for calculating a MD vote assignment which perform better than the heuristics known so far. Media Production: Towards Creative Collaboration Using Communication Networks To examine the diffusion of remote collaboration technologies within the media production industries, a series of case studies was recently conducted with early adopters of advanced electronic networks in Sydney, Los Angeles and London. The studies assessed: 1) user reactions to these collaboration technologies and types of activities being supported and 2) factors influencing their adoption decisions. Interviews conducted also provided early indications of the conditions likely to facilitate remote collaboration and the likely impacts on work practices in media production organizations. It was established that electronic delivery, remote access to resources and materials, and remote creative collaboration were all being carried out, even internationally. Although most network applications were routine substitutions for non-electronic equivalents (e.g. couriers or catalogue browsing), some did involve shared creative activities, thus confirming that remote creative collaboration is a viable option. Key factors influencing network adoption were cost considerations and regulatory issues, time savings and productivity, and security concerns. Certain industry segments -- animation, post-production, and advertising -- were more likely to be early adopters, as were companies who found innovative ways to achieve greater benefits. Conditions likely to facilitate remote collaboration include more sophisticated change-agent strategies, increasing the perceived control of creative outputs, developing and maintaining trust, providing more auxiliary support for coordination needs, and making more effective use of timing and time-zone differences. Likely impacts of remote collaboration in media production are: more overlap between pre-production, production, and post-production activities; faster work pace; enhanced creativity; and improved quality of work life. The structure of rights in Directive 95/46/EC on the protection of individuals with regard to the processing of personal data and the free movement of such data The paper has three parts. First, a survey and analysis is given ofthe structure of individual rights in the recent EU Directive ondata protection. It is argued that at the core of this structure isan unexplicated notion of what the data subject can `reasonablyexpect' concerning the further processing of information about himor herself. In the second part of the paper it is argued thattheories of privacy popular among philosophers are not able to shed much light on the issues treated in the Directive, whichare, arguably, among the central problems pertaining to theprotection of individual rights in the information society. Inthe third part of the paper, some suggestions are made for a richerphilosophical theory of data protection and privacy. It is arguedthat this account is better suited to the task of characterizingthe central issues raised by the Directive. Wavelength-Conversion-Based Protocols for Single-Hop Photonic Networks with Bursty Traffic WDM star networks using fixed lasers and tunable optical filters are favored by the current state-of-the-art in technology over the other WDM star architectural forms. However, networks of this architectural form suffer from low efficiency when the offered traffic is bursty. Under bursty traffic conditions, it is probable that some wavelengths are idle, while some other wavelengths are overloaded. Therefore, the overall network performance is degraded. In this paper, a new MAC protocol which is capable of operating efficiently under bursty traffic conditions is introduced. According to the proposed protocol an array of tunable wavelength converters is placed at the network hub in order to uniformly distribute the incoming packets to the available wavelengths. In this way, the load is balanced between the wavelengths and consequently, the network performance is improved. The performance of the proposed protocol is studied via analytical and simulation results which indicate that a WDM Star network operating under this protocol achieves a high throughput-delay performance under both bursty and non-bursty traffic conditions. Throughput performance of distributed applications in switched networks in presence of end‐system bottlenecks The steady state throughput performance of distributed applications deployed in switched networks in presence of end‐system bottlenecks is studied in this paper. The effect of various limitations at an end‐system is modelled as an equivalent transmission capacity limitation. A class of distributed applications is characterised by a static traffic distribution matrix that determines the communication between various components of the application. It is found that uniqueness of steady state throughputs depends only on the traffic distribution matrix and that some applications (e.g., broadcast applications) can yield non‐unique values for the steady state component throughputs. For a given switch capacity, with traffic distribution that yield fair unique throughputs, the trade‐off between the end‐system capacity and the number of application components is brought out. With a proposed distributed rate control, it has been illustrated that it is possible to have unique solution for certain traffic distributions which is otherwise impossible. Also, by proper selection of rate control parameters, various throughput performance objectives can be realised. Authoring SMIL documents by direct manipulations during presentation This paper presents Smil‐Editor – an authoring environment to write multimedia documents encoded in SMIL. The main feature of Smil‐Editor is to strongly integrate the presentation view, in which the document is executed, with the editing process. In this view objects can be selected to perform a wide set of editing actions ranging from attributes setting to direct spatial or temporal editions. This way of editing a multimedia document is close to the well‐known WYSIWYG paradigm used by usual word‐processors. Moreover, in order to help the author to specify the temporal organisation of documents, Smil‐Editor provides an execution report displayed through a timeline view. This view also contains information which helps the author to understand why such execution occurred. These multiple and synchronised views aim at covering the various needs for authoring multimedia documents. Is geographical proximity necessary in the innovation networks in the era of global economy? In the analysis of geographical spillovers, a commonly accepted hypothesis is that the different actors of innovation need to be physically closed to one another because the transfer of tacit knowledge implies frequent face-to-face relations. This hypothesis is put under closer examination in this paper. The first section analyses the need for economic agents to be closely located to develop research and innovative activities, starting with the analysis of their need for co-ordination and using some case studies. Based on the example of three French regions, the second section examines the importance given by the local development policies to geographical proximity in order to support the rapid development of local networks favouring innovation. In both sections, nonlocal relations appear as a key factor to develop innovation. As a conclusion, nonlocal relations should be encouraged by local development policies in the same way as local relations. Instructional uses of the WWW: An evaluation tool The development of the World Wide Web (WWW) and the subsequent introduction of different browsers, with their extensions, has changed the Internet from a text‐only communications tool to a powerful multimedia platform whose potential applications are increasing day by day. Research efforts in the computer aided education field are represented by a broad spectrum of applications, from the virtual classroom to remote courses. In these environments, visualising the progress of students in a certain course is an important part of the learning process. At the Universidad Politecnica de Valencia we are experimenting with WWW based software tools and networks for computer aided learning. This research process has resulted in the development of a teacher's authoring tool and an evaluation application; both developed using Java and based on Internet browsers. With this evaluation tool, teachers can easily create questions of different types – which are stored on a database. These questions can later be used to compose different exams or exercises for different students depending on the course and the objective of the examinations. The advantages include an improvement in the fulfillment of the teacher's duties; an increase in the responsiveness of the exam results to the level of student understanding; and the potential for using the application in distance learning and training. Knowledge as a Social Medium The increasing popularity and access to computer networks such as the Internet has introduced a new form of interaction among individuals, and brought about the social dimension to intelligent systems that are embedded into group and community settings. Knowledge is now seen as an asset not only of an individual but also of groups; research fields such as organisational memory, knowledge management and community ware are beginning to emerge. This paper surveys recent approaches, discusses whether social knowledge is a tangible notion, and examines the role of social knowledge in the context of group and community oriented systems with new challenges it offers. Experience with adaptive mobile applications in Odyssey In this paper, we present our experience with application-aware adaptation in the context of Odyssey, a platform for mobile data access. We describe three applications that we have modified to run on Odyssey – a video player, a Web browser, and a speech recognition system. Our experience indicates that it is relatively simple to incorporate applications into Odyssey, and that application source code is not always essential. Although our applications were built without knowledge of each other, Odyssey is able to run them concurrently without interference. However, our experience also exposes important areas of future work. Specifically, it reveals the difficulty of balancing agility with stability in adaptation, and emphasizes the need for controlled exposure of internal Odyssey state to users. Performance of Single-Hop WDM LANs Supporting Real-Time Services Optical wavelength division multiplexing (WDM) local area networks are capable of fulfilling the enormous bandwidth demands of present and future applications. Up to now, the WDM LAN world is primarily dominated by the passive-star coupler (PSC) based architectures, for which many medium access control (MAC) protocols have been proposed. However, an arrayed waveguide grating multiplexer (AWGM)-based single-hop WDM network seems to be a very promising alternative. One of the most critical issues in designing next generation photonic LANs is the support of real-time services for applications with different time constraints. In this paper, different basic access protocols for the PSC as well as AWGM-based single-hop WDM LANs are considered and their performance in supporting real-time traffic is analyzed by means of extensive computer simulations. For evaluation of real-time performance, packet drop rates and deadline missing rates are taken as performance measures. Furthermore, new real-time message scheduling schemes are proposed which improve the performance of protocols accommodating mixed traffic. They can be differentiated between message scheduling at the source nodes’ transmit queues and scheduling based upon control information from a control channel. It is shown that both types of priority scheduling significantly improve the overall real-time performance. A trace-based evaluation of adaptive error correction for a wireless local area network Wireless transmissions are highly susceptible to noise and interference. As a result, the error characteristics of a wireless link may vary widely depending on environmental factors such as location of the communicating systems and activity of competing radiation sources, making error control a difficult task. In this paper we evaluate error control strategies for a wireless LAN. Based on low-level packet traces of WaveLAN, we first show that forward error correction (FEC) is effective in recovering from bit corruptions and that packet length adjustment can reduce packet truncation. However, as expected, fixed error control policies can perform very poorly, because they either introduce too much overhead in “good” environments or are not aggressive enough in “bad” environments. We address this problem through adaptive error control, i.e., error control policies that adapt the degree of FEC redundancy and the packet size to the environment. The effectiveness of adaptive error control depends on the characteristics of the error environment, e.g., the type of errors and the frequency with which the error environment changes. Our evaluation shows that adaptive error control can improve throughput consistently across a wide range of wireless LAN error environments. The reason for this effectiveness is that changes in the error environment are often caused by human mobility-related events such as the motion of a cordless phone, which take place over seconds, while adaptation protocols can respond in tens of milliseconds. Evaluating adaptive error control in a wireless environments is challenging because repeatable experiments are difficult: the wireless environment cannot easily be isolated and the adaptation process itself changes the environment, which may make trace-based evaluation difficult. We introduce a trace-based evaluation methodology that deals appropriately with changes in packet content and size. Using the Concept of Intelligent Agents in Fault Management of Distributed Services This paper proposes the application of conceptsfrom the area of intelligent agents to overcomedeficiencies of existing management architecturesregarding distribution of functionality and flexibility. Its main contribution is the proposal of amethodology for a flexible, distributed realization ofcomplex management tasks. The main application areas aredistributed services which are complex pieces of software, distributed across variousheterogeneous end systems in a network. Mostly, theyrely on the provision of other services as well. Theapproach relies on well-known concepts, such ascooperative distributed problem solving and intelligentagents, and offers a framework to combine these twoconcepts, providing a step on the roadmap to a flexible,distributed management architecture. The assessment of the approach is displayed throughout thepaper by scenarios from the area of nontime criticalfault management. ConData: A Tool for Automating Specification-Based Test Case Generation for Communication Systems This paper describes a tool called ConData used as test generation for communication protocols specified as extended finite state machines. The strategy for test generation combines different specification-based test methods: (i) transition testing for the control part of a protocol and (ii) syntax and equivalence partitioning for the data part. The tool uses a representation of the protocol in PSL (Protocol Specification Language), which is transformed into a format readable by a Prolog program. This implements the test strategies mentioned above. The text also presents some results obtained in the test generation for the protocol of the Tele-command Communication System of the SACI-1 satellite. An integrated GA–LP approach to communication network design In this paper we demonstrate success with an implementation of a genetic algorithm, integrated with linear programming, for solving a minimum cost network synthesis problem. The problem is formulated to include a number of practical constraints and the technique applied to moderately large networks (50 nodes). The associated linear program may be large but successful methods have been developed with very small population sizes for the genetic algorithm. The impact of self-similar traffic on network delay The effect of self-similar traffic on the delay of a single queue system is studied through the use of the measured traffic and models as input process. A model-driven simulation-based method is then proposed for the computation of mean line delay in a network design. Both the hybrid-FGN and the FARIMA algorithms have been used to synthesize self-similar sample paths. The comparison results with real-traffic data sets firmly establish the usefulness of the proposed model-driven simulation-based method. A practical database method is also introduced that helps the designer to determine the parameters in network design. This approach may play an important role in network design and analysis. A Multimedia World Wide Web Based Conference Minute System for Group Collaboration In this paper, we propose a World Wide Web based conference minute system which preserves important information in the conference as web documents and maintains hyperlinks to related minutes to accelerate the progress of the project. This system, based on our Java application sharing framework, provides capabilities to record and replay the audio/video data of the video conference and operations of the shared applications used in the meeting in a synchronous manner. Through the hyperlinks, people can quickly understand the logic flow of every meeting held in the project duration and select any part in a meeting for replay to know what has actually happened. Furthermore, when a new meeting is held, a minute template is generated by the system to inherit the hyperlinks from its predecessors. Other related minutes and the execution status of the resolutions in the project can be easily accessed through the hyperlinks between them. Through the help of the system, execution of the project and management of its organizational memory could be easily achieved to increase the productivity of the collaborative groups with geographically dispersed members. ACS: An adaptive communication system for heterogeneous wide-area ATM clusters This paper presents an architecture, implementation, and performance evaluation of an adaptive message-passing system for a heterogeneous wide-area ATM cluster that we call the Adaptive Communication System (ACS). ACS uses multithreading to provide efficient techniques for overlapping computation and communication in wide-area computing. By separating control and data activities, ACS eliminates unnecessary control transfers over the data path. This optimizes the data path and improves the performance. ACS supports several different flow control algorithms, error control algorithms, and multicasting algorithms. Furthermore, ACS allows programmers to select at runtime the suitable communication schemes per-connection basis to meet the requirements of a given application. ACS provides three application communication interfaces: Socket Communication Interface (SCI), ATM Communication Interface (ACI), and High Performance Interface (HPI) to support various classes of applications. The SCI is provided mainly for applications that must be portable to many different computing platforms. The ACI provides services that are compatible with ATM connection oriented services where each connection can be configured to meet the Quality of Service (QOS) requirements of that connection. This allows programmers to fully utilize the benefits of the ATM network. The HPI supports applications that demand low-latency and high-throughput communication services. In this interface, ACS uses read/write trap routines to reduce latency and data transfer time, and to avoid using traditional communication protocols. We analyze and compare the performance of ACS with those of other message-passing systems such as p4, PVM, and MPI in terms of point-to-point, multicasting, and application performance. The benchmarking results show that ACS outperforms other message-passing systems and provides flexible communication services for various classes of applications. Applying packet techniques to cellular radio The cell size in mobile networks is decreasing to accommodate more users in the same bandwidth. Smaller cell sizes increase the number of handoffs between cells and the probability of encountering a cell with more users than the bandwidth can accommodate. Stateless packet techniques, such as those used in Internet routers, can reduce the work that is performed in a handoff and reduce the probability of losing a connection in an overpopulated cell. In order to obtain these advantages, the mobile network must consist of both a wired and a wireless segment and different packet techniques must be used for the inbound and outbound traffic on each of these segments. A fifth packet technique is used for a control channel that is independent of a mobile unit's location. The resultant packet network has unique characteristics and requirements. We will show how these characteristics affect the structure of the wired network and the access protocols that are used in the wireless network. Performance of Carrier Sense Multiple Access with Collision Avoidance Protocols in Wireless LANs The performance of Carrier Sense Multiple Access/Collision Avoidance (CSMA/CA) protocols, which is adopted as a draft standard in IEEE 802.11, is analyzed in the view of throughput and packet delay. We consider three kinds of CSMA/CA protocols, which include Basic, Stop-and-Wait and 4-Way Handshake CSMA/CA, and introduce a theoretical analysis for them. First, we consider that a network consists of a finite population and then expand to an infinite population model. We model the CSMA/CA protocol as a hybrid protocol of a 1-persistent CSMA and a p-persistent CSMA protocol. We calculate the throughput and packet delay for three kinds of CSMA/CA protocols and verify analytical results by computer simulation. We have found that 4-Way Handshake CSMA/CA shows better performance than those of other two type CSMA/CA in high traffic load and analytical results are very close to simulation ones. Bound analysis for WRR scheduling in a statistical multiplexer with bursty sources Among various cell scheduling schemes for ATM networks, weighted round‐robin (WRR) seems a promising algorithm for explicit bandwidth allocation [15]. In this paper, we present a method for analyzing a discrete‐time queueing model of a statistical multiplexer with contiguous slot assignments, deterministic vacations, and bursty input sources, which serves as a bound analysis for WRR scheduling in ATM networks. Similar models have been studied as well in the context of TDMA (time division multiple access) schemes with multiple contiguous slots assigned per frame [3,16]. For the model under study, after establishing an expression for the probability generating function (pgf) of the system contents, we derive closed‐form expressions for performance measures such as the expected value, and an asymptotic approximation for the tail probabilities of the system contents distribution. Also, after examining the cell delay, we formulate the pgf of the cell delay in a closed form in terms of the system contents pgf. The numerical results obtained for the system contents and cell delay distributions illustrate that they match with simulation results extremely well, especially in the low probability area. We also discuss the impact of the slot assignment cycle of WRR on the system performance. Simulation‐based results of weighted fair queuing algorithms for ATM networks The behavior of the ideal General Processor Sharing (GPS) discipline and different per‐VC queuing algorithms approximating this ideal scheme, namely the Self Clocked Fair Queuing, the Packet by Packet Generalized Processor Sharing, and the Virtual Starting Time disciplines, are studied in this paper via simulation. We specifically consider a simple simulation configuration involving two Constant Bit rate (CBR) connections and several ON/OFF connections (bursty traffic). This simple simulation experiment allows us to point out three important features of the GPS and approximating disciplines. First, by adequately choosing the weight coefficients, these scheduling schemes can offer to CBR traffic almost Head of Line (HOL) priority over ON/OFF connections, to each of which, nevertheless, a minimum bandwidth is guaranteed. Second, GPS and per‐VC queuing disciplines, like the simple FIFO scheme, is very sensitive to burst scale congestion phenomena. Finally, simulation results seem to indicate that the scheduling disciplines considered perform traffic shaping on ON/OFF connections, which drastically reduces the burstiness of output traffic. Performance evaluation of the rate‐based flow control mechanism for ABR service In this paper we investigate the performances of the EFCI‐based (Explicit Forward Congestion Indication) and ER‐based (Explicit Rate) algorithms for the rate‐based flow control of the ABR (Available Bit Rate) traffic in an ATM network. We consider the case of two switches in tandem. We present several definitions of a bottleneck, and provide conditions that determine whether the first, the second or both queues are bottleneck. We show that it is not necessarily the queue with the slowest transmission rate in which congestion actually occurs. We derive analytic formulas for the maximum queue length. We compare our results to those obtained by approximating a network by a simpler one, containing only the bottleneck switch. We show that the maximum queue lengths under the approximating approach may largely underestimate the ones obtained in the real network. KWM: Knowledge-based Workflow Model for Agile Organization The workflow management system (WFMS) in an agile organization should be highly adaptable to the frequent organizational changes. To increase the adaptability of contemporary WFMSs, a mechanism for managing changes within the organizational structure and changes in business rules needs to be reinforced. In this paper, a knowledge-based approach for workflow modeling is proposed, in which a workflow is defined as a set of business rules. Knowledge on the organizational structure and special workflow, such as role/actor mappings and complex routing rules, can be explicitly modeled in KWM (Knowledge-based Workflow Model). Using knowledge representation scheme and dependency management facility, a change propagation mechanism is provided to adapt to the frequent changes in the organizational structure, business rules, and procedures. Fuzzy generalized network approach for solving an optimization model for routing in B‐ISDN Routing algorithms are required to guarantee the various quality of service (QoS) characteristics requested by the wide range of applications supported by Broadband Integrated Services Digital Networks (B‐ISDN). In this paper the routing problem is formulated as a fuzzy multiobjective optimization model. The fuzzy approach allows for the inclusion and evaluation of several criteria simultaneously. The proposed model takes into consideration the balancing of the load in the network to avoid link saturation and hence the possibility of congestion. A hybrid approach that combines the generalized network concept with the technique of fuzzy programming is recommended to solve the model. The efficiency and applicability of the model is tested under different load conditions by studying several measures of performance. An improvement of GNY logic for the reflection attacks In this paper, the limitation of the GNY logic about its inability to detect the reflection attacks against some authentication protocols is given. An improvement is proposed which takes into account the possible multiple instances (principals) of the same identity in the model. Convergent technologies in distance learning delivery onConvergent technologies are beginning to make an impact on the delivery of learning material at a distance in the U.K. The author predicts that as course providers purchase more telematics equipment, two things will happen. First, as has been historically the case with the adoption of new technologies, costs of units will decrease as the user base increases. Second, and perhaps more important, users will discover and develop new and innovative techniques to exploit the capabilities of the technology. The only limits to innovation will be the imagination of the proponents of the new technologies. Time will reveal just how fast these developments occur An application‐ and management‐based approach to ATM scheduling Two frame‐based ATM scheduling strategies, Delayed Frame Queueing (DFQ) and Virtual Frame Queueing (VFQ), are described for real‐time network applications. Both strategies guarantee explicit upper bounds on delay and jitter on a per virtual connection (VC) basis without relying on per‐VC queueing. They also resolve the disadvantages often associated with other frame‐based schedulers. The DFQ scheduler employs Resource Management cells to enable work‐conserving forwarding at intermediate nodes while retaining the option for non‐work‐conserving forwarding at terminal nodes. This allows delay bounds to be uncoupled from jitter bounds. The VFQ scheduler requires no such overhead cell transmissions, but is more limited in its ability to uncouple these two types of bounds. ATM network simulation results indicate that both proposed disciplines offer favorable multiplexing performance in comparison to a well documented high performance service discipline. Finally, we contrast our proposal against the significant difficulties that alternative scheduling strategies based on bandwidth guarantees will face with regard to network management and network synthesis issues. Studies on algorithms for self-stabilizing communication protocols In this paper the algorithms for self-stabilizing communication protocols are studied. First some concepts and a formal method for describing the proposed algorithms are described, then an improved algorithm for achieving global states is presented. The study shows that the improved algorithm can be applied to obtain the global states in the case of a loss of cooperation of the different processes in the protocol, which can be used as a recovery point that will be used by the following recovery procedure. Thus, the improved algorithm can be used to self-stabilize a communication protocol. Meanwhile, a recovery algorithm for self-stabilizing communication protocols is presented. After a failure is detected, all processes can eventually know the error. The recovery algorithm uses the contextual information exchanged during the progress of the protocol and recorded on the stable memory. The proof of correctness and analysis of complexity for these algorithms have been made. The availability and efficiency of the algorithms have been verified by illustrating the example protocols. Finally, some conclusions and remarks are given. Robust Feedback Control of a Single Server Queueing System . This paper extends previous work of Ball et al. [BDKY] to control of a model of a simple queueing server. There are n queues of customers to be served by a single server who can service only one queue at a time. Each queue is subject to an unknown arrival rate, called a “disturbance” in accord with standard usage from H∞ theory. An H∞-type performance criterion is formulated. The resulting control problem has several novel features distinguishing it from the standard smooth case already studied in the control literature: the presence of constraining dynamics on the boundary of the state space to ensure the physical property that queue lengths remain nonnegative, and jump discontinuities in any nonconstant state-feedback law caused by the finiteness of the admissible control set (choice of queue to be served). We arrive at the solution to the appropriate Hamilton–Jacobi equation via an analogue of the stable invariant manifold for the associated Hamiltonian flow (as was done by van der Schaft for the smooth case) and relate this solution to the (lower) value of a restricted differential game, similar to that formulated by Soravia for problems without constraining dynamics. An additional example is included which shows that the projection dynamics used to maintain nonnegativity of the state variables must be handled carefully in more general models involving interactions among the different queues. Primary motivation comes from the application to traffic signal control. Other application areas, such as manufacturing systems and computer networks, are mentioned. Demand Priority Protocol simulation and evaluation A new network protocol (Demand Priority Protocol) environment can provide more satisfying service for different urgent transmission requests. In this paper, in order to provide guidance for the selection of environment of multimedia data transmission in Computer Supported Cooperative Work better, an object-oriented protocol specification language based on C++ is used to design a virtual environment of multiworkstation of computer cooperative work and to simulate execution of demand priority network protocol and then the performances of various transmission requests are analyzed. Finally, an evaluation of the demand priority LAN is given. An approach to concurrent TTCN test generation The basis of distributed system conformance testing is to test the conformance of each entity with its standard. This paper addresses the approach to entity conformance testing based on concurrent TTCN. First a preliminary framework for entity conformance testing is introduced and a specification model CEBE is presented. Then a test generation method, which could directly derive concurrent TTCN test suite from CEBE, is proposed. The life span of a specific topic on the web In this case study a first attempt was made to explore data on the Web for a certain period of time by using bibliometric methods for analysis. The period under investigation was between January 3, 1998 and June 7, 1998. An additional search was carried out on June 20, 1999. The terms used were “informetrics or, informetric”. The results show that substantial changes occurred to the “literature on the Web” on informetrics during this period. Three specific trends were observed: some documents disppeared, new ones were added and some underwent changes. Storage System and Multimedia: Classification and Extensions With the increasing processing speeds, there is a shift away from the paradigm of centralized, sequential storage systems towards distributed and network based storage systems. Further, with the new imaging and real time multimedia applications, it is becoming more than ever important to design powerful, efficient and scaleable I/O systems. In this paper, the requirements of storage subsystems in multimedia environment were presented. The storage system components relating to those requirements were analyzed. Current solutions were surveyed and classified. Then we proposed approaches to improve storage subsystem performance for multimedia. The first approach applies constrained layout currently used for single disk model to multi-disk system. The second calls for using a stripping unit that meets both media and storage system optimization criteria. The third uses a pool of buffers instead of single buffer per stream. Survivable Network Design: The State of the Art In the past few years the telecommunications industry has undergone significant changes. We are rapidly evolving to a state where audio/visual and data traffic is all provided on the same networks. Telecommunication companies are investing billions of dollars in the design and maintenance of telecommunication networks to provide the users with the better quality of service that they have begun to expect. Due to their high capacity, fiber optic cables have become the medium of choice in the deployment of such new networks worldwide. Such high capacities encourage telecommunication providers to create networks that are substantially more sparse than previous copper based networks. Unfortunately, with sparsity comes vulnerability to failure. Given the dependence on the varied services offered by the modern networks, the magnitudes of the investments involved and the costs of disasters it is only logical that researchers look at problems in survivable network design as an interesting research question. There have been a number of papers that have addressed these and other related issues. In this paper we try to classify the area of survivable network design and provide a classification scheme for the same. Arrow: A flexible architecture for an accounting and charging infrastructure in the Next Generation Internet Current pricing and charging methods for the Internet are not based on actual usage of this service, which leads to unfairness and more important, it does not deliver the right signals through financial incentives to network providers to upgrade critical links of their networks. The development of new multimedia applications and the convergence to an integrated services network will foster the tremendous growth of the Internet even more. With the Next Generation Internet not only technical services like bandwidth reservation will be introduced, but also new applications will emerge within the Internet.Charging the Internet in a fashion that provides feedback to users and providers has been proposed since the early '90s, however, only a few implementations and real-world examples are known today. This is due to subsidizing the Internet in its early stages and due to a technical development that did not care much about charging. With the recent redesign of the Internet protocol suite and discussions on multiple service classes in the Internet, architectures for charging and accounting have to be revisited, too.Economic models for the Internet cannot be tested fully and validated in non-real-world environments, because of the unknown user behavior. With this uncertainty over what models and pricing schemes to choose, it is evident that a specific charging and accounting platform will never be accepted by the community. In this paper a novel and flexible architecture for charging and accounting is proposed that provides a wide range of mechanisms and lets researchers experiment in an environment as close as possible to the targeted system. As a first step, four different pricing schemes are described, qualitatively assessed on the proposed platform, and a prototypical implementation performed. One of the economic models that have been implemented on Arrow is based on different service classes including reservation and recalculates prices dynamically depending on the traffic situation. An Automated Document Filing System TEXPROS (TEXt PROcessing System) is an automatic document processing system which supports text-based information representation and manipulation, conveying meanings from stored information within office document texts. A dual modeling approach is employed to describe office documents and support document search and retrieval. The frame templates for representing document classes are organized to form a document type hierarchy. Based on its document type, the synopsis of a document is extracted to form its corresponding frame instance. According to the user predefined criteria, these frame instances are stored in different folders, which are organized as a folder organization (i.e., repository of frame instances associated with their documents). The concept of linking folders establishes filing paths for automatically filing documents in the folder organization. By integrating document type hierarchy and folder organization, the dual modeling approach provides efficient frame instance access by limiting the searches to those frame instances of a document type within those folders which appear to be the most similar to the corresponding queries.This paper presents an agent-based document filing system using folder organization. A storage architecture is presented to incorporate the document type hierarchy, folder organization and original document storage into a three-level storage system. This folder organization supports effective filing strategy and allows rapid frame instance searches by confining the search to the actual predicate-driven retrieval method. A predicate specification is proposed for specifying criteria on filing paths in terms of user predefined predicates for governing the document filing. A method for evaluating whether a given frame instance satisfies the criteria of a filing path is presented. The basic operations for constructing and reorganizing a folder organization are proposed. Intensive Data Management in Parallel Systems: A Survey In this paper we identify and discuss issues that are relevant to the design and usage of databases handling massive amounts of data in parallel environments. The issues that are tackled include the placement of the data in the memory, file systems, concurrent access to data, effects on query processing, and the implications of specific machine architectures. Since not all parameters are tractable in rigorous analysis, results of performance and bench-marking studies are highlighted for several systems. MPEG-4 Video and Image Coding on Digital Signal Processors The emerging MPEG-4 standard encompasses a wide variety of applications, many of which are suitable for implementation on a Digital Signal Processor (DSP). In particular, consumer products with embedded multimedia capability, such as set-top boxes and wireless communicators, are suitable for DSP-based implementation. With a programmable approach, various algorithmic tradeoffs can be made, based on processing capability. For best performance, careful attention must be paid to memory allocation, data transfer, and ordering of instructions to best match the DSP architecture. We discuss implementing simple profile MPEG-4 video on the low-power TMS320C54x, core profile on the TMS320C6x, and scalable texture profile, which could be implemented on either processor family. Necessary and sufficient optimality conditions of a design decision on the structure of a local computer network A problem of nonlinear programming with Boolean variables is considered, for which the possibility of extension of the optimality conditions of solving a special problem of nonlinear programming (with continuous variables) is shown by statistical estimation of possible design decisions. This contributed to the solution of the initial problem by simpler methods. Multifactor authentication as a protection mechanism in computer networks A direction of authentification is considered that is a component of the problem of creating mechanisms for information protection in computing systems (CS). The proposed mechanism of multifactor authentication makes it possible to increase the degree of security of authentication procedures in CS, which is especially important in practice. Simulation of Complete Binary Tree Structures in a Faulty Flexible Hypercube The Flexible Hypercube is a generalization of binary hypercube networks in that the number of nodes can be arbitrary in contrast to a strict power of 2. Restated, the Flexible Hypercube retains the connectivity and diameter properties of the corresponding hypercube. Although the embedding of complete binary trees in faulty hypercubes has received considerable attention, to our knowledge, no paper has demonstrated how to embed a complete binary tree in a faulty Flexible Hypercube. Therefore, this investigation presents a novel algorithm to facilitate the embedding job when the Flexible Hypercube contains faulty nodes. Of particular concern are the network structures of the Flexible Hypercube that balance the load before as well as after faults start to degrade the performance of the Flexible Hypercube. Furthermore, to obtain the replaceable node of the faulty node, 2-expansion is permitted such that up to (n − 2) faults can be tolerated with congestion 1, dilation 4 and load 1. That is, (n − 1) is the dimension of a Flexible Hypercube. Results presented herein demonstrate that embedding methods are optimized. State and prospects of development of the national telecommunication network in the spheres of science and education The project of creating a modern computer network for Ukrainian educational and scientific institutions is considered, and analysis of the stage of development of this network is performed. The objectives and role of telecommunication networks with INTERNET access at the universities and research institutes of the National Academy of Sciences of Ukraine are shown. The resources of the base center and regional centers are analyzed, the topology and data transmission channels of the network are specified, and the prospects of development of the information infrastructure of the educational and scientific spheres are given. Self-Management Services For people with chronic illness, day-to-day responsibilities for care fall most heavily on patients and their families. Organising healthcare to strengthen and support self-management in chronic illness while assuring that effective medical, preventative and health maintenance interventions take place is key to effective disease management.This paper discusses the behavioural principles and empirical evidence about healthcare designed to maximise positive patient participation in chronic disease care. Four main essential elements are key: (i) collaborative definition of problems, in which patient-defined problems are identified along with medical problems diagnosed by physicians; (ii) targeting, goal-setting and planning, where patients and providers together agree on realistic objectives and set an action plan for attaining them; (iii) availability of a continuum of self-management training and support options that teach patients the skills needed to carry out medical regimens, guide health behaviour change and provide emotional support; (iv) active and sustained follow-up during which patients are contacted at specified intervals to monitor health status and reinforce progress in meeting care plan objectives. These elements constitute a common core of services and approaches that do not need to be replicated for each chronic condition. The effects of asymmetry on TCP performance In this paper, we study the effects of network asymmetry on end‐to‐end TCP performance and suggest techniques to improve it. The networks investigated in this study include a wireless cable modem network and a packet radio network, both of which can form an important part of a mobile ad hoc network. In recent literature (e.g., [18]), asymmetry has been considered in terms of a mismatch in bandwidths in the two directions of a data transfer. We generalize this notion of bandwidth asymmetry to other aspects of asymmetry, such as latency and media‐access, and packet error rate, which are common in wide‐area wireless networks. Using a combination of experiments on real networks and simulation, we analyze TCP performance in such networks where the throughput achieved is not solely a function of the link and traffic characteristics in the direction of data transfer (the forward direction), but depends significantly on the reverse direction as well. We focus on bandwidth and latency asymmetries, and propose and evaluate several techniques to improve end‐to‐end performance. These include techniques to decrease the rate of acknowledgments on the constrained reverse channel (ack congestion control and ack filtering), techniques to reduce source burstiness when acknowledgments are infrequent (TCP sender adaptation), and algorithms at the reverse bottleneck router to schedule data and acks differently from FIFO (acks‐first scheduling). Prospects for Optical Interconnects in Distributed, Shared-Memory Organized MIMD Architectures The antipodes of the class of sequential computers, executing tasks with a single CPU, are the parallel computers containing large numbers of computing nodes. In the shared-memory category, each node has direct access through a switching network to a memory bank, that can be composed of a single but large or multiple but medium sized memory configurations. Opposite to the first category are the distributed memory systems, where each node is given direct access to its own local memory section. Running a program in especially the latter category requires a mechanism that gives access to multiple address spaces, that is, one for each local memory. Transfer of data can only be done from one address space to another. Along with the two categories are the physically distributed, shared-memory systems, that allow the nodes to explore a single globally shared address space. All categories, the performances of which are subject to the way the computing nodes are linked, need either a direct or a switched interconnection network for inter-node communication purposes. Linking nodes and not taking into account the prerequisite of scalability in case of exploiting large numbers of them is not realistic, especially when the applied connection scheme must provide for fast and flexible communications at a reasonable cost. Different network topologies, varying from a single shared bus to a more complex elaboration of a fully connected scheme, and with them the corresponding intricate switching protocols have been extensively explored. A different vision is introduced concerning future prospects of an optically coupled distributed, shared-memory organized multiple-instruction, multiple-data system. In each cluster, an electrical crossbar looks after the interconnections between the nodes, the various memory modules and external I/O channels. The clusters itself are optically coupled through a free space oriented data distributing system. Analogies found in the design of the Convex SPP1000 substantiate the closeness to reality of such an architecture. Subsequently to the preceding introduction also an idealized picture of the fundamental properties of an optically based, fully connected, distributed, (virtual) shared-memory architecture is outlined. A Lagrangian Based Heuristic for the Design of Multipoint Linkages in a Communication Network with Unreliable Links and Node Outage Costs This paper studies the capacitated minimal spanning tree with unreliable links and node outage costs problem. Tree topologies appear in the design of centralized communication networks. In these topologies the number of nodes in a subtree rooted at the central node is limited to a predefined number due to polling, loading, and response time restrictions. The links in a communication network are prone to failure. Whenever a link in these networks fails all the terminal nodes connected to the central node through that link are unable to communicate till the faulty link is repaired. In some networks such failures can have adverse economic effect on the network user. The economic effect on the network user due to inability of a terminal to communicate with the central node due to link failure is called node outage cost. The sum of expected yearly node outage costs for a network depends on the topology of the network. In this paper we suggest a Lagrangean based heuristic to solve the integer programming formulation of the network topology problem. The objective of the problem is to minimize the sum of link costs and node outage costs. Our computational results on a set of test data with up to 80 nodes show that compared to the previously developed greedy heuristic, our method gives solution that are better by up to 6 percent. The gaps between our heuristic solutions and the lower bounds found as a byproduct of the solution procedure are in the 2–17 percent range.