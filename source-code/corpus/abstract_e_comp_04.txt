Analysis of oligonucleotide array experiments with repeated measures using mixed models BackgroundTwo or more factor mixed factorial experiments are becoming increasingly common in microarray data analysis. In this case study, the two factors are presence (Patients with Alzheimer's disease) or absence (Control) of the disease, and brain regions including olfactory bulb (OB) or cerebellum (CER). In the design considered in this manuscript, OB and CER are repeated measurements from the same subject and, hence, are correlated. It is critical to identify sources of variability in the analysis of oligonucleotide array experiments with repeated measures and correlations among data points have to be considered. In addition, multiple testing problems are more complicated in experiments with multi-level treatments or treatment combinations.ResultsIn this study we adopted a linear mixed model to analyze oligonucleotide array experiments with repeated measures. We first construct a generalized F test to select differentially expressed genes. The Benjamini and Hochberg (BH) procedure of controlling false discovery rate (FDR) at 5% was applied to the P values of the generalized F test. For those genes with significant generalized F test, we then categorize them based on whether the interaction terms were significant or not at the α-level (αnew= 0.0033) determined by the FDR procedure. Since simple effects may be examined for the genes with significant interaction effect, we adopt the protected Fisher's least significant difference test (LSD) procedure at the level of αnewto control the family-wise error rate (FWER) for each gene examined.ConclusionsA linear mixed model is appropriate for analysis of oligonucleotide array experiments with repeated measures. We constructed a generalized F test to select differentially expressed genes, and then applied a specific sequence of tests to identify factorial effects. This sequence of tests applied was designed to control for gene based FWER. A capacity scaling algorithm for M-convex submodular flow .This paper presents a faster algorithm for the M-convex submodular flow problem, which is a generalization of the minimum-cost flow problem with an M-convex cost function for the flow-boundary, where an M-convex function is a nonlinear nonseparable discrete convex function on integer points. The algorithm extends the capacity scaling approach for the submodular flow problem by Fleischer, Iwata and McCormick (2002) with the aid of a novel technique of changing the potential by solving maximum submodular flow problems. Audit of therapeutic interventions in inpatient children using two scores: are they evidence-based in developing countries? BackgroundThe evidence base of clinical interventions in paediatric hospitals of developing countries has not been formally assessed. We performed this study to determine the proportion of evidence-based therapeutic interventions in a paediatric referral hospital of a developing countryMethodsThe medical records of 167 patients admitted in one-month period were revised. Primary diagnosis and primary therapeutic interventions were determined for each patient. A systematic search was performed to assess the level of evidence for each intervention. Therapeutic interventions were classified using the Ellis score and the Oxford Centre for Evidence Based Medicine Levels of EvidenceResultsAny dehydration due to diarrhoea (59 cases) and pneumonia (42 cases) were the most frequent diagnoses. Based on Ellis score, level I evidence supported the primary therapeutic intervention in 21%, level II in 73% and level III in 6% cases. Using the Oxford classification 16%, 8%, 1% and 75% therapeutic interventions corresponded to grades A, B, C, and D recommendations, respectively. Overall, according to Ellis score, 94% interventions were evidence based. However, out of the total, 75% interventions were based on expert opinion or basic sciences. Most children with mild to moderate dehydration (52 cases) were inappropriately treated with slow intravenous fluids, and most children with non-complicated community acquired pneumonia (42 cases) received intravenous antibioticsConclusionsMost interventions were inappropriate, despite the availability of effective therapy for several of them. Diarrhoeal dehydration and community acquired pneumonia were the most common diagnoses and were inappropriately managed. Existing effective interventions for dehydration and pneumonia need to be put into practice at referral hospitals of developing countries. For the remaining problems, there is the need to conduct appropriate clinical studies. Caution must be taken when assigning the level of evidence supporting therapeutic interventions, as commonly used classifications may be misleading Gadolinium-enhanced small-animal TOF magnetic resonance angiography So far, magnetic resonance angiography (MRA) of rodents has only been performed by using time-of-flight (TOF) MRI techniques. This is because applications of first-passage contrast agents as in humans are hampered by pronounced physiologic differences (blood volume and heart beat rate). Here we describe the use of low-dose Gd-DOTA to enhance the performance of TOF MRA in rat brain. While no improvement in contrast was achieved, the measuring time could be reduced by almost a factor of three. This decrease in total acquisition time has been used to study the impact of a model of ligatured common carotid on the upper part of the blood system of the rat. Automatic Target Detection Using Wavelet Transform Automatic target recognition (ATR) involves processing images for detecting, classifying, and tracking targets embedded in a background scene. This paper presents an algorithm for detecting a specified set of target objects embedded in visual images for an ATR application. The developed algorithm employs a novel technique for automatically detecting man-made and non-man-made single, two, and multitargets from nontarget objects, located within a cluttered environment by evaluating nonoverlapping image blocks, where block-by-block comparison of wavelet cooccurrence feature is done. The results of the proposed algorithm are found to be satisfactory. Autonomous Mobile Robot That Can Read The ability to read would surely contribute to increased autonomy of mobile robots operating in the real world. The process seems fairly simple: the robot must be capable of acquiring an image of a message to read, extract the characters, and recognize them as symbols, characters, and words. Using an optical Character Recognition algorithm on a mobile robot however brings additional challenges: the robot has to control its position in the world and its pan-tilt-zoom camera to find textual messages to read, potentially having to compensate for its viewpoint of the message, and use the limited onboard processing capabilities to decode the message. The robot also has to deal with variations in lighting conditions. In this paper, we present our approach demonstrating that it is feasible for an autonomous mobile robot to read messages of specific colors and font in real-world conditions. We outline the constraints under which the approach works and present results obtained using a Pioneer 2 robot equipped with a Pentium 233 MHz and a Sony EVI-D30 pan-tilt-zoom camera. A Model-Selection-Based Self-Splitting Gaussian Mixture Learning with Application to Speaker Identification We propose a self-splitting Gaussian mixture learning (SGML) algorithm for Gaussian mixture modelling. The SGML algorithm is deterministic and is able to find an appropriate number of components of the Gaussian mixture model (GMM) based on a self-splitting validity measure, Bayesian information criterion (BIC). It starts with a single component in the feature space and splits adaptively during the learning process until the most appropriate number of components is found. The SGML algorithm also performs well in learning the GMM with a given component number. In our experiments on clustering of a synthetic data set and the text-independent speaker identification task, we have observed the ability of the SGML for model-based clustering and automatically determining the model complexity of the speaker GMMs for speaker identification. Subband-Based Group Delay Segmentation of Spontaneous Speech into Syllable-Like Units In the development of a syllable-centric automatic speech recognition (ASR) system, segmentation of the acoustic signal into syllabic units is an important stage. Although the short-term energy (STE) function contains useful information about syllable segment boundaries, it has to be processed before segment boundaries can be extracted. This paper presents a subband-based group delay approach to segment spontaneous speech into syllable-like units. This technique exploits the additive property of the Fourier transform phase and the deconvolution property of the cepstrum to smooth the STE function of the speech signal and make it suitable for syllable boundary detection. By treating the STE function as a magnitude spectrum of an arbitrary signal, a minimum-phase group delay function is derived. This group delay function is found to be a better representative of the STE function for syllable boundary detection. Although the group delay function derived from the STE function of the speech signal contains segment boundaries, the boundaries are difficult to determine in the context of long silences, semivowels, and fricatives. In this paper, these issues are specifically addressed and algorithms are developed to improve the segmentation performance. The speech signal is first passed through a bank of three filters, corresponding to three different spectral bands. The STE functions of these signals are computed. Using these three STE functions, three minimum-phase group delay functions are derived. By combining the evidence derived from these group delay functions, the syllable boundaries are detected. Further, a multiresolution-based technique is presented to overcome the problem of shift in segment boundaries during smoothing. Experiments carried out on the Switchboard and OGI-MLTS corpora show that the error in segmentation is at most 25 milliseconds for 67% and 76.6% of the syllable segments, respectively. Clustering under the line graph transformation: application to reaction network BackgroundMany real networks can be understood as two complementary networks with two kind of nodes. This is the case of metabolic networks where the first network has chemical compounds as nodes and the second one has nodes as reactions. In general, the second network may be related to the first one by a technique called line graph transformation (i.e., edges in an initial network are transformed into nodes). Recently, the main topological properties of the metabolic networks have been properly described by means of a hierarchical model. While the chemical compound network has been classified as hierarchical network, a detailed study of the chemical reaction network had not been carried out.ResultsWe have applied the line graph transformation to a hierarchical network and the degree-dependent clustering coefficient C(k) is calculated for the transformed network. C(k) indicates the probability that two nearest neighbours of a vertex of degree k are connected to each other. While C(k) follows the scaling law C(k) ~ k-1.1 for the initial hierarchical network, C(k) scales weakly as k0.08 for the transformed network. This theoretical prediction was compared with the experimental data of chemical reactions from the KEGG database finding a good agreement.ConclusionsThe weak scaling found for the transformed network indicates that the reaction network can be identified as a degree-independent clustering network. By using this result, the hierarchical classification of the reaction network is discussed. A database for G proteins and their interaction with GPCRs BackgroundG protein-coupled receptors (GPCRs) transduce signals from extracellular space into the cell, through their interaction with G proteins, which act as switches forming hetero-trimers composed of different subunits (α,β,γ). The α subunit of the G protein is responsible for the recognition of a given GPCR. Whereas specialised resources for GPCRs, and other groups of receptors, are already available, currently, there is no publicly available database focusing on G Proteins and containing information about their coupling specificity with their respective receptors.DescriptiongpDB is a publicly accessible G proteins/GPCRs relational database. Including species homologs, the database contains detailed information for 418 G protein monomers (272 Gα, 87 Gβ and 59 Gγ) and 2782 GPCRs sequences belonging to families with known coupling to G proteins. The GPCRs and the G proteins are classified according to a hierarchy of different classes, families and sub-families, based on extensive literature searchs. The main innovation besides the classification of both G proteins and GPCRs is the relational model of the database, describing the known coupling specificity of the GPCRs to their respective α subunit of G proteins, a unique feature not available in any other database. There is full sequence information with cross-references to publicly available databases, references to the literature concerning the coupling specificity and the dimerization of GPCRs and the user may submit advanced queries for text search. Furthermore, we provide a pattern search tool, an interface for running BLAST against the database and interconnectivity with PRED-TMR, PRED-GPCR and TMRPres2D.ConclusionsThe database will be very useful, for both experimentalists and bioinformaticians, for the study of G protein/GPCR interactions and for future development of predictive algorithms. It is available for academics, via a web browser at the URL: http://bioinformatics.biol.uoa.gr/gpDB Treatment of pregnancy-related pelvic girdle and/or low back pain after delivery design of a randomized clinical trial within a comprehensive prognostic cohort study [ISRCTN08477490] BackgroundPregnancy-related pelvic girdle and/or low back pain is a controversial syndrome because insight in etiology and prognosis is lacking. The controversy relates to factors eliciting pain and some prognostic factors such as the interpretation of pain at the symphysis. Recent research about treatment strategies also reflects those various opinions, in fact suggesting there is professional uncertainty about the optimal approach. Currently, physiotherapists often prescribe a pain-contingent treatment regime of relative rest and avoiding several day-to-day activities. Additionally, treatment more often includes an exercise program to guide rectification of the muscle imbalance and alignment of the pelvic girdle. Effectiveness of those interventions is not proven and the majority of the studies are methodologically flawed. Investigators draw particular attention to biomedical factors but there is growing evidence that important prognostic issues such as biopsychosocial factors appear to be even more important as point of action in a treatment program.Methods/designThis pragmatic randomized controlled trial is designed to evaluate the effectiveness of a tailor-made treatment program with respect to biopsychosocial factors in primary care. The effect of the experimental intervention and usual care are evaluated as they are applied in primary health care. The trial is embedded in a cohort study that is designed as a longitudinal, prospective study, which studies prevalence, etiology, severity and prognosis during pregnancy until one year after delivery. The present paper focuses on choices regarding recruitment procedures, in-/exclusion criteria and the development of a well-timed intervention.DiscussionThis section briefly discusses the actions taken to minimize bias in the design, the proper time-window for the experimental intervention and the contrast between the experimental intervention and usual care. Dynamic in vivo imaging and cell tracking using a histone fluorescent protein fusion in mice BackgroundAdvances in optical imaging modalities and the continued evolution of genetically-encoded fluorescent proteins are coming together to facilitate the study of cell behavior at high resolution in living organisms. As a result, imaging using autofluorescent protein reporters is gaining popularity in mouse transgenic and targeted mutagenesis applications.ResultsWe have used embryonic stem cell-mediated transgenesis to label cells at sub-cellular resolution in vivo, and to evaluate fusion of a human histone protein to green fluorescent protein for ubiquitous fluorescent labeling of nucleosomes in mice. To this end we have generated embryonic stem cells and a corresponding strain of mice that is viable and fertile and exhibits widespread chromatin-localized reporter expression. High levels of transgene expression are maintained in a constitutive manner. Viability and fertility of homozygous transgenic animals demonstrates that this reporter is developmentally neutral and does not interfere with mitosis or meiosis.ConclusionsUsing various optical imaging modalities including wide-field, spinning disc confocal, and laser scanning confocal and multiphoton excitation microscopy, we can identify cells in various stages of the cell cycle. We can identify cells in interphase, cells undergoing mitosis or cell death. We demonstrate that this histone fusion reporter allows the direct visualization of active chromatin in situ. Since this reporter segments three-dimensional space, it permits the visualization of individual cells within a population, and so facilitates tracking cell position over time. It is therefore attractive for use in multidimensional studies of in vivo cell behavior and cell fate. Considerations for the future development of virtual technology as a rehabilitation tool BackgroundVirtual environments (VE) are a powerful tool for various forms of rehabilitation. Coupling VE with high-speed networking [Tele-Immersion] that approaches speeds of 100 Gb/sec can greatly expand its influence in rehabilitation. Accordingly, these new networks will permit various peripherals attached to computers on this network to be connected and to act as fast as if connected to a local PC. This innovation may soon allow the development of previously unheard of networked rehabilitation systems. Rapid advances in this technology need to be coupled with an understanding of how human behavior is affected when immersed in the VE.MethodsThis paper will discuss various forms of VE that are currently available for rehabilitation. The characteristic of these new networks and examine how such networks might be used for extending the rehabilitation clinic to remote areas will be explained. In addition, we will present data from an immersive dynamic virtual environment united with motion of a posture platform to record biomechanical and physiological responses to combined visual, vestibular, and proprioceptive inputs. A 6 degree-of-freedom force plate provides measurements of moments exerted on the base of support. Kinematic data from the head, trunk, and lower limb was collected using 3-D video motion analysis.ResultsOur data suggest that when there is a confluence of meaningful inputs, neither vision, vestibular, or proprioceptive inputs are suppressed in healthy adults; the postural response is modulated by all existing sensory signals in a non-additive fashion. Individual perception of the sensory structure appears to be a significant component of the response to these protocols and underlies much of the observed response variability.ConclusionThe ability to provide new technology for rehabilitation services is emerging as an important option for clinicians and patients. The use of data mining software would help analyze the incoming data to provide both the patient and the therapist with evaluation of the current treatment and modifications needed for future therapies. Quantification of individual perceptual styles in the VE will support development of individualized treatment programs. The virtual environment can be a valuable tool for therapeutic interventions that require adaptation to complex, multimodal environments. Simulator sickness when performing gaze shifts within a wide field of view optic flow environment: preliminary evidence for using virtual reality in vestibular rehabilitation BackgroundWide field of view virtual environments offer some unique features that may be beneficial for use in vestibular rehabilitation. For one, optic flow information extracted from the periphery may be critical for recalibrating the sensory processes used by people with vestibular disorders. However, wide FOV devices also have been found to result in greater simulator sickness. Before a wide FOV device can be used in a clinical setting, its safety must be demonstrated.MethodsSymptoms of simulator sickness were recorded by 9 healthy adult subjects after they performed gaze shifting tasks to locate targets superimposed on an optic flow background. Subjects performed 8 trials of gaze shifting on each of the six separate visits.ResultsThe incidence of symptoms of simulator sickness while subjects performed gaze shifts in an optic flow environment was lower than the average reported incidence for flight simulators. The incidence was greater during the first visit compared with subsequent visits. Furthermore, the incidence showed an increasing trend over the 8 trials.ConclusionThe performance of head unrestrained gaze shifts in a wide FOV optic flow environment is tolerated well by healthy subjects. This finding provides rationale for testing these environments in people with vestibular disorders, and supports the concept of using wide FOV virtual reality for vestibular rehabilitation. Quality of life in spina bifida patients: results of an Italian survey  Early increases in plasminogen activator activity following partial hepatectomy in humans BackgroundIncreases in urokinase-like plasminogen activator (uPA) activity are reported to be amongst the earliest events occurring in remnant liver following partial hepatectomy in rats, and have been proposed as a key component of the regenerative response. Remodelling of the extracellular matrix, conversion of single chain hepatocyte growth factor to the active two-chain form and a possible activation of a mitogenic signalling pathway have all been ascribed to the increased uPA activity. The present study aimed to determine whether similar early increases in uPA activity could be detected in the remnant liver following resection of metastatic tumours in surgical patients.ResultsEighteen patients undergoing partial hepatectomy for the removal of hepatic metastases secondary to primary colonic tumours were studied. Increased plasminogen activator activity was found in the final liver samples for the group of patients in whom the resection size was at least 50%. For smaller resections, the increased activity was not observed. The increased activity did not correlate with the age of the patient or with the time between the start of resection and the end of the operation. There was, however, a negative correlation between plasminogen activator activity and the time for which blood supply to the liver was clamped.ConclusionsOur findings are in accordance with those from experimental animal models and show, for the first time, that rapid increases in plasminogen activator activity can occur following similarly large liver resection in humans. Thus, increases in plasminogen activator activity are an early event in the remnant liver following major liver resection in man. Our observations provide support for the contention that increases in plasminogen activators play a key role in the initiation of hepatic regeneration in man. Blind Channel Estimation for Space-Time Coded WCDMA A new blind channel estimation technique is proposed for space-time coded wideband CDMA systems using aperiodic and possibly multirate spreading codes. Using a decorrelating front end, the received signal is projected onto a subspace from which channel parameters can be estimated up to a rotational ambiguity. Exploiting the subspace structure of the WCDMA signaling and the orthogonality of the unitary space-time codes, the proposed algorithm provides a blind channel estimate via least squares. A new identifiability condition is established under the assumption that the system is not heavily loaded. The mean square error of the estimated channel is compared with the Cramér-Rao bound, and the bit error rate (BER) performance of the proposed algorithm is compared with that of differential schemes. Crest Factor Reduction in MC-CDMA Employing Carrier Interferometry Codes This paper addresses signal compactness issues in MC-CDMA employing carrier interferometry codes using the measure of crest factor (CF). Carrier interferometry codes, applied to-carrier MC-CDMA systems, enable users to simultaneously share the system bandwidth with minimal degradation in performance (relative to the-orthogonal-user case). First, for a fully loaded ( and users) MC-CDMA system with practical values of, it is shown that the CF in downlink transmission demonstrates desirable properties of low mean and low variance. The downlink CF degrades when the number of users in the system decreases. Next, the high CF observed in the uplink is characterized and the poor CF in a partially loaded downlink as well as uplink is effectively combated using Schroeder's analytical CF reduction techniques. Robust Downlink Power Control in Wireless Cellular Systems A serious shortcoming of current downlink power control methods is that their performance may be severely degraded when the downlink channel information is known imprecisely at the transmitter. In this paper, a computationally and implementationally simple centralized downlink power control method is proposed for cellular wireless communication systems using code division multiple access (CDMA) or space division multiple access (SDMA). Our method provides a substantially improved robustness against imperfect knowledge of the wireless channel by means of maintaining the required quality of service for the worst-case channel uncertainty. In the SDMA case, the proposed technique can be straightforwardly combined with any of the existing transmit beamforming methods. Simulation results validate substantial robustness improvements achieved by our approach. Editorial  Analysis of Multiuser MIMO Downlink Networks Using Linear Transmitter and Receivers In contrast to dirty-paper coding (DPC) which is largely information theoretic, this paper proposes a linear codec that can spatially multiplex the multiuser signals to realize the rich capacity of multiple-input multiple-output (MIMO) downlink broadcast (point-to-multipoint) channels when channel state information (CSI) is available at the transmitter. Assuming single-stream (or single-mode) communication for each user, we develop an iterative algorithm, which is stepwise optimal, to obtain the multiuser antenna weights accomplishing orthogonal space-division multiplexing (OSDM). The steady state solution has a straightforward interpretation and requires only maximal-ratio combiners (MRC) at the mobile stations to capture the optimized spatial modes. Our main contribution is that the proposed scheme can greatly reduce the processing complexity (at least by a factor of the number of base station antennas) while maintaining the same error performance when compared to a recently published OSDM method. Intensive computer simulations show that the proposed scheme promises to provide multiuser diversity in addition to user separation in the spatial domain so that both diversity and multiplexing can be obtained at the same time for multiuser scenario. Cochannel Interference Mitigation and Cooperative Processing in Downlink Multicell Multiuser MIMO Networks Recently, the remarkable capacity potential of multiple-input multiple-output (MIMO) wireless communication systems was unveiled. The predicted enormous capacity gain of MIMO is nonetheless significantly limited by cochannel interference (CCI) in realistic cellular environments. The previously proposed advanced receiver technique improves the system performance at the cost of increased receiver complexity, and the achieved system capacity is still significantly away from the interference-free capacity upper bound, especially in environments with strong CCI. In this paper, base station cooperative processing is explored to address the CCI mitigation problem in downlink multicell multiuser MIMO networks, and is shown to dramatically increase the capacity with strong CCI. Both information-theoretic dirty paper coding approach and several more practical joint transmission schemes are studied with pooled and practical per-base power constraints, respectively. Besides the CCI mitigation potential, other advantages of cooperative processing including the power gain, channel rank/conditioning advantage, and macrodiversity protection are also addressed. The potential of our proposed joint transmission schemes is verified with both heuristic and realistic cellular MIMO settings. Design of FIR Precoders and Equalizers for Broadband MIMO Wireless Channels with Power Constraints This paper examines the optimum design of FIR precoders or equalizers for multiple-input multiple-output (MIMO) frequency-selective wireless channels. For the case of a left-coprime FIR channel, which arises generically when the number of transmit antennas is larger than the number of receive antennas, the Bezout matrix identity can be employed to design an FIR MIMO precoder that equalizes exactly the channel at the transmitter. Similarly, for a right-coprime FIR channel, the Bezout identity yields an FIR zero-forcing MIMO equalizer. Unfortunately, Bezout precoders usually increase the transmit power, and Bezout equalizers tend to amplify the noise power. To overcome this problem, we describe in this paper a convex optimization technique for the optimal synthesis of MIMO FIR precoders subject to transmit power constraints, and of MIMO FIR equalizers with output noise power constraints. The synthesis problem reduces to the minimization of a quadratic objective function under convex quadratic inequality constraints, so it can be solved by employing Lagrangian duality. Instead of solving the primal problem, we solve the lower-dimensional dual problem for the Lagrange multipliers. When an FIR MIMO precoder has already been selected, we also describe a technique for adding a vector shaping sequence to the transmitted signal in order to reduce the transmit power. The selection of effective shaping sequences requires a search over a trellis of large dimensionality, which can be accomplished suboptimally by employing reduced-complexity search techniques. A Hybrid Approach to Spatial Multiplexing in Multiuser MIMO Downlinks In the downlink of a multiuser multiple-input multiple-output (MIMO) communication system, simultaneous transmission to several users requires joint optimization of the transmitted signals. Allowing all users to have multiple antennas adds an additional degree of complexity to the problem. In this paper, we examine the case where a single base station transmits to multiple users using linear processing (beamforming) at each of the antenna arrays. We propose generalizations of several previous iterative algorithms for multiuser transmit beamforming that allow multiple antennas and multiple data streams for each user, and that take into account imperfect channel estimates at the transmitter. We then present a new hybrid algorithm that is based on coordinated transmit-receive beamforming, and combines the strengths of nonorthogonal iterative solutions with zero-forcing solutions. The problem of distributing power among the subchannels is solved by using standard bit-loading algorithms combined with the subchannel gains resulting from the zero-forcing solution. The result is a significant performance improvement over equal power distribution. At the same time, the number of iterations required to compute the final solution is reduced. Intestinal parasites prevalence and related factors in school children, a western city sample-Turkey BackgroundIntestinal parasitic infections are amongst the most common infections worldwide. Epidemiological research carried out in different countries has shown that the social and economical situation of the individuals is an important cause in the prevalence of intestinal parasites. Previous studies in Turkey revealed a high prevalence of intestinal parasitic infection. The objectives of the current study were to determine the prevalence of intestinal parasitic infections in Aydin among 7–14 years old school children and to identify associated socio-demographic and environmental factors, behavioral habits and also related complaints.MethodsMultistage sampling was used in the selection of the study sample. A questionnaire, cellulose adhesive and a stool specimen examination were done.ResultsA total of 456 stool specimens were collected. 145 students (31.8%) were infected with one or more intestinal parasites. 29 (6.4%) of the students were infected more than one parasite, 26 (5.7%) with two parasites and 3 (0.7%) with three parasites. The three most common were E. vermicularis, G. intestinalis and E. coli. Intestinal parasite prevalence was higher in rural area, in children with less than primary school educated mother, in children who use hands for washing anal area after defecation, and in children who use toilet paper sometimes or never. The relation between child health and mother education is well known. Children were traditionally taught to wash anal area by hand. Toiler paper usage was not common and might be due to low income or just a behavioral habit also. Most of the complaints of the study population were not significantly related with the intestinal parasitic infection.ConclusionsIntestinal parasitic infection is an important public health problem in Aydin, Turkey. Rural residence, mother education less than primary school, sometimes or never usage of toilet paper, and washing anal area by hands after defecation were the significant associations. Interventions including health education on personal hygiene to the students and to the parents, especially to mothers are required. The ratio of uneducated women should be declined with specific programs. A multisectoral approach is needed. A genomic island present along the bacterial chromosome of the Parachlamydiaceae UWE25, an obligate amoebal endosymbiont, encodes a potentially functional F-like conjugative DNA transfer system BackgroundThe genome of Protochlamydia amoebophila UWE25, a Parachlamydia-related endosymbiont of free-living amoebae, was recently published, providing the opportunity to search for genomic islands (GIs).ResultsOn the residual cumulative G+C content curve, a G+C-rich 19-kb region was observed. This sequence is part of a 100-kb chromosome region, containing 100 highly co-oriented ORFs, flanked by two 17-bp direct repeats. Two identical gly-tRNA genes in tandem are present at the proximal end of this genetic element. Several mobility genes encoding transposases and bacteriophage-related proteins are located within this chromosome region. Thus, this region largely fulfills the criteria of GIs. The G+C content analysis shows that several modules compose this GI. Surprisingly, one of them encodes all genes essential for F-like conjugative DNA transfer (traF, traG, traH, traN, traU, traW, and trbC), involved in sex pilus retraction and mating pair stabilization, strongly suggesting that, similarly to the other F-like operons, the parachlamydial tra unit is devoted to DNA transfer. A close relatedness of this tra unit to F-like tra operons involved in conjugative transfer is confirmed by phylogenetic analyses performed on concatenated genes and gene order conservation. These analyses and that of gly-tRNA distribution in 140 GIs suggest a proteobacterial origin of the parachlamydial tra unit.ConclusionsA GI of the UWE25 chromosome encodes a potentially functional F-like DNA conjugative system. This is the first hint of a putative conjugative system in chlamydiae. Conjugation most probably occurs within free-living amoebae, that may contain hundreds of Parachlamydia bacteria tightly packed in vacuoles. Such a conjugative system might be involved in DNA transfer between internalized bacteria. Since this system is absent from the sequenced genomes of Chlamydiaceae, we hypothesize that it was acquired after the divergence between Parachlamydiaceae and Chlamydiaceae, when the Parachlamydia-related symbiont was an intracellular bacteria. It suggests that this heterologous DNA was acquired from a phylogenetically-distant bacteria sharing an amoebal vacuole. Since Parachlamydiaceae are emerging agents of pneumonia, this GI might be involved in pathogenicity. In future, conjugative systems might be developed as genetic tools for Chlamydiales. Computational prediction of human metabolic pathways from the complete human genome BackgroundWe present a computational pathway analysis of the human genome that assigns enzymes encoded therein to predicted metabolic pathways. Pathway assignments place genes in their larger biological context, and are a necessary first step toward quantitative modeling of metabolism.ResultsOur analysis assigns 2,709 human enzymes to 896 bioreactions; 622 of the enzymes are assigned roles in 135 predicted metabolic pathways. The predicted pathways closely match the known nutritional requirements of humans. This analysis identifies probable omissions in the human genome annotation in the form of 203 pathway holes (missing enzymes within the predicted pathways). We have identified putative genes to fill 25 of these holes. The predicted human metabolic map is described by a Pathway/Genome Database called HumanCyc, which is available at http://HumanCyc.org/. We describe the generation of HumanCyc, and present an analysis of the human metabolic map. For example, we compare the predicted human metabolic pathway complement to the pathways of Escherichia coli and Arabidopsis thaliana and identify 35 pathways that are shared among all three organisms.ConclusionsOur analysis elucidates a significant portion of the human metabolic map, and also indicates probable unidentified genes in the genome. HumanCyc provides a genome-based view of human nutrition that associates the essential dietary requirements of humans with a set of metabolic pathways whose existence is supported by the human genome. The database places many human genes in a pathway context, thereby facilitating analysis of gene expression, proteomics, and metabolomics datasets through a publicly available online tool called the Omics Viewer. Genome-scale approaches for discovering novel nonconventional splicing substrates of the Ire1 nuclease BackgroundThe unfolded protein response (UPR) allows intracellular feedback regulation that adjusts the protein-folding capacity of the endoplasmic reticulum (ER) according to need. The signal from the ER lumen is transmitted by the ER-transmembrane kinase Ire1, which upon activation displays a site-specific endoribonuclease activity. Endonucleolytic cleavage of the intron from the HAC1 mRNA (encoding a UPR-specific transcription factor) is the first step in a nonconventional mRNA splicing pathway; the released exons are then joined by tRNA ligase. Because only the spliced mRNA is translated, splicing is the key regulatory step of the UPR.ResultsWe developed methods to search for additional mRNA substrates of Ire1p in three independent lines of genome-wide analysis. These methods exploited the well characterized enzymology and genetics of the UPR and the yeast genome sequence in conjunction with microarray-based detection. Each method successfully identified HAC1 mRNA as a substrate according to three criteria: HAC1 mRNA is selectively cleaved in vitro by Ire1; the HAC1 mRNA sequence contains two predicted Ire1 cleavage sites; and HAC1 mRNA is selectively degraded in tRNA ligase mutant cells.ConclusionWithin the limits of detection, no other mRNA satisfies any of these criteria, suggesting that a unique nonconventional mRNA-processing mechanism has evolved solely for carrying out signal transduction between the ER and the nucleus. The approach described here, which combines biochemical and genetic 'fractionation' of mRNA with a novel application of cDNA microarrays, is generally applicable to the study of pathways in which RNA metabolism and alternative splicing have a regulatory role. An empirical analysis of training protocols for probabilistic gene finders BackgroundGeneralized hidden Markov models (GHMMs) appear to be approaching acceptance as a de facto standard for state-of-the-art ab initio gene finding, as evidenced by the recent proliferation of GHMM implementations. While prevailing methods for modeling and parsing genes using GHMMs have been described in the literature, little attention has been paid as of yet to their proper training. The few hints available in the literature together with anecdotal observations suggest that most practitioners perform maximum likelihood parameter estimation only at the local submodel level, and then attend to the optimization of global parameter structure using some form of ad hoc manual tuning of individual parameters.ResultsWe decided to investigate the utility of applying a more systematic optimization approach to the tuning of global parameter structure by implementing a global discriminative training procedure for our GHMM-based gene finder. Our results show that significant improvement in prediction accuracy can be achieved by this method.ConclusionsWe conclude that training of GHMM-based gene finders is best performed using some form of discriminative training rather than simple maximum likelihood estimation at the submodel level, and that generalized gradient ascent methods are suitable for this task. We also conclude that partitioning of training data for the twin purposes of maximum likelihood initialization and gradient ascent optimization appears to be unnecessary, but that strict segregation of test data must be enforced during final gene finder evaluation to avoid artificially inflated accuracy measurements. Despite WT1 binding sites in the promoter region of human and mouse nucleoporin glycoprotein 210, WT1 does not influence expression of GP210 BackgroundGlycoprotein 210 (GP210) is a transmembrane component of the nuclear pore complex of metazoans, with a short carboxyterminus protruding towards the cytoplasm. Its function is unknown, but it is considered to be a major structural component of metazoan nuclear pores. Yet, our previous findings showed pronounced differences in expression levels in embryonic mouse tissues and cell lines. In order to identify factors regulating GP210, the genomic organization of human GP210 was analyzed in silico.ResultsThe human gene was mapped to chromosome 3 and consists of 40 exons spread over 102 kb. The deduced 1887 amino acid showed a high degree of alignment homology to previously reported orthologues. Experimentally we defined two transcription initiation sites, 18 and 29 bp upstream of the ATG start codon. The promoter region is characterized by a CpG island and several consensus binding motifs for gene regulatory transcription factors, including clustered sites associated with Sp1 and the Wilms' tumor suppressor gene zinc finger protein (WT1). In addition, distal to the translation start we found a (GT)n repetitive sequence, an element known for its ability to bind WT1. Homologies for these motifs could be identified in the corresponding mouse genomic region. However, experimental tetracycline dependent induction of WT1 in SAOS osteosarcoma cells did not influence GP210 transcription.ConclusionAlthough mouse GP210 was identified as an early response gene during induced metanephric kidney development, and WT1 binding sites were identified in the promoter region of the human GP210 gene, experimental modulation of WT1 expression did not influence expression of GP210. Therefore, WT1 is probably not regulating GP210 expression. Instead, we suggest that the identified Sp binding sites are involved. Video capture virtual reality as a flexible and effective rehabilitation tool Video capture virtual reality (VR) uses a video camera and software to track movement in a single plane without the need to place markers on specific bodily locations. The user's image is thereby embedded within a simulated environment such that it is possible to interact with animated graphics in a completely natural manner. Although this technology first became available more than 25 years ago, it is only within the past five years that it has been applied in rehabilitation. The objective of this article is to describe the way this technology works, to review its assets relative to other VR platforms, and to provide an overview of some of the major studies that have evaluated the use of video capture technologies for rehabilitation. Patenting inventions arising from biological research Patents are the most important way in which researchers can protect the income that might come from ideas or technologies they have developed. This article describes the steps involved and the considerations needed for successful granting of a patent. For instance, inventions must be novel and not obvious, adequately described, and useful, and they should not be disclosed publicly before a patent is applied for. An electronic application for rapidly calculating Charlson comorbidity score BackgroundUncertainty regarding comorbid illness, and ability to tolerate aggressive therapy has led to minimal enrollment of elderly cancer patients into clinical trials and often substandard treatment. Increasingly, comorbid illness scales have proven useful in identifying subgroups of elderly patients who are more likely to tolerate and benefit from aggressive therapy. Unfortunately, the use of such scales has yet to be widely integrated into either clinical practice or clinical trials research.MethodsThis article reviews evidence for the validity of the Charlson Comorbidity Index (CCI) in oncology and provides a Microsoft Excel (MS Excel) Macro for the rapid and accurate calculation of CCI score. The interaction of comorbidity and malignant disease and the validation of the Charlson Index in oncology are discussed.ResultsThe CCI score is based on one year mortality data from internal medicine patients admitted to an inpatient setting and is the most widely used comorbidity index in oncology. An MS Excel Macro file was constructed for calculating the CCI score using Microsoft Visual Basic. The Macro is provided for download and dissemination.The CCI has been widely used and validated throughout the oncology literature and has demonstrated utility for most major cancers. The MS Excel CCI Macro provides a rapid method for calculating CCI score with or without age adjustments. The calculator removes difficulty in score calculation as a limitation for integration of the CCI into clinical research. The simple nature of the MS Excel CCI Macro and the CCI itself makes it ideal for integration into emerging electronic medical records systems.ConclusionsThe increasing elderly population and concurrent increase in oncologic disease has made understanding the interaction between age and comorbid illness on life expectancy increasingly important. The MS Excel CCI Macro provides a means of increasing the use of the CCI scale in clinical research with the ultimate goal of improving determination of optimal treatments for elderly cancer patients. From bench to clinic and back: Perspective on the 1st IQPC Translational Research conference Translational Research (TR) provides a set of tools and communication context for scientists and clinicians to optimize the drug discovery and development process. In the proceedings of a Princeton conference on this timely topic, the strengths and needs of this developing field were debated. Outcomes and key points from these discussions are summarized in this article which covers the topics of defining what we mean by translational research (both theoretically and in operational terms), ways in which to engender the TR mindset and embed it in organizations such as the pharmaceutical industry in order to optimize the impact of available technologies (including imaging methods), the scientific basis and under-pinnings of TR including genomics knowledge, information sharing, as well as examples of application to drug discovery and development. Importantly, it should be noted that collaborations and communications between the stakeholders in this field, namely academia, industry and regulatory authorities, must be strengthened in order for the promise of TR to be delivered as better therapies to patients. Identification of a three-gene expression signature of poor-prognosis breast carcinoma BackgroundThe clinical course of breast cancer is difficult to predict on the basis of established clinical and pathological prognostic criteria. Given the genetic complexity of breast carcinomas, it is not surprising that correlations with individual genetic abnormalities have also been disappointing. The use of gene expression profiles could result in more accurate and objective prognostication.ResultsTo this end, we used real-time quantitative RT-PCR assays to quantify the mRNA expression of a large panel (n = 47) of genes previously identified as candidate prognostic molecular markers in a series of 100 ERα-positive breast tumor samples from patients with known long-term follow-up. We identified a three-gene expression signature (BRCA2, DNMT3B and CCNE1) as an independent prognostic marker (P = 0.007 by univariate analysis; P = 0.006 by multivariate analysis). This "poor prognosis" signature was then tested on an independent panel of ERα-positive breast tumors from a well-defined cohort of 104 postmenopausal breast cancer patients treated with primary surgery followed by adjuvant tamoxifen alone: although this "poor prognosis" signature was associated with shorter relapse-free survival in univariate analysis (P = 0.029), it did not persist as an independent prognostic factor in multivariate analysis (P = 0.27).ConclusionOur results confirm the value of gene expression signatures in predicting the outcome of breast cancer. Protocol for the evaluation of a decision aid for women with a breech-presenting baby [ISRCTN14570598] BackgroundThere is now good evidence about the management options for pregnant women with a breech presentation (buttocks or feet rather than head-first) at term; external cephalic version (ECV) – the turning of a breech baby to a head-down position and/or planned caesarean section (CS). Each of these options has benefits and risks and the relative importance of these vary for each woman, subject to her personal values and preferences, a situation where a decision aid may be helpful.Decision aids are designed to assist patients and their doctors in making informed decisions using information that is unbiased and based on high quality research evidence. Decision aids are non-directive in the sense that they do not aim to steer the user towards any one option, but rather to support decision making which is informed and consistent with personal values.The ECV decision aid was developed using the Ottawa Decision Support Framework, including a systematic review of the evidence about the benefits and risks of the options for breech pregnancy. It comprises an audiotape with a supplementary booklet and worksheet, a format that can be taken home and discussed with a partner. This project aims to evaluate the ECV decision aid for women with a breech presenting baby in late pregnancy.Study designWe aim to evaluate the effectiveness of the decision aid compared with usual care in a randomised controlled trial in maternity hospitals that offer ECV. The study group will receive the decision aid in addition to usual care and the control group will receive standard information on management options for breech presentation from their usual pregnancy care provider. Approximately 184 women with a single breech-presenting baby at greater than 34 weeks gestation and who are clinically eligible for ECV will be recruited for the trial.The primary outcomes of the study are knowledge, decisional conflict, anxiety and satisfaction with decision-making that will be assessed using self-administered questionnaires. The decision aid is not intended to influence either the uptake of either ECV or planned CS, however we will monitor health service utilisation rates and maternal and perinatal outcomes. Perceived work demands, felt stress, and musculoskeletal neck/shoulder symptoms among elderly female computer users. The NEW study The aim of the present study was to test a structural model of the relationship between the perceived quantitative (time pressure and unevenly distributed workload) and emotional work demands and self-reported musculoskeletal symptoms from the neck and shoulder region with felt stress (rested, relaxed, calm, tense, stressed, and pressured at the end of a normal workday) as a mediating variable. As part of the NEW (Neuromuscular assessment in the Elderly Worker) study, a European case-control study, the present cross-sectional study was based on a questionnaire survey among Danish, Dutch, Swedish and Swiss female computer users aged 45 or older ( n =148). The hypothesized structural model was tested using structural equation modelling. The results indicate that perceived work demands influence neck/shoulder musculoskeletal symptoms through their effect on felt stress. The results further indicate complete mediation, which means that all of the effect of the perceived work demands on symptoms could be attributed to the stress mechanism. As regards the percentage of explained variance in the endogenous variables, 36% of the variation in felt stress was explained by the perceived work demands, and about 20% of the variation in musculoskeletal neck/shoulder symptoms was explained by the combination of the perceived work demands and the felt stress. WINPEPI (PEPI-for-Windows): computer programs for epidemiologists BackgroundThe WINPEPI (PEPI-for-Windows) computer programs for epidemiologists are designed for use in practice and research in the health field and as learning or teaching aids. They aim to complement other statistics packages. The programs are free, and can be downloaded from the Internet.ImplementationThere are at present four WINPEPI programs: DESCRIBE, for use in descriptive epidemiology, COMPARE2, for use in comparisons of two independent groups or samples, PAIRSetc, for use in comparisons of paired and other matched observations, and WHATIS, a "ready reckoner" utility program. The programs contain 75 modules, each of which provides a number, sometimes a large number, of statistical procedures. The manuals explain the uses, limitations and applicability of specific procedures, and furnish formulae and references.ConclusionsWINPEPI provides a wide variety of statistical routines commonly used by epidemiologists, and is a handy resource for many procedures that are not very commonly used or easily found. The programs are in general user-friendly, although some users may be confused by the large numbers of options and results provided. The main limitations are the inability to read data files and the fact that only one of the programs presents graphic results. WINPEPI has a considerable potential as a learning and teaching aid. Recent translational research: computational studies of breast cancer The combination of mathematics – queen of sciences – and the general utility of computers has been used to make important inroads into insight-providing breast cancer research and clinical aids. These developments are in two broad areas. First, they provide useful prognostic guidelines for individual patients based on historic evidence. Second, by suggesting numeric tumor growth laws that are correlated to clinical parameters, they permit development of biologically relevant theories and comparison with patient data to help us understand complex biologic processes. These latter studies have produced many new ideas that are testable in clinical trials. In this review we discuss these developments from a clinical perspective, and ask whether and how they translate into useful tools for patient treatment. Modelling the impact of climate change on woody plant population dynamics in South African savanna BackgroundIn Southern Africa savannas climate change has been proposed to alter rainfall, the most important environmental driver for woody plants. Woody plants are a major component of savanna vegetation determining rangeland condition and biodiversity. In this study we use a spatially explicit, stochastic computer model to assess the impact of climate change on the population dynamics of Grewia flava, a common, fleshy-fruited shrub species in the southern Kalahari. Understanding the population dynamics of Grewia flava is a crucial task, because it is widely involved in the shrub/bush encroachment process, a major concern for rangeland management due to its adverse effect on livestock carrying capacity and biodiversity.ResultsFor our study we consider four climate change scenarios that have been proposed for the southern Kalahari for the coming decades: (1) an increase in annual precipitation by 30–40%, (2) a decrease by 5–15%, (3) an increase in variation of extreme rainfall years by 10–20%, (4) and increase in temporal auto-correlation, i.e. increasing length and variation of periodic rainfall oscillations related to El Niño/La Niña phenomena. We evaluate the slope z of the time-shrub density relationship to quantify the population trend. For each climate change scenario we then compared the departure of z from typical stable population dynamics under current climatic conditions. Based on the simulation experiments we observed a positive population trend for scenario (1) and a negative trend for scenario (2). In terms of the projected rates of precipitation change for scenario (3) and (4) population dynamics were found to be relatively stable. However, for a larger increase in inter-annual variation or in temporal auto-correlation of rainfall population trends were negative, because favorable rainfall years had a limited positive impact due to the limited shrub carrying capacity.ConclusionsWe conclude that a possible increase in precipitation will strongly facilitate shrub encroachment threatening savanna rangeland conditions and regional biodiversity. Furthermore, the negative effects found for positive auto-correlated rainfall support current ecological theory stating that periodically fluctuating environments can reduce population viability because species suffer disproportionately from poor environmental conditions. Predicting binding sites of hydrolase-inhibitor complexes by combining several methods BackgroundProtein-protein interactions play a critical role in protein function. Completion of many genomes is being followed rapidly by major efforts to identify interacting protein pairs experimentally in order to decipher the networks of interacting, coordinated-in-action proteins. Identification of protein-protein interaction sites and detection of specific amino acids that contribute to the specificity and the strength of protein interactions is an important problem with broad applications ranging from rational drug design to the analysis of metabolic and signal transduction networks.ResultsIn order to increase the power of predictive methods for protein-protein interaction sites, we have developed a consensus methodology for combining four different methods. These approaches include: data mining using Support Vector Machines, threading through protein structures, prediction of conserved residues on the protein surface by analysis of phylogenetic trees, and the Conservatism of Conservatism method of Mirny and Shakhnovich. Results obtained on a dataset of hydrolase-inhibitor complexes demonstrate that the combination of all four methods yield improved predictions over the individual methods.ConclusionsWe developed a consensus method for predicting protein-protein interface residues by combining sequence and structure-based methods. The success of our consensus approach suggests that similar methodologies can be developed to improve prediction accuracies for other bioinformatic problems. An SVD-based comparison of nine whole eukaryotic genomes supports a coelomate rather than ecdysozoan lineage BackgroundEukaryotic whole genome sequences are accumulating at an impressive rate. Effective methods for comparing multiple whole eukaryotic genomes on a large scale are needed. Most attempted solutions involve the production of large scale alignments, and many of these require a high stringency pre-screen for putative orthologs in order to reduce the effective size of the dataset and provide a reasonably high but unknown fraction of correctly aligned homologous sites for comparison. As an alternative, highly efficient methods that do not require the pre-alignment of operationally defined orthologs are also being explored.ResultsA non-alignment method based on the Singular Value Decomposition (SVD) was used to compare the predicted protein complement of nine whole eukaryotic genomes ranging from yeast to man. This analysis resulted in the simultaneous identification and definition of a large number of well conserved motifs and gene families, and produced a species tree supporting one of two conflicting hypotheses of metazoan relationships.ConclusionsOur SVD-based analysis of the entire protein complement of nine whole eukaryotic genomes suggests that highly conserved motifs and gene families can be identified and effectively compared in a single coherent definition space for the easy extraction of gene and species trees. While this occurs without the explicit definition of orthologs or homologous sites, the analysis can provide a basis for these definitions. A power law global error model for the identification of differentially expressed genes in microarray data BackgroundHigh-density oligonucleotide microarray technology enables the discovery of genes that are transcriptionally modulated in different biological samples due to physiology, disease or intervention. Methods for the identification of these so-called "differentially expressed genes" (DEG) would largely benefit from a deeper knowledge of the intrinsic measurement variability. Though it is clear that variance of repeated measures is highly dependent on the average expression level of a given gene, there is still a lack of consensus on how signal reproducibility is linked to signal intensity. The aim of this study was to empirically model the variance versus mean dependence in microarray data to improve the performance of existing methods for identifying DEG.ResultsIn the present work we used data generated by our lab as well as publicly available data sets to show that dispersion of repeated measures depends on location of the measures themselves following a power law. This enables us to construct a power law global error model (PLGEM) that is applicable to various Affymetrix GeneChip data sets. A new DEG identification method is therefore proposed, consisting of a statistic designed to make explicit use of model-derived measurement spread estimates and a resampling-based hypothesis testing algorithm.ConclusionsThe new method provides a control of the false positive rate, a good sensitivity vs. specificity trade-off and consistent results with varying number of replicates and even using single samples. Directed evolution of single-chain Fv for cytoplasmic expression using the β-galactosidase complementation assay results in proteins highly susceptible to protease degradation and aggregation BackgroundAntibody fragments are molecules widely used for diagnosis and therapy. A large amount of protein is frequently required for such applications. New approaches using folding reporter enzymes have recently been proposed to increase soluble expression of foreign proteins in Escherichia coli. To date, these methods have only been used to screen for proteins with better folding properties but have never been used to select from a large library of mutants. In this paper we apply one of these methods to select mutations that increase the soluble expression of two antibody fragments in the cytoplasm of E. coli.ResultsWe used the β-galactosidase α-complementation system to monitor and evolve two antibody fragments for high expression levels in E. coli cytoplasm. After four rounds of mutagenesis and selection from large library repertoires (>107 clones), clones exhibiting high levels of β-galactosidase activity were isolated. These clones expressed a higher amount of soluble fusion protein than the wild type in the cytoplasm, particularly in a strain deficient in the cytoplasmic Lon protease. The increase in the soluble expression level of the unfused scFv was, however, much less pronounced, and the unfused proteins proved to be more aggregation prone than the wild type. In addition, the soluble expression levels were not correlated with the β-galactosidase activity present in the cells.ConclusionThis is the first report of a selection for soluble protein expression using a fusion reporter method. Contrary to anticipated results, high enzymatic activity did not correlate with the soluble protein expression level. This was presumably due to free α-peptide released from the protein fusion by the host proteases. This means that the α-complementation assay does not sense the fusion expression level, as hypothesized, but rather the amount of free released α-peptide. Thus, the system does not select, in our case, for higher soluble protein expression level but rather for higher protease susceptibility of the fusion protein. Knockdown of c-Myc expression by RNAi inhibits MCF-7 breast tumor cells growth in vitro and in vivo IntroductionBreast cancer is the leading cause of cancer death in women worldwide. Elevated expression of c-Myc is a frequent genetic abnormality seen in this malignancy. For a better understanding of its role in maintaining the malignant phenotype, we used RNA interference (RNAi) directed against c-Myc in our study. RNAi provides a new, reliable method to investigate gene function and has the potential for gene therapy. The aim of the study was to examine the anti-tumor effects elicited by a decrease in the protein level of c-Myc by RNAi and its possible mechanism of effects in MCF-7 cells.MethodA plasmid-based polymerase III promoter system was used to deliver and express short interfering RNA (siRNA) targeting c-myc to reduce its expression in MCF-7 cells. Western blot analysis was used to measure the protein level of c-Myc. We assessed the effects of c-Myc silencing on tumor growth by a growth curve, by soft agar assay and by nude mice experiments in vivo. Standard fluorescence-activated cell sorter analysis and TdT-mediated dUTP nick end labelling assay were used to determine apoptosis of the cells.ResultsOur data showed that plasmids expressing siRNA against c-myc markedly and durably reduced its expression in MCF-7 cells by up to 80%, decreased the growth rate of MCF-7 cells, inhibited colony formation in soft agar and significantly reduced tumor growth in nude mice. We also found that depletion of c-Myc in this manner promoted apoptosis of MCF-7 cells upon serum withdrawal.Conclusionc-Myc has a pivotal function in the development of breast cancer. Our data show that decreasing the c-Myc protein level in MCF-7 cells by RNAi could significantly inhibit tumor growth both in vitro and in vivo, and imply the therapeutic potential of RNAi on the treatment of breast cancer by targeting overexpression oncogenes such as c-myc, and c-myc might be a potential therapeutic target for human breast cancer. Microarray-based resequencing of multiple Bacillus anthracisisolates We used custom-designed resequencing arrays to generate 3.1 Mb of genomic sequence from a panel of 56 Bacillus anthracis strains. Sequence quality was shown to be very high by replication (discrepancy rate of 7.4 × 10-7) and by comparison to independently generated shotgun sequence (discrepancy rate < 2.5 × 10-6). Population genomics studies of microbial pathogens using rapid resequencing technologies such as resequencing arrays are critical for recognizing newly emerging or genetically engineered strains. Identification of α-type subunits of the Xenopus 20S proteasome and analysis of their changes during the meiotic cell cycle BackgroundThe 26S proteasome is the proteolytic machinery of the ubiquitin-dependent proteolytic system responsible for most of the regulated intracellular protein degradation in eukaryotic cells. Previously, we demonstrated meiotic cell cycle dependent phosphorylation of α4 subunit of the 26S proteasome. In this study, we analyzed the changes in the spotting pattern separated by 2-D gel electrophoresis of α subunits during Xenopus oocyte maturation.ResultsWe identified cDNA for three α-type subunits (α1, α5 and α6) of Xenopus, then prepared antibodies specific for five subunits (α1, α3, α5, α6, and α7). With these antibodies and previously described monoclonal antibodies for subunits α2 and α4, modifications to all α-type subunits of the 26S proteasome during Xenopus meiotic maturation were examined by 2D-PAGE. More than one spot for all subunits except α7 was identified. Immunoblot analysis of 26S proteasomes purified from immature and mature oocytes showed a difference in the blots of α2 and α4, with an additional spot detected in the 26S proteasome from immature oocytes (in G2-phase).ConclusionsSix of α-type subunits of the Xenopus 26S proteasome are modified in Xenopus immature oocytes and two subunits (α2 and α4) are modified meiotic cell cycle-dependently. Development of a questionnaire weighted scoring system to target diagnostic examinations for asthma in adults: a modelling study BackgroundIdentification and treatment of unrecognised asthmatics in the community is important for improving the health of the individual and minimising cost and quality of life burden. It is not practical to offer clinical diagnostic assessment to whole communities, and a simple tool such as a questionnaire is required to identify a smaller target group. Conventional questionnaire screening methods which separate individuals into positive and negative categories have resulted in large numbers of individuals requiring clinical assessment. This study has therefore developed and tested a weighted scoring system that prioritises those most urgently in need, based on their questionnaire responses.MethodsA stratified random sample of adult respondents to a general practice postal questionnaire survey were categorised 'asthmatic' or 'non-asthmatic' according to three expert physicians' opinions. Based on this categorisation, logistic regression was used to derive weights reflecting the relative importance of each question in predicting asthma, allowing calculation of weighted scores reflecting likelihood of asthma. Respondents scoring higher than a chosen threshold would be offered diagnostic examination.ResultsAge and presence of wheeze were most influential (weight 3) and overall weighted scores ranged from -1 to 13. Positive predictive values (PPV) were estimated. For example, setting the threshold score at nine gave an estimated PPV for asthma diagnosis of 93.5%, a threshold score of seven corresponded to PPV 78.8%. PPV estimates were supported by examining 145 individuals from a new survey.ConclusionWeighted scoring of questionnaire responses provides a method for evaluating the priority level of an individual 'at a glance', minimising the resource wastage of examining false positives. A novel Mixture Model Method for identification of differentially expressed genes from DNA microarray data BackgroundThe main goal in analyzing microarray data is to determine the genes that are differentially expressed across two types of tissue samples or samples obtained under two experimental conditions. Mixture model method (MMM hereafter) is a nonparametric statistical method often used for microarray processing applications, but is known to over-fit the data if the number of replicates is small. In addition, the results of the MMM may not be repeatable when dealing with a small number of replicates. In this paper, we propose a new version of MMM to ensure the repeatability of the results in different runs, and reduce the sensitivity of the results on the parameters.ResultsThe proposed technique is applied to the two different data sets: Leukaemia data set and a data set that examines the effects of low phosphate diet on regular and Hyp mice. In each study, the proposed algorithm successfully selects genes closely related to the disease state that are verified by biological information.ConclusionThe results indicate 100% repeatability in all runs, and exhibit very little sensitivity on the choice of parameters. In addition, the evaluation of the applied method on the Leukaemia data set shows 12% improvement compared to the MMM in detecting the biologically-identified 50 expressed genes by Thomas et al. The results witness to the successful performance of the proposed algorithm in quantitative pathogenesis of diseases and comparative evaluation of treatment methods. Identifying spatially similar gene expression patterns in early stage fruit fly embryo images: binary feature versus invariant moment digital representations BackgroundModern developmental biology relies heavily on the analysis of embryonic gene expression patterns. Investigators manually inspect hundreds or thousands of expression patterns to identify those that are spatially similar and to ultimately infer potential gene interactions. However, the rapid accumulation of gene expression pattern data over the last two decades, facilitated by high-throughput techniques, has produced a need for the development of efficient approaches for direct comparison of images, rather than their textual descriptions, to identify spatially similar expression patterns.ResultsThe effectiveness of the Binary Feature Vector (BFV) and Invariant Moment Vector (IMV) based digital representations of the gene expression patterns in finding biologically meaningful patterns was compared for a small (226 images) and a large (1819 images) dataset. For each dataset, an ordered list of images, with respect to a query image, was generated to identify overlapping and similar gene expression patterns, in a manner comparable to what a developmental biologist might do. The results showed that the BFV representation consistently outperforms the IMV representation in finding biologically meaningful matches when spatial overlap of the gene expression pattern and the genes involved are considered. Furthermore, we explored the value of conducting image-content based searches in a dataset where individual expression components (or domains) of multi-domain expression patterns were also included separately. We found that this technique improves performance of both IMV and BFV based searches.ConclusionsWe conclude that the BFV representation consistently produces a more extensive and better list of biologically useful patterns than the IMV representation. The high quality of results obtained scales well as the search database becomes larger, which encourages efforts to build automated image query and retrieval systems for spatial gene expression patterns.