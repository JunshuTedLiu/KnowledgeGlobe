Numerical Hydrodynamics in Special Relativity This review is concerned with a discussion of numerical methods for the solution of the equations of special relativistic hydrodynamics (SRHD). Particular emphasis is put on a comprehensive review of the application of high-resolution shock-capturing methods in SRHD. Results obtained with different numerical SRHD methods are compared, and two astrophysical applications of SRHD flows are discussed. An evaluation of the various numerical methods is given and future developments are analyzed. Formality Considered Harmful: Experiences, Emerging Themes, and Directions on the Use of Formal Representations in Interactive Systems This paper reflects on experiences designing, developing, and working with users of a variety of interactive computer systems. The authors propose, based on these experiences, that the cause of a number of unexpected difficulties in human-computer interaction lies in users' unwillingness or inability to make structure, content, or procedures explicit. Besides recounting experiences with system use, this paper discusses why users reject or circumvent formalisms which require such explicit expression, and suggests how system designers can anticipate and compensate for problems users have in making implicit aspects of their tasks explicit. The authors propose computational approaches that address this problem, including incremental and system-assisted formalization mechanisms and methods for recognizing and using undeclared structure; they also propose non-computational solutions that involve designers and users reaching a shared understanding of the task situation and the methods that motivate the formalisms. This paper poses that, while it is impossible to remove all formalisms from computing systems, system designers need to match the level of formal expression entailed with the goals and situation of the users -- a design criteria not commonly mentioned in current interface design. Accumulating and Coordinating: Occasions for Information Technologies in Medical Work This paper attempts to provide a relational understanding of the generative power of information technologies: an understanding that sees information technologies as embedded in workpractices. This theoretical undertaking, inspired by actor-network theory and work within CSCW, has a practical and political aim. The problems it discusses are directly relevant for the aims and hopes of CSCW: the design of systems that fit workpractices better than traditionally designed systems, and that enhance worker's competencies and responsibilities. The paper depicts information technologies as reading and writing artifacts. Taking parts of the medical record as an example, the paper argues that those tools -- in relation with the reading and writing activities of nurses, doctors, laboratory systems -- can be seen to perform two roles in work practices. They accumulate inscriptions and coordinate activities of other entities in the work practice, and in that way afford the handling of more complex worktasks. This focus on the generative power of these artifacts leads to a reconsideration of the notions of ‘supporting’ work and ‘transparent’ technologies, and to a series of specific entry-points for a politics of IT. Combination of Edge Element and Optical Flow Estimates for 3D-Model-Based Vehicle Tracking in Traffic Image Sequences A model-based vehicle tracking system for the evaluation of inner-city traffic video sequences has been systematically tested on about 15 minutes of real world video data. Methodological improvements during preparatory test phases affected—among other changes—the combination of edge element and optical flow estimates in the measurement process and a more consequent exploitation of background knowledge. The explication of this knowledge in the form of models facilitates the evaluation of video data for different scenes by exchanging the scene-dependent models. An extensive series of experiments with a large test sample demonstrates that the current version of our system appears to have reached a relative optimum: further interactive tuning of tracking parameters does no longer promise to improve the overall system performance significantly. Even the incorporation of further knowledge regarding vehicle and scene geometry or illumination has to cope with an increasing level of interaction between different knowledge sources and system parameters. Our results indicate that model-based tracking of rigid objects in monocular image sequences may have to be reappraised more thoroughly than anticipated during the recent past. The SGF metadata framework and its support for social awareness on the World Wide Web The widespread use of metadata is transforming the WWW into an information space that can be accessed not only by humans, but also by software agents. In this article, one application for metadata is more closely examined: the description of Web sites structures in a machine understandable way. The Structured Graph Format (SGF) is introduced as an XML‐based format supporting the description of Web spaces as structured graphs. The SGF framework, built around this format specification, is then described. This integrated and extensible set of software components supports the generation, the distribution and the processing of SGF metadata. Three approaches to the problem of generating SGF metadata are compared and highlight a tradeoff between quality and cost. SGF consumers are then presented as components that process the metadata for some purpose. An SGF consumer that uses the metadata to dynamically generate interactive site maps is presented. The discussion then argues for the need to increase social awareness on the WWW. In other words, it raises the issue of monitoring the activity occurring within Web sites. The notion of awareness is first introduced and situated in the context of Computer Supported Cooperative Work (CSCW). Different ways to apply awareness to the WWW are then reviewed. Finally, the SGF framework is described as a valuable foundation for building awareness systems on the Web, with two main advantages. First, because SGF metadata supports the definition of regions within a Web site, at different granularities, it ensures the scalability of monitoring systems. It thus gives users of these systems a very flexible way to define regions of interest and to monitor activity in more meaningful ways. Second, the site maps generated on the basis of SGF metadata provide an efficient way to represent the activity occurring within the monitored site. These explicit representations, which are useful to analyze activity, are contrasted with abstract representations, which are useful to maintain peripheral awareness about ongoing activity on the Web. Depth Discontinuities by Pixel-to-Pixel Stereo An algorithm to detect depth discontinuities from a stereo pair of images is presented. The algorithm matches individual pixels in corresponding scanline pairs, while allowing occluded pixels to remain unmatched, then propagates the information between scanlines by means of a fast postprocessor. The algorithm handles large untextured regions, uses a measure of pixel dissimilarity that is insensitive to image sampling, and prunes bad search nodes to increase the speed of dynamic programming. The computation is relatively fast, taking about 600 nanoseconds per pixel per disparity on a personal computer. Approximate disparity maps and precise depth discontinuities (along both horizontal and vertical boundaries) are shown for several stereo image pairs containing textured, untextured, fronto-parallel, and slanted objects in indoor and outdoor scenes. Spatial Color Indexing and Applications We define a new image feature called the color correlogram and use it for image indexing and comparison. This feature distills the spatial correlation of colors and when computed efficiently, turns out to be both effective and inexpensive for content-based image retrieval. The correlogram is robust in tolerating large changes in appearance and shape caused by changes in viewing position, camera zoom, etc. Experimental evidence shows that this new feature outperforms not only the traditional color histogram method but also the recently proposed histogram refinement methods for image indexing/retrieval. We also provide a technique to cut down the storage requirement of the correlogram so that it is the same as that of histograms, with only negligible performance penalty compared to the original correlogram.We also suggest the use of color correlogram as a generic indexing tool to tackle various problems arising from image retrieval and video browsing. We adapt the correlogram to handle the problems of image subregion querying, object localization, object tracking, and cut detection. Experimental results again suggest that the color correlogram is more effective than the histogram for these applications, with insignificant additional storage or processing cost. Effects of Computer-Assisted Career Decision Making on Vocational Identity and Career Exploratory Behaviors  A Methodological View of Constraint Solving Constraints are an effective tool to define sets of data by means of logical formulae. Our goal here is to survey the notion of constraint system and to give examples of constraint systems operating on various domains, such as natural, rational or real numbers, finite domains, and term domains. We classify the different methods used for solving constraints, syntactic methods based on transformations, semantic methods based on adequate representations of constraints, hybrid methods combining transformations and enumerations. The concepts and methods are illustrated via examples. We also discuss applications of constraints to various fields, such as programming, operations research, and theorem proving. Web-based administration of a personality questionnaire: Comparison with traditional methods The World-Wide Web holds great promise as a mechanism for questionnaire-based research. But are data from Web-based questionnaires comparable to data from standard paper-and-pencil questionnaires? This study assessed the equivalence of the Ruminative Responses Scale in a Web-based format and in a paper-and-pencil format among introductory psychology, upper-level psychology, and non-psychology students. Internal consistency coefficients were comparable across the groups. The participants in the Web sample reported higher levels of self-focused rumination than did the other groups. Women in the Web sample reported more self-focused rumination than did women in the other groups. In the Web sample, results did not covary with access location. These results suggest that findings from Web-based questionnaire research are comparable with results obtained using standard procedures. The computerized Web interface may also facilitate self-disclosure among research participants. Determining Generative Models of Objects Under Varying Illumination: Shape and Albedo from Multiple Images Using SVD and Integrability We describe a method of learning generative models of objects from a set of images of the object under different, and unknown, illumination. Such a model allows us to approximate the objects' appearance under a range of lighting conditions. This work is closely related to photometric stereo with unknown light sources and, in particular, to the use of Singular Value Decomposition (SVD) to estimate shape and albedo from multiple images up to a linear transformation (Hayakawa, 1994). Firstly we analyze and extend the SVD approach to this problem. We demonstrate that it applies to objects for which the dominant imaging effects are Lambertian reflectance with a distant light source and a background ambient term. To determine that this is a reasonable approximation we calculate the eigenvectors of the SVD on a set of real objects, under varying lighting conditions, and demonstrate that the first few eigenvectors account for most of the data in agreement with our predictions. We then analyze the linear ambiguities in the SVD approach and demonstrate that previous methods proposed to resolve them (Hayakawa, 1994) are only valid under certain conditions. We discuss alternative possibilities and, in particular, demonstrate that knowledge of the object class is sufficient to resolve this problem. Secondly, we describe the use of surface consistency for putting constraints on the possible solutions. We prove that this constraint reduces the ambiguities to a subspace called the generalized bas relief ambiguity (GBR) which is inherent in the Lambertian reflectance function (and which can be shown to exist even if attached and cast shadows are present (Belhumeur et al., 1997)). We demonstrate the use of surface consistency to solve for the shape and albedo up to a GBR and describe, and implement, a variety of additional assumptions to resolve the GBR. Thirdly, we demonstrate an iterative algorithm that can detect and remove some attached shadows from the objects thereby increasing the accuracy of the reconstructed shape and albedo. Research on technology and teacher education: Current status and future directions Within the context of a brief history of information technology in teacher education (ITTE), current research on ITTE is reviewed. It is argued that ITTE research can be categorized into three paradigms: empirical, critical, and interpretive. The need for a clear, multi-paradigmatic approach for future work is emphasized. Examples of exemplary work are cited. Conclusions suggest needs for more sharing of information of “islands of excellence” in work on technology in teacher education, more case studies on diffusion of innovation, more emphasis on bias-related findings from critical theory, and more development and dissemination of resources and tools for using technology effectively in teacher education. Recommendations for further work in the area also include emphasizing instructional design (ID) work to create innovations and recognizing the need for grounded, reflective papers on innovative approaches that have been implemented and studied over several years. The microworld of Phoenix Quest: social and cognitive considerations The present paper explores social and cognitive considerations in the context of a computer-game microworld or learning culture environment. Forty-one boys and 57 girls, aged 8 to 12 years (Grades 4, 5, and 6) were observed playing a computer game called Phoenix Quest. This computer game, featuring an adolescent female protagonist, is an interactive, mystery-adventure with embedded language and mathematics activities. The issues discussed include (a) the development of a computer game learning culture or microworld, (b) interdependence in the process of learning social skills, (c) computer game-playing strategies, (d) gender differences in computer-game play, and (e) mathematics concepts explored in the Phoenix Quest environment. These findings not only contribute to the understanding of how students create and shape a microworld around a computer game like Phoenix Quest, but also indicate some of the inherent teaching and learning limitations of educational software when the guidance of a teacher is absent. Issues associated with participation in on line forums—the case of the communicative learner This paper reports on participation within on-line forums. The focus is on asynchronous text based discussion within small groups of learners following a learning event or course. Participation is a key issue within such forums and research was carried out into adult learners' experiences within three case studies. Learners were positive about the forums in which they took part but participation was less than many would have liked. This paper describes the constraints on participation and outlines three patterns of participation—non participation, quiet participation and communicative participation. Discussion focuses on the communicative leaner—someone who participates regularly in forums and in ways which are broadly welcomed by others in the group. A profile of the communicative learner is developed in which the importance of fluency, coherence and informality is highlighted. The paper summarises the issues associated with on-line participation and their implications for supporting communicative participation. Evaluating the effectiveness of augmented reality displays for a manual assembly task The focus of this research was to examine how effectively augmented reality displays, generated with a wearable computer, could be used for aiding an operator performing a manual assembly task. Fifteen subjects were asked to assemble a computer motherboard using four types of instructional media: paper manual, computer-aided, opaque augmented reality display, and see-through augmented reality display. The time of assembly and assembly errors were measured for each type of instructional media, and a questionnaire focusing on usability was administered to each subject at the end of each condition. The results of the experiment indicated that the augmented reality conditions were more effective instructional aids for the assembly task than either the paper instruction manual or the computer-aided instruction. The see-through augmented reality display resulted in the fastest assembly times, followed by the opaque augmented reality display, the computer-aided instruction, and the paper instructions respectively. In addition, subjects made fewer errors using the augmented reality conditions compared to the computer-aided and paper instructional media. However, while the two augmented reality conditions were a more effective instructional media when time for assembly was the response measure, there were still some important usability issues associated with the augmented reality technology that were not present in the non-augmented reality conditions. A tale of two mailing lists This paper serves to report a research study on the use made of two separate mailing lists or listservs, for professional development—Oz-Teachers and UK-Schools. Both lists were, and still are, used by teachers in Australia and the United Kingdom, as well as by teachers across the globe, to communicate electronically with each other. The practice of this communication is typically characterised by text messages that pose questions or offer answers; by ‘threads’ of discussion based around single or combined themes; and by statements of information. In this context, two windows are opened in this study: one shows a dynamic picture of teachers at work and play in the technology of listservs, developing skills and practices in asynchronous communications. The other looks into the content of many of the postings, demonstrating the practices, views, ideas and concerns teachers have with using technology in traditional school and classroom environments. Whilst this paper provides a detailed overview of the study, the full report of the research programme, of which this study constitutes one part, can be found elsewhere, in Lankshear et al. (1997) and Wild (1999). Technology professional development for teachers This article examines technology professional development for preservice and inservice teachers. It reviews the current status of technology in our schools, what we know about professional development in the area of technology, and research on efforts to increase preservice teacher use of technology in appropriate ways. ICOME: An Immersive Collaborative 3D Object Modelling Environment In most existing immersive virtual environments, 3D geometry is imported from external packages. Within ICOME (an immersive Collaborative 3D Object Modelling Environment) we focus on the immersive construction of 3D geometrical objects within the environment itself. Moreover, the framework allows multiple people to simultaneously undertake 3D modelling tasks in a collaborative way. This article describes the overall architecture, which conceptually follows a client/server approach. The various types of clients, which are implemented, are described in detail. Some illustrative 3D object modelling examples are given. Extensions to the system with regard to 3D audio are also mentioned. Preserving attribute values on simplified meshes by resampling detail textures  Computergraphics society Special Issue  Optimum Fiducials Under Weak Perspective Projection We investigate how a given fixed number of points should be located in space so that the pose of a camera viewing them from unknown locations can be estimated with the greatest accuracy. We show that optimum solutions are obtained when the points form concentric complete regular polyhedra. For the case of optimal configurations we provide a worst-case error analysis and use it to analyze the effects of weak perspective approximation to true perspective viewing. Comprehensive computer simulations validate the theoretical results. The Network RamDisk: Using remote memory on heterogeneous NOWs Efficient data storage, a major concern in the modern computer industry, is mostly provided today by traditional magnetic disks. However, the cost of a disk transfer (measured in processor cycles) continues to increase with time, making disk accesses increasingly expensive. In this paper we describe the design, implementation and evaluation of a Network RamDisk device that uses main memory of remote workstations as a faster‐than‐disk storage device. In our study we propose various reliability policies, making the device tolerant to single workstation crashes. We show that the Network RamDisk is portable, flexible, and can operate under any of the existing Unix file systems. The Network RamDisk has been implemented both on the Linux and the Digital Unix operating systems, as a block device driver without any modifications to the kernel code. Using several real applications and benchmarks, we measure the performance of the Network RamDisk over an Ethernet and an ATM network, and find it to be usually four to eight times better than the magnetic disk. In one benchmark, our system was two orders of magnitude faster than the disk. We believe that a Network RamDisk can be efficiently used to provide reliable low‐latency access to files that would otherwise be stored on magnetic disks. Diffusive smoothing of polygonal meshes with bias and tension controls  Interactive surface decomposition for polyhedral morphing  Using digital but physical surrogates to mediate awareness, communication and privacy in media spaces Digital but physical surrogates are tangible representations of remote people (typically members of small intimate teams), positioned within an office and under digital control. Surrogates selectively collect and present awareness information about the people they represent. They also react to people's explicit and implicit physical actions: a person's explicit acts include grasping and moving them, while their implicit acts include how they move towards or away from the surrogate. By responding appropriately to these physical actions of people, surrogates can control the communication capabilities of a media space in a natural way. Surrogates also balance awareness and privacy by limiting and abstracting how activities are portrayed, and by offering different levels of salience to its users. The combination of all these attributes means that surrogates can make it easy for intimate collaborators to move smoothly from awareness of each other to casual interaction while mitigating privacy and distraction concerns.Exploring different surrogate designs and how they work together can be straightforward if a good infrastructure is in place. We use anawareness server based on a distributed model-view-controller architecture, which automatically captures, stores and distributes events. We also package surrogates as physical widgets orphidgets with a well-defined interface; this makes it easy for a programmer to plug a surrogate into the awareness server as a controller (to generate awareness events), or view (to display events that others have produced), or both. Because surrogate design, implementation and use is still a new discipline, we also present several issues and next steps. Using metaballs to modeling and animate clouds from satellite images  Computer-generated still images composited with panned/zoomed landscape video sequences  Voice Loops as Coordination Aids in Space Shuttle Mission Control Voice loops, an auditory groupware technology, are essential coordination support tools for experienced practitioners in domains such as air traffic management, aircraft carrier operations and space shuttle mission control. They support synchronous communication on multiple channels among groups of people who are spatially distributed. In this paper, we suggest reasons for why the voice loop system is a successful medium for supporting coordination in space shuttle mission control based on over 130 hours of direct observation. Voice loops allow practitioners to listen in on relevant communications without disrupting their own activities or the activities of others. In addition, the voice loop system is structured around the mission control organization, and therefore directly supports the demands of the domain. By understanding how voice loops meet the particular demands of the mission control environment, insight can be gained for the design of groupware tools to support cooperative activity in other event-driven domains. Tuning Compiler Optimizations for Simultaneous Multithreading Simultaneous Multithreading (SMT) is a processor architectural technique that promises to significantly improve the utilization and performance of modern wide-issue superscalar processors. An SM T processor is capable of issuing multiple instructions from multiple threads to a processor's functional units each cycle. Unlike shared-memory multiprocessors, SMT provides and benefits from fine-grained sharing of processor and memory system resources; unlike current uniprocessors, SMT exposes and benefits from inter-thread instruction-level parallelism when hiding long-latency operations. Compiler optimizations are often driven by specific assumptions about the underlying architecture and implementation of the target machine, particularly for parallel processors. For example, when targeting shared-memory multiprocessors, parallel programs are compiled to minimize sharing, in order to decrease high-cost inter-processor communication. Therefore, optimizations that are appropriate for these conventional machines may be inappropriate for SMT, which can benefit from finegrained resource sharing within the processor. This paper reexamines several compiler optimizations in the context of simultaneous multithreading. We revisit three optimizations in this light: loop-iteration scheduling, software speculative execution, and loop tiling. Our results show that all three optimizations should be applied differently in the context of SMT architectures: threads should be parallelized with a cyclic, rather than a blocked algorithm; non-loop programs should not be software speculated, and compilers no longer need to be concerned about precisely sizing tiles to match cache sizes. By following these new guidelines, compilers can generate code that improves the performance of programs executing on SMT machines. Efficient rendering of multiresolution meshes with guaranteed image quality  Animating bird flight using aerodynamics  Speaking to read: The effects of speech recognition technology on the reading and spelling performance of children with learning disabilities In recent literature on persons with learning disabilities (LD), speech recognition has been discussed primarily as an assistive technology to help compensate for writing difficulties. However, prior research by the authors has suggested that in addition to helping persons to compensate for poor writing skills, speech recognition also may enhance reading and spelling; that is, what was designed as assistive technology appears to serve remedial functions as well. The present study was conducted to determine whether elementary and secondary students with LD who used the technology to write self-selected compositions and class assignments would demonstrate improvements in reading and spelling. Thirty-nine students with LD (ages 9 to 18) participated. Nineteen participants used speech recognition 50 minutes a week for sixteen weeks, and twenty students in a control group received general computer instruction. Results indicated that the speech recognition group showed significantly more improvement than the control group in word recognition (p<.0001), spelling (p<.002) and reading comprehension (p<.01). Pre- and posttests on five reading-related cognitive processing measures (phonological, orthographic, semantic processing, metacognitive reading strategies, and working memory) indicated that for the experimental group, only phonological processing improved significantly over the treatment period when compared to controls (p<.04). Further ANCOVA suggested that growth in phonological processing was associated with significant differences among conditions for all three academic measures: word recognition, spelling, and reading comprehension. Instructional uses of the WWW: An evaluation tool The development of the World Wide Web (WWW) and the subsequent introduction of different browsers, with their extensions, has changed the Internet from a text‐only communications tool to a powerful multimedia platform whose potential applications are increasing day by day. Research efforts in the computer aided education field are represented by a broad spectrum of applications, from the virtual classroom to remote courses. In these environments, visualising the progress of students in a certain course is an important part of the learning process. At the Universidad Politecnica de Valencia we are experimenting with WWW based software tools and networks for computer aided learning. This research process has resulted in the development of a teacher's authoring tool and an evaluation application; both developed using Java and based on Internet browsers. With this evaluation tool, teachers can easily create questions of different types – which are stored on a database. These questions can later be used to compose different exams or exercises for different students depending on the course and the objective of the examinations. The advantages include an improvement in the fulfillment of the teacher's duties; an increase in the responsiveness of the exam results to the level of student understanding; and the potential for using the application in distance learning and training. Addressing first- and second-order barriers to change: Strategies for technology integration Although teachers today recognize the importance of integrating technology into their curricula, efforts are often limited by both external (first-order) and internal (second-order) barriers. Traditionally, technology training, for both preservice and inservice teachers, has focused on helping teachers overcome first-order barriers (e.g., acquiring technical skills needed to operate a computer). More recently, training programs have incorporated pedagogical models of technology use as one means of addressing second-order barriers. However, little discussion has occurred that clarifies the relationship between these different types of barriers or that delineates effective strategies for addressing different barriers. If pre- and inservice teachers are to become effective users of technology, they will need practical strategies for dealing with the different types of barriers they will face. In this paper, I discuss the relationship between first- and second-order barriers and then describe specific strategies for circumventing, overcoming, and eliminating the changing barriers teachers face as they work to achieve technology integration. High-School Chemistry Students' Performance and Gender Differences in a Computerized Molecular Modeling Learning Environment Computerized molecular modeling (CMM) contributes to the development of visualization skills via vivid animation of three dimensional representations. Its power to illustrate and explore phenomena in chemistry teaching stems from the convenience and simplicity of building molecules of any size and color in a number of presentation styles. A new CMM-based learning environment for teaching and learning chemistry in Israeli high schools has been designed and implemented. Three tenth grade experimental classes used this discovery CMM approach, while two other classes, who studied the same topic in the customary approach, served as a control group. We investigated the effects of using molecular modeling on students' spatial ability, understanding of new concepts related to geometric and symbolic representations and students' perception of the model concept. Each variable was examined for gender differences. Students of the experimental group performed better than control group students in all three performance aspects. Experimental group students scored higher than the control group students in the achievement test on structure and bonding. Students' spatial ability improved in both groups, but students from the experimental group scored higher. For the average students in the two groups the improvement in all three spatial ability sub-tests —paper folding, card rotation, and cube comparison—was significantly higher for the experimental group. Experimental group students gained better insight into the model concept than the control group and could explain more phenomena with the aid of a variety of models. Hence, CMM helps in particular to improve the examined cognitive aspects of the average student population. In most of the achievement and spatial ability tests no significant differences between the genders were found, but in some aspects of model perception and verbal argumentation differences still exist. Experimental group females improved their model perception more than the control group females in understanding ways to create models and in the role of models as mental structures and prediction tools. Teachers' and students' feedback on the CMM learning environment was found to be positive, as it helped them understand concepts in molecular geometry and bonding. The results of this study suggest that teaching/learning of topics in chemistry that are related to three dimensional structures can be improved by using a discovery approach in a computerized learning environment. Biplane X-ray angiograms, intravascular ultrasound, and 3D visualization of coronary vessels The technology for determination of the 3D vascular tree and quantitative characterization of the vessel lumen and vessel wall has become available. With this technology, cardiologists will no longer rely primarily on visual inspection of coronary angiograms but use sophisticated modeling techniques combining images from various modalities for the evaluation of coronary artery disease and the effects of treatment. Techniques have been developed which allow the calculation of the imaging geometry and the 3D position of the vessel centerlines of the vascular tree from biplane views without a calibration object, i.e., from the images themselves, removing the awkwardness of moving the patient to obtain 3D information. With the geometry and positional information, techniques for reconstructing the vessel lumen can now be applied that provide more accurate estimates of the area and shape of the vessel lumen. In conjunction with these developments, techniques have been developed for combining information from intravascular ultrasound images with the information obtained from angiography. The combination of these technologies will yield a more comprehensive characterization and understanding of coronary artery disease and should lead to improved and perhaps less invasive patient care. A Student Evaluation of Molecular Modeling in First Year College Chemistry This three-year study involved an evaluation of molecular modeling by students in first year college chemistry. The molecular modeling program utilized was Spartan (Wavefunction, Inc., Irvine, California) on a UNIX-based platform with Silicon Graphics Indigo series workstations. A treatment group of 129 students visited a computer room four times during the semester for two-hour sessions. They completed exercises on periodic trends in atoms, structure of molecules, electronic structure of molecules such as MO and valence bond theory, and properties of organic molecules. The students were required to complete an evaluation of the molecular modeling computer experience at the end of the semester regarding aspects such as: effectiveness, integration with course content, interest, benefit, and advantages and disadvantages. Also obtained through the evaluation were students' opinions regarding the helpfulness of the molecular modeling computer experience for 3-D visualization of atomic and molecular structure and whether their understanding of atomic and molecular structure was enhanced. The first two years of the study constituted a pilot study and data for this study were obtained in the third year. Though the specifics are not reported here, quantitatively the achievement of the treatment and non-treatment groups was also assessed. There was a significant difference in achievement on the Final Exam of the semester (p = 0.0067) between the treatment and non-treatment groups on multiple choice questions pertaining to concepts of resonance, dipole moment, and atomic/molecular stoichiometry. Obstacles Confronting Technology Initiatives as Seen Through the Experience of Science Teachers: A Comparative Study of Science Teachers' Beliefs, Planning, and Practice There currently exists unparalleled discrepant growth between technological advancements and educators' understanding of appropriate classroom technology implemenation. The Tech Tools™ teacher enhancement program was designed to provide teachers with hardware and expertise with state-of-the-art science and math microcomputer technologies. This study was conducted as an examination of the implementation of current technologies in teacher education and school settings for the purpose of informing other science, mathematics, and technology reform efforts. For over two years researchers gathered data from surveys, interviews, and on site visits and observations explicating the 1) teacher knowledge and beliefs, 2) computer use for instruction, 3) hardward access, and 4) school support for technology use. Results revealed teachers given identical equipment and training implemented similar technologies in vastly different ways. Discrepancies in implementation of technology were best explained through the lenses of teachers' existing practice and beliefs about their school context. Recommendations are given regarding technology implementation, teacher education, and evaluation of technology initiatives. KDD, data mining, and the challenge for normative privacy The present study examines certain challenges that KDD (Knowledge Discovery in Databases) in general and data mining in particular pose for normative privacy and public policy. In an earlier work (see Tavani, 1999), I argued that certain applications of data-mining technology involving the manipulation of personal data raise special privacy concerns. Whereas the main purpose of the earlier essay was to show what those specific privacy concerns are and to describe how exactly those concerns have been introduced by the use of certain KDD and data-mining techniques, the present study questions whether the use of those techniques necessarily violates the privacy of individuals. This question is considered vis-à-vis a recent theory of privacy advanced by James Moor (1997). The implications of that privacy theory for a data-mining policy are also considered. Towards an electronic independent learning environment for statistics in higher education This study focuses on the feasibility of implementing independent learning in a traditional university and the feasibility of providing this independent learning by means of an electronic interactive learning environment. The target group contained students enrolled in an applied statistics course at the Department of Psychology and Educational Sciences at the University of Gent (RUG). Three experimental variables were designed: learning environment, delivery and support. This created five different learning conditions to which subjects were assigned at random. The present study gives empirical evidence that an electronic-based independent learning environment with discernible support devices can take its place in a traditional university setting. Our results indicate that the cognitive outcomes of students' learning in a computer-based environment are neither fostered nor hindered by attitudes towards computers. The merely cognitive aspect of attitude towards computers, i.e., ‘interest in learning about computers’, affects the perception of structure in the materials; more interested students have a better perception of structure. Students with better prior knowledge and having fewer problems with statistics have a better perception of the learning access to the contents. In order to construct electronic learning environments, further investigation is needed into ‘student characteristics’ interacting with ‘learning environment characteristics’, and this is currently in progress by our group. Patient's Perceptions of an Anesthesia Preoperative Computerized Patient Interview Our desire to elicit a more complete medical history from our patients ledto the implementation of a preoperative computerized interview. We previouslydemonstrated the effectiveness of the interview by computing its meancompletion time for the overall patient population (n= 120), andfurther examined the effects of age, gender, and educational level. In thisstudy, we investigated patient perception of the interview itself. Before andafter taking the computer interview, we asked the patients to complete a paperand pencil questionnaire comprised of sixteen questions, expressing theirfeelings toward the computer interview. Responses elicited prior to taking thecomputer interview were compared with those obtained afterward. TheStuart–Maxwell test was used to determine statistically significantdifferences in answers before and after the interview. Initial questionnaireresponses reflected a positive attitude toward computer usage which becameeven stronger after the interview. The only negative responses elicited werereally more “doctor positive” than “computernegative.” We conclude that patients looked favorably upon participatingin a computerized medical interview provided that physician–patientcontact is maintained. C2 Local convexity-preserving interpolation through the control point form method nuous convexity-preserving parametric curves in ℝ2 is presented.  The control point form method, which was developed in the field of numerical grid generation, is used here to construct interpolating curves. Good control over the shape of the curves is obtained thanks to the capability of the proposed approach to interpolate not only the data points, but also  some directions suitably associated with them. Discrete element simulation and the contact problem his paper addresses the problem of contact detection in discrete element multibody dynamic simulations. We present an overview of the problem and a detail description of a new object representation scheme called the discrete function representation (DFR). This representation is designed to reduce the computational cost of both contact detection and the more difficult problem of contact resolution. The scheme has a maximum theoretical complexity of orderO(N) for contact resolution between bodies defined byN boundary points. In practice, the discrete element method constrains overlap between objects and the actual complexity is approximately
$$O(\sqrt {(N)} $$
 giving a speedup of nearly 2 orders of magnitude over traditional algorithms for systems with more than 1000 objects. The technique is robust and is able to handle convex and concave object geometries, including objects containing holes. Examples of relatively large discrete element simulations in three dimensions are presented. Evaluating the usability of the Siemens C10 Mobile Phone going beyond common practice in industry This paper describes the usability evaluation conducted at Siemens of the prototype for a novel interface of a cellular telephone. The aim of the paper is to show the advantages of more systematic usability testing in contrast to low-cost (often called “quick and dirty”) usability testing. The test provided key data for the decision to implement the new user interface. A quick and dirty test would not have been sufficient to achieve this. The interface design itself is presented followed by a description of the test method, the 80 subjects sample, and the results. The conclusions focus on lessons learnt by conducting an extended study and on the need of integrating usability evaluation in the product cycle. Agent-based Drivers’ Information Assistance System “Drivers’ Information Assistance System (DIA system)” is an ITS (Intelligent Transport Systems) application framework that provides agent-based information assistance to drivers through car navigation systems or on-board PCs.DIA system enables flexible information retrieval over the Internet using intelligent mobile agent, and incorporates a high-speed event delivery facility that makes real-time information service possible. The goal of the system is to provide up to the minute information and services related to driver needs, such as parking lot vacancy information. Crucial to making this a practical operation is the agent-based ability to access the network while the vehicle is in motion. On using network RAM as a non‐volatile buffer File systems and databases usually make several synchronous disk write accesses in order to make sure that the disk always has a consistent view of their data, so that it can be recovered in the case of a system crash. Since synchronous disk operations are slow, some systems choose to employ asynchronous disk write operations that improve performance at the cost of low reliability: in case of a system crash all data that have not yet been written to disk are lost. In this paper we describe a software‐based Non‐Volatile RAM system that achieves the high performance of asynchronous write operations without sacrificing the reliability of synchronous write operations. Our system takes a set of volatile main memories residing in independent workstations and transforms it into a non‐volatile memory buffer – much like RAIDS do with magnetic disks. It then uses this non‐volatile buffer as an intermediate storage space in order to acknowledge synchronous write operations before actually writing the data to magnetic disk, but after writing the data to (intermediate) stable storage. We demonstrate the performance advantages of our system using both simulation and experimental evaluation. On the Decidability of the Equivalence Problem for Orthogonal Sequential Programs We introduce a new class OrtSP of first-order sequential programs. This class of programs is characterized by means of orthogonal substitutions θ = x1/t1, ..., xn/tn such that none of the terms ti occurs in the other terms tj, j ≠ i. We show that the equivalence problem for programs in OrtSP is decidable. We select also a subclass OrtSPout of orthogonal programs and demonstrate that the equivalence problem for programs in OrtSPout is decidable in polynomial time when the alphabet of relational symbols is finite and fixed. Media Production: Towards Creative Collaboration Using Communication Networks To examine the diffusion of remote collaboration technologies within the media production industries, a series of case studies was recently conducted with early adopters of advanced electronic networks in Sydney, Los Angeles and London. The studies assessed: 1) user reactions to these collaboration technologies and types of activities being supported and 2) factors influencing their adoption decisions. Interviews conducted also provided early indications of the conditions likely to facilitate remote collaboration and the likely impacts on work practices in media production organizations. It was established that electronic delivery, remote access to resources and materials, and remote creative collaboration were all being carried out, even internationally. Although most network applications were routine substitutions for non-electronic equivalents (e.g. couriers or catalogue browsing), some did involve shared creative activities, thus confirming that remote creative collaboration is a viable option. Key factors influencing network adoption were cost considerations and regulatory issues, time savings and productivity, and security concerns. Certain industry segments -- animation, post-production, and advertising -- were more likely to be early adopters, as were companies who found innovative ways to achieve greater benefits. Conditions likely to facilitate remote collaboration include more sophisticated change-agent strategies, increasing the perceived control of creative outputs, developing and maintaining trust, providing more auxiliary support for coordination needs, and making more effective use of timing and time-zone differences. Likely impacts of remote collaboration in media production are: more overlap between pre-production, production, and post-production activities; faster work pace; enhanced creativity; and improved quality of work life. Preserving communication context: Virtual workspace and interpersonal space in Japanese CSCW The past decade has seen the development of a perspective holding that technology is socially constructed. This paper examines the social construction of one group of technologies: systems for computer-supported cooperative work (CSCW). It describes the design of CSCW in Japan, with particular attention to the influence of culture on the design process. Two case studies are presented to illustrate the argument that culture is an important factor in technology design, despite commonly held assumptions about the neutrality and objectivity of science and technology. The paper further argues that, by looking at CSCW systems as texts which reflect the context of their production and the society from which they come, we may be better able to understand the transformations that operate when these texts are ‘read’ in the contexts of their implementation. Intelligent simulation tools for mining large scientific data sets This paper describes problems, challenges, and opportunities forintelligent simulation of physical systems. Prototype intelligent simulation tools have been constructed for interpreting massive data sets from physical fields and for designing engineering systems. We identify the characteristics of intelligent simulation and describe several concrete application examples. These applications, which include weather data interpretation, distributed control optimization, and spatio-temporal diffusion-reaction pattern analysis, demonstrate that intelligent simulation tools are indispensable for the rapid prototyping of application programs in many challenging scientific and engineering domains.