An algorithm for optimal minimax routing in ATM networks Asynchronous Transfer Mode (ATM) has been adopted by the CCITT as the transport mode in which Broadband ISDN will be based. In this paper, we formulate the problem of routing cells in an ATM network as an optimization problem. The objective is to minimize the largest cell loss probability among all links. The constraints correspond to a multicommodity network flow problem with gains. An algorithm to determine a global optimal flow assignment is presented. The minimax routing algorithm was implemented and tested on several sample networks. The computational experiments show that the algorithm is computationally efficient. Sympathetic nervous activity and cardiovascular variability after a 3-day tail suspension in rats The effects of a 3-day tail suspension on central and peripheral sympathetic activity were studied in rats by determining the in vivo noradrenaline (NA) turnover in the brain cell groups involved in central blood pressure control (A1, A2, A5 and A6) and in two peripheral organs, heart and kidneys. In addition, cardiovascular parameters and their variabilities were investigated by recording blood pressure (BP) and heart rate (HR) before and after suspension. These measurements were processed by spectrum analysis to assess the influence of tail suspension on autonomic balance. The NA turnover in the suspended rats was markedly reduced in A2 (−49%, P<0.01) and A5 (−38%, P<0.01) nuclei but unchanged in A1 and A6 cell groups compared with the control rats. Peripheral NA turnover was decreased in cardiac atria (−44%, P<0.001) and ventricles (−27%, P<0.01) while it was unchanged in kidneys after suspension. The BP, HR and their variabilities were similar in both groups of animals and showed no changes after suspension compared with baseline values. Spectrum analysis of BP and HR in our conscious suspended rats revealed no changes in power spectrum density or in peak frequencies. The discrepancy between the decrease in central sympathetic activity and the absence of changes in cardiovascular parameters after tail suspension raises the question of the validity of the tail suspended rat model when studying the cardiovascular deconditioning observed in humans after an exposure to actual or simulated weightlessness. Computer-administered versus paper-and-pencil surveys and the effect of sample selection Airport patrons answered a self-administered questionnaire regarding their satisfaction with various airport facilities and operations. The questionnaire was administered either by a computer touch-sensitive screen or by a contextually identical paper-and-pencil version. For the latter method, respondents were selected randomly, and for the former, they were either randomly selected or self-selected. The effect of the method of questionnaire administration on the rating scales was very small when the samples were selected at random. However, there were substantial differences in ratings between self-selected and randomly selected respondents: The former gave consistently more negative ratings. These differences are probably due to psychological factors such as motivation to participate. Also, it was found that self-selected persons using the computer were more likely to make comments. The findings of this study are discussed with emphasis on their implications for computer interactive surveys. A universal building block for the approximate analysis of a shared buffer ATM switch architecture A universal analytic approximation is proposed for the performance analysis of a general queueing model of a shared buffer ATM switch architecture with bursty arrivals. The forms of the joint, aggregate and marginal state probabilities are characterised via entropy maximisation. As an application, a continuous-time maximum entropy (ME) solution is implemented at equilibrium by assuming that the arrival process to each port of the ATM switch is modelled by a Compound Poisson Process (CPP) with geometrically distributed batches. Consequently, efficientz-transform-type recursive expressions of low computational cost are derived. Validation tests against simulation show that the ME approximation is credible with a very good error-level. Moreover, performance bounds for the mean queue length and cell-loss probability at each output port are experimentally defined over those generated by Interrupted Poisson Processes (IPPs) having the same first two interarrival-time moments. Assessing the effect on high school teachers of direct and unrestricted access to the internet: A case study of an east central florida high school The purpose of this study was to investigate the effect direct and unrestricted access to the Internet had on a group of high school teachers. Based on the naturalistic inquiry paradigm, this study explored the barriers these teachers encountered when using the Internet, how and when they elected to use the Internet, the factors that influenced their continued use of the Internet, and the transitions they experienced from using the Internet. Data collection was based on Patton's (1990) three approaches to interviewing; data analysis was based in part on Miles and Huberman's (1984) model of data reduction and display and on Spradley's (1979) task of domain analysis. Findings suggested: that teachers require ongoing Internet training, technical support, home Internet access, and time in which to learn and incorporate the Internet into their classes; that Internet use can increase teachers' self-esteem and improve their attitudes toward computers and education; and that use of the Internet by teachers encourages them to restructure their classes and schedules to accommodate Internet resources within their classrooms. Bandwidth allocation in ATM networks In an ATM network, bandwidth is allocated at different levels and in different stages. At the physical level, the ATM topology can be dynamically reconfigured by adding/removing truns between ATM switches. This allocation of bandwidth is made possible by the SONET Synchronous Transfer Mode (STM) infrastructure equipped with Digital Cross Connect Systems (DCSs). We will refer to this allocation asSTM allocation. At the ATM level, we can allocate bandwidth to individual Virtual Circuits (ATM-VC allocation) as well as to Virtual Paths (ATM-VP allocation). For example, in order to implement the Connectionless Network Access layer functions we find it convenient to organize the Virtual Paths in a Connectionless Overlay Network. This introduces another type of bandwidth allocation (CLS allocation). In this paper, we address and formulate the above bandwidth allocation problems, and propose efficient techniques for their solution. We illustrate these techniques with examples based on STM and CLS allocation, respectively. Efficient window flow control for high speed data networks with small buffers As the transmission speeds of emerging data networks scale up, the effects of propagation delays, which do not scale, become quite consequential for the design of sliding windows which are needed for congestion control. It was previously shown that optimal window lengths grow linearly with transmission speed λ, thus making the cost of memory for buffers a major factor. However, it was also shown that the moments of the number of packets in the buffers are onlyO(
$$\sqrt {{\mathbf{ }}\lambda }$$
), the remaining packets are in the course of being propagated. This fact underlies the proposal made here which requires smallO(
$$\sqrt {{\mathbf{ }}\lambda {\mathbf{ }}ln{\mathbf{ }}\lambda }$$
) buffers and yet guarantees that the ratio of the realized throughput to the ideal throughput approaches unity with increasing λ. That is, buffers when properly sized overflow so rarely that even with a rudimentary (conversely, easily implemented) protocol like go-back-n, the loss in throughput due to retransmissions is negligible. This result is arrived at by obtaining an explicit characterization for large λ of thetail of the distribution of buffer occupancy in the closed network with window sized buffers; in the case of a single-hop virtual circuit the characterization is by a Gaussian conditioned to be nonnegative. Numerical and simulation results are presented to corroborate the performance predictions of the theory for the case of 45 Mbits/sec transmission speed. A formal description of open distributed processing (ODP) trading based on guidelines for the definition of managed objects (GDMO) New requirements of growing computer networks and information systems have an influence on extended client/server models with increased functionality. This forms the basis for service management in distributed systems which is realized by a service trading concept. This paper studies the requirements derived from the Open Distributed Processing (ODP) Reference Model in order to consider an open service market. Furthermore, it examines management possibilities for describing the service trading scenario. Because of similar architectures and properties ODP services, service offers, types, exporters and traders are mapped onto management components and modeled as managed objects. Therefore, the Guidelines for the Definition of Managed Objects (GDMO) are used. The final concept allows a precise and unambiguous study of the service trading scenario and provides means for exporting and importing of service offers in a distributed environment. Automatizing Parametric Reasoning on Distributed Concurrent Systems There can be different views of a concurrent distributed system, depending on who observes it. The final user may just want to know how the system behaves in terms of its possible sequences of actions, while the designer may want to know what are the sequential components of a system or how are they distributed in space. In other words, there is not a widely accepted single semantic model for concurrent systems. This paper describes a parametric verification tool for process description languages. It performs a symbolic execution of processes at different levels of abstraction and verifies deadlock and reachability properties. The tool also provides facilities to check behavioural equivalences. In addition to the classical interleaving semantics, truly concurrent approaches based on the notion of causality and locality are considered. This allows us to compare the expressive power of different models within the same environment. In this respect, we have verified many of the examples given in the literature using our tool. A robust heuristic for the Generalized Assignment Problem The Generalized Assignment Problem, in the class of NP-hard problems, occurs in a wide range of applications — vehicle packing, computers, and logistics, to name only a few. Previous research has been concentrated on optimization methodologies for the GAP. Because the Generalized Assignment Problem is NP-hard, optimization methods tend to require larger computation times for large-scale problems. This paper presents a new heuristic,Variable-Depth-Search Heuristic (VDSH). We show that on the sets of large test problems, the quality of the solution found by VDSH exceeds that of the leading heuristic by an average of over twenty percent, while maintaining acceptable solution times. On difficult problem instances, VDSH provides solutions having costs 140% less than those found by the leading heuristic. A duality gap analysis of VDSH demonstrates the robustness of our heuristics. Bandwidth allocation and access control in high-speed networks The problem of bandwidth allocation and access regulation arises in the congestion control of Broadband ISDN networks. This paper assumes that a single user, described by an on-off fluid model, is connected to the network via a leaky bucket access control mechanism. The bandwidth allocated to this user and the leaky bucket parameters are to be selected so as to guarantee a negotiated level of delay probability at the access point and packet loss probability in the network which is modelled as an output buffer. The design problem is to minimize the allocated bandwidth subject to service guarantees and stability conditions for the input and output buffers. We provide a desirable feasible solution to the design problem. The paper studies the effect of non-conforming users on the network performance using the leaky bucket access control corresponding to this feasible solution. We provide expressions that quantify the impact of the leaky bucket parameters in access regulation and the worst-case queueing behavior at the output buffer. Finally, we discuss the extension of this methodology to the multiple leaky buckets case. Design of software for safety critical systems In this paper, we provide an overview of the use of formal methods in the development of safety critical systems and the notion ofsafety in the context. Our attempt would be to draw lessons from the various research efforts that have gone in towards the development of robust/reliable software for safety-critical systems. In the context of India leaping into hi-tech areas, we argue for the need of a thrust in the development of quality software and also discuss the steps to be initiated towards such a goal. Ninth graders' attitudes towards selected uses of technology Technology has become affordable and available for science teachers of all grade levels. This study presents the results of collecting attitudinal data from over 240 ninth grade physical science students prior to the integration of technology into their science curriculum. The data were evaluated utilizing a probabilistic model, which corrects for the nonlinearity of rating scale responses. Results indicate that surveyed students, on average, were supportive of the integration of a wide range of technology into their classroom. Although students were generally positive, they were statistically more supportive of activities that involved the sending of electronic messages to other students when a comparison was made to their attitudes toward the collecting of data with computer probes. The results suggest that physical science teachers may want to initiate the integration of technology into classes by first requiring students to use electronic mail to share data collected without the aid of a computer. This activity could, in turn, be followed by labs that require the collecting of data with computer probes and subsequent sharing of that data with other students through electronic mail. Diffusion approximation of systems with repeated calls and an unreliable server We consider single-server queueing systems with repeated calls and an unreliable server, which may fail both when free and when busy. A central limit theorem and a diffusion approximation theorem are obtained for the queue as a time-dependent process in the case of a low rate of repeated calls. Statistical relationships between systolic blood pressure and heart rate and their functional significance in conscious rats  The medical applications of the internet  Book reviews  Computer conferencing: A new medium for investigating issues in gender and learning Claims have been made that computer mediated communication (CMC) is a potentially highly participatory and democratic medium because it reduces the requirement to interrupt or wait your turn to speak. Such aspects of discussion have been shown to be relevant to differences in male and female participation in group discussions. In general, men have been found to take more turns and to speak longer than women in mixed sex groups. Men are also said to characteristically speak about “things”, take centre stage and give opinions. Women on the other hand are more likely to emphasis people rather than things, and to build and maintain relations in the way they talk. These two styles have been described as “report talk” of men and “rapport talk” of women.In this paper we describe some preliminary findings on the impact of using CMC and its effect on traditional gender participation differences. We look first at turn taking by men and women in computer conferences, and then how women in particular experience differences in the kind of contributions made to the conferences by men and women. Finally, we look at the actual contributions made by men and women and the extent they differ from each other. Generating conformance tests for nondeterministic protocol machines We present a method of generating test cases from the software specifications which are modeled by nondeterministic finite state machines. It is applicable to both non-deterministic and deterministic finite state machines. When applied to deterministic machines, this method yields usually smaller test suites with full fault coverage than the existing methods that also assure full fault coverage. In particular, the proposed method can be used to test the control portion of software specified in the formal specification languages SDL or ESTELLE. Canonical cactus representation for minimum cuts It is known that all minimum cuts in a networkN can be embedded in a cactus whose size is bounded by a linear function of the number of vertices inN, such that any minimum cut ofN can be easily obtained as a minimum cut of the cactus. However, such a representation for a given network is not unique. We introduce two canonical forms of cactus representation for the minimum cuts and show their uniqueness. These cacti contain at most twice as many vertices asN. Processing real-time transactions in a replicated database system A database system supporting a real-time application has to provide real-time information to the executing transactions. Each real-time transaction is associated with a timing constraint, typically in the form of a deadline. It is difficult to satisfy all timing constraints due to the consistency requirements of the underlying database. In scheduling the transactions it is aimed to process as many transactions as possible within their deadlines. Replicated database systems possess desirable features for real-time applications, such as a high level of data availability, and potentially improved response time for queries. On the other hand, multiple copy updates lead to a considerable overhead due to the communication required among the data sites holding the copies. In this paper, we investigate the impact of storing multiple copies of data on satisfying the timing constraints of real-time transactions. A detailed performance model of a distributed database system is employed in evaluating the effects of various workload parameters and design alternatives on the system performance. The performance is expressed in terms of the fraction of satisfied transaction deadlines. A comparison of several real-time concurrency control protocols, which are based on different approaches in involving timing constraints of transactions in scheduling, is also provided in performance experiments. G-networks: a unifying model for neural and queueing networks We survey results concerning a new stochastic network we have developed [1–7], which was initially motivated by neural network modelling [1], or — as we called it — by queueing networks with positive and negative customers [2, 3]. Indeed, it is well known that signals in neural networks are formed by impulses or action potentials, traveling much like customers in a queueing network. We call this model a G-network because it serves as a unifying basis for diverse areas of stochastic modelling in queueing networks, computer networks, computer system performance and neural networks. In its simplest version, “negative” and “positive” signals or customers circulate among a finite set of units, modelling inhibitory and excitatory signals of a neural network, or “negative and positive customers” of a queueing network. Signals can arrive either from other units or from the outside world. Positive signals are accumulated at the input of each unit, and constitute its signal potential. The state of each unit or neuron is its signal potential (which is equivalent to the queue length), while the network state is the vector of signal potentials at each neuron. If its potential is positive, a unit or neuron fires, and sends out signals to the other neurons or to the outside world. As it does so, its signal potential is depleted. In the Markovian case, this model has product form, i.e. the steady-state probability distribution of its potential vector is the product of the marginal probabilities of the potential at each neuron. The signal flow equations of the network, which describe the rate at which positive or negative signals arrive to each neuron, are non-linear. We discuss the relationship between this model and the usual connectionist (formal) model of neural networks, and present applications to combinatorial optimization and to image texture processing. Extensions of the model to the case of “multiple signal classes”, and to “networks with triggered customer motion” are presented. We also examine the general stability conditions which guarantee that the network has a well-defined steady-state behaviour. Collaborative writing in multiple discourse contexts Research in computer-supported writing has traditionally compared electronic communication with oral, face-to-face communication to identify the benefits and weaknesses of each, as if they entailed dichotomous choices. In this article, we challenge that view and argue instead that any form of communication and its educational usefulness is shaped by the situation in which it is used, the backgrounds and goals of the participants, the institutional and technological setup, and the intended purpose of the medium. Three modes of communication in one graduate course are examined — oral discussion, synchronous written discussion on a local area network, and asynchronous written postings on an email list set up for the class. It was found that patterns of participation, topic introduction, and topic development differed across the three communication modes, but that the three were interwoven with each other and embedded within the larger classroom context and forms of knowledge creation in the class. Thus, rather than examining different communication media separately, researchers interested in understanding computer-supported collaborative writing need to look at how different media are used to create a “meta-medium,” which is established by the discourse community involved. A modified transition tour protocol test method Protocol conformance test is a procedure to validate whether the implementation of a communication protocol conforms to its specification. A modified transition tour protocol test method is proposed in this paper. The modified transition tourprotocol test method is based on the executable rule-based specification and implementation that are realized by using the OPS5 production system. Instead of using some optimization algorithms to minimize test sequences, the new test method is based on modifying test architectures and enhancing Formal Description Techniques' (FDTs) functionalities so that they are powerful enough to be used in both the design phase and the test phase. The conresponding test architectures for local, distributed, coordinated, remote, and ferry control methods also need to be modified. In this paper, we will present the major concept and the test procedure of the modified transition tour method. Additionally, we also present the logical design of the corresponding coordinated test system. Collaborative writing and technological change: Implications for writing practice and system design  International computer networks and new possibilities for scientific cooperation in crystallography Global computer networks remove geographical and territorial limitations from free exchange of information. Electronic mail, interactive communications, and data servers help scientists keep in contact with each other and with other research groups by exchanging the latest scientific news and taking part in electronic conferences. The international community of crystallographers is actively involved in the system of computer communications. This is due to the large crystallographic database and collaborative efforts of crystallographers aimed at developing the necessary service systems and standards for electronic representation of crystallographic texts. Computer networks give Russian scientists access to foreign structural databases. A scheduling discipline and admission control policy for xunet 2 Xunet 2 is a collaborative research program with a goal of understanding the fundamental issues in the performance of ATM networks. These networks are expected to carry a mixture of constant bit-rate traffic, variable bit-rate traffic and computer traffic spanning a wide range of performance requirements. This paper describes these service requirements and matches them with performance guarantees that can be provided by the scheduling discipline supported by an experimental ATM switch. The scheduler supports per-virtual-circuit queueing and several priorities of round robin service in order to segregate real-time and non-real-time traffic and provide fair sharing for bursty computer traffic. Detailed simulations show that real-time traffic can be efficiently integrated with non-real-time traffic using appropriate call admission policies and enhancements to traditional round robin scheduling. While the present study focuses on providing quality of service guarantees in the Xunet 2 network, the design of the scheduler and the call admission policies are relevant to ATM networks in general. An educators’ guide to information access across the internet Educational use of the Internet network has exploded in the past few years. Most colleges and universities now provide Internet access to students and educators for instructional and reasearch purposes. Electronic mail, on-line conferencing, software access, and remote login are some of the many services which make it convenient to use the Internet as a global database. Since data is distributed in thousands of computers worldwide, accessing information in an organized manner is sometimes complicated. Client software tools are available that facilitate access to information by providing the user with a more intuitive interface. This paper provides summary information on the use of listservs, telnet, ftp, archie, and gopher application tools which are available to connect to and access data from remote hosts on the Internet. A queueing theoretic methodology for the analysis of separable conflict resolution algorithms with variable length elementary events We describe a queueing theoretic approach to the delay analysis for the class of synchronous random-access protocols consisting of a Capetanakis-type Tree Algorithm for conflict resolution and a window algorithm for channel access. Our method features a stochastic decomposition, in which a major component of the delay is viewed as a discrete time queueing problem, where each window (selected by the channel access algorithm) becomes a customer requiring service in the form of conflict resolution. This technique is sufficiently powerful to give us the distribution of the packet delay in steady state. In this paper, we extend our method to allow the durations of elementary algorithmic steps to take on a general distribution (rather than being constants), which allows us to provide a unified treatment of channels with shared errors, some types of explicit reservation systems, and Local Area Networks with carrier sensing and/or collision detection, possibly in combination with variable size packets. Comparative study on the effects of groupware and conventional technologies on the efficiency of collaborative writing In this paper the concept of efficiency in collaborative writing is considered in detail and a definition of efficiency is proposed. The definition of efficiency leads to the development of a research framework that delineates five operational measures of efficiency: (a) writing activities efficiency, (b) coordination efficiency, (c) quality of output, (d) absence of breakdowns, and (e) satisfaction with group performance. A comparative study is subsequently presented on the effects that groupware and conventional technologies have on the effciency of collaborative writing. The hypothesis is advanced that groupware can improve the efficiency of collaborative writing over conventional technologies. The results seem to support the hypothesis and indicate that (a) the groupware system examined in this study (MUCH system) offers efficiency benefits in terms of coordination, (b) MUCH users tend to face communication breakdowns while users of conventional technologies tend to face task-related breakdowns, (c) the documents produced with MUCH are of higher content quality, more coherent, and of higher rhetorical effectiveness than the documents produced with conventional technologies, and (d) the comparison of MUCH with conventional technologies shows no significant difference in terms of their effects on group performance satisfaction. Designing broadcasting algorithms in the postal model for message-passing systems In many distributed-memory parallel computers and high-speed communication networks, the exact structure of the underlying communication network may be ignored. These systems assume that the network creates a complete communication graph between the processors, in which passing messages is associated with communication latencies. In this paper we explore the impact of communication latencies on the design of broadcasting algorithms for fully connected message-passing systems. For this purpose, we introduce thepostal model that incorporates a communication latency parameter λ ≥ 1. This parameter measures the inverse of the ratio between the time it takes an originator of a message to send the message and the time that passes until the recipient of the message receives it. We present an optimal algorithm for broadcasting one message in systems withn processors and communication latency λ, the running time of which is Θ((λ logn)/log(λ + 1)). For broadcastingm ≥ 1 messages, we first examine several generalizations of the algorithm for broadcasting one message and then analyze a family of broadcasting algorithms based on degree-d trees. All the algorithms described in this paper are practical event-driven algorithms that preserve the order of messages. Unslotted CSMA/CD protocol with the threshold control policy We consider a single channelCSM A/CD system withD homogeneous stations and impeded buffer of infinite size. We find a sufficient condition for the model to be stable under the threshold control policy and derive the limiting distribution of the number of messages in the system at the moment of service completion. We also derive the limiting distribution of the number of messages in the system size at arbitrary time by using Markov regenerative processes. Some numerical examples and special cases are also treated. Constitution and monitoring of an epidemiological surveillance network with sentinel general practitioners The Réseau National Télé-informatique de surveillance et d'information sur les Maladies Transmissibles (RNTMT) (French communicable diseases computerised surveillance network) comprises a network of sentinel general practitioners (SGP). These benevolent volunteers are responsible for the weekly epidemiological surveillance. Since its creation, 1,700 SGPs have participated in the RNTMT, representing a total of more than 120,000 connections to the RNTMT telematic service center. The principal motivation of these benevolent SGPs was to ‘actively participate in public health’, although only a minority of them (17.6%) had any training in this field. Such a system, based on the benevolent and voluntary activity of SGPs, requires a good understanding of SGPs' attitudes towards epidemiological surveillance in general and the tool used, in order to quantitatively and qualitatively follow their participation and to provide regular and useful feedback to the surveillance actors. Allocation of buffer capacities in queueing networks with arbitrary topologies Two algorithms are developed to allocateM buffers toN service stations connected arbitrarily in a feed-forward manner. All service times and the interarrival times are assumed to be exponentially distributed. Both methodologies are easy-to-use tools to explore alternative buffer storage configurations and parameter settings during the initial design stages of production systems, communications networks, and flexible manufacturing systems. Architecture and algorithms of the Xphone multimedia communication system We describe the architecture and the algorithms used in Columbia University'sXphone multimedia communication system. The system assumes a “best-effort” operating system and network and provides facilities for call management, intra-application scheduling for the support of continuous data flow and integration with the windowing system, and synchronized video/audio acquisition/playback (locally or across a network) with minimized and bounded end-to-end delay. An algorithm based on time-stamps and device-state information is used for synchronization. The effects of jitter (delay variation) are mitigated with silence detection; the end-to-end delay is kept bounded by a restart mechanism. Finally, for live video sources, we describe a source bit-rate adaptation algorithm that maximizes the video image quality to the available network bandwidth and video display window size. The catalog management strategy of distributed data base systems In this paper the catalog management strategy of the successfully integrating and running DDBMS C-POREL is summarized. The new catalog management strategy and its implementation scheme are based on the analysis of the catalog management methods of the pioneer DDBMS. The goal of the new strategy is to improve the system efficiency. Analysis and practice show that this strategy is successful. Conventional and early token release scheduling models for the IEEE 802.5 token ring We develop analyticalscheduling models for both the original IEEE 802.5 token ring protocol and a recent extension to the original protocol that allows early token release (ETR). A scheduling model is an abstraction that supports reasoning about the timing correctness of a given set of real-time messages scheduled on the network. Scheduling analysis of the original IEEE 802.5 token ring protocol has previously been discussed in Strosnider and Marchok (1989) and Pleinevaux (1992) in the context of improving responsiveness of soft deadline aperiodic messages. In contrast, this paper develops schedulability conditions for arbitrary periodic message sets. The main contributions of this work are: Scheduling models for both the original protocol and ETR protocol; comparison for maximum achievable utilizations for the two protocols; comparison between the original protocol and ETR from a schedulability viewpoint. We also demonstrate the utility of our scheduling models to select network operating parameters such as maximum packet size, and to quantify effects of parameters such as the number of stations, and network size on schedulability. Computer networks break new ground in agency cooperation  HyperCourseware for interactive instruction in the electronic classroom An electronic classroom with computer workstations and multimedia offers tremendous potential for interactive instruction. To support such instruction, HyperCourseware was developed as an environment and authoring system that recreates on a computer network familiar objects of instruction, such as the syllabus, lecture notes, class rolls, seating charts, exams, and grade lists. In addition, it provides interactive and collaborative tools for group discussion, anonymous feedback, student polling, and shared collaborative workspaces. Applications in statistics and cognitive psychology are discussed along with the specific advantages due to hypermedia links, structure of course materials, integration of parts, and classroom interactivity. Student and faculty evaluations have supported the positive educational benefits of both the electronic classroom and HyperCourseware in general. Use of telecommunications for reflective discourse of science teacher leaders This case study explores how a group of teacher leaders (TLCs) used network exchange to reflect upon their involvement with peer leadership and teacher-teacher support. By communicating with each other via a telecommunications network, the teachers discussed how they promoted science projects in the classroom and provided encouragement to other teachers. The network dialogue was specifically designed to facillitate the TLCs' exploration of their experiences as teacher leaders. The network messages were analyzed for content and network patterns, frequency of the TLC conversations and reflections on professional practice, and the types and topics of messages. Findings from the case study suggest that reflective messages about professional practice rarely happen on networks and do not naturally occur in the practice of teaching. However, with specific sociotechnical conditions in place, they can occur more readily. Such conditions include: protected workspace for reflection, retrieved text base, collaborative research, access and response to messages, structure dialogue, linking action with reflection, forming reflective practice inquiry, and participatory motivation. Three important questions stem from this analysis of the discourse on teacher-teacher leadership: (1) Can network-mediated reflective discourse about professional practice in fact take place? (2) What types of network exchanges promote reflective discourse? (3) What sociotechnical factors help sustain or inhibit network-mediated teacher-teacher professional discourse? An optimization problem related to balancing loads on SONET rings We provide a model and a set of solution techniques for an important problem arising in the design of survivable telecommunication networks utilizing fiber-optics-based technologies. The emergence of a synchronous standard for optical signaling called “SONET” allows for an economic implementation of ring designs that provides protection for high capacity services. An objective is to choose a loading of the demands onto a ring design that minimizes associated equipment and facility costs while providing capacity for alternative routing should some link or node fail. After the computational complexity of the problem has been determined, three approximation heuristics, including a mathematical programming dual-ascent solution technique, are described and compared. The heuristics are being successfully applied to actual network design problems arising in Bell operating companies and other telecommunication providers. E-talk: Attitudes and motivation in computer-assisted classroom discussion This paper is the description of an experiment in E-talk, computer-assisted classroom discussion, undertaken at a large southwestern university with a class of intermediate French students. We describe the research design and the results as they relate to the students' attitudes and motivation. The research seems to indicate that there are important benefits to using a local area network (LAN) as a means of encouraging discussion amongst students. Modelling buffer admission mechanisms using stochastic automata networks The stochastic automata networks formalism is an attractive technique to model complex systems with interacting components. Each component of the system is modelled by a single automaton; interactions between components are modelled by labels on the arcs which may represent synchronization and state-dependent transitions. Every automaton is associated with some matrices which allow to build the transition matrix of the underlying Markov chain, using tensor algebra. To illustrate this methodology, we introduce two buffer policies which could be used inAtm switching node. Every policy manages two priority levels which have distinct cell loss requirements. The first buffer policy is based on the push-out mechanism : a high priority cell replaces a low priority cell when the buffer is full. The second policy causes the discarding of all the low priority cells when the user transmits a request to send a burst of cells. In both studies, we compute the loss probabilities of each type of cells under various assumptions.RésuméLe formalisme des réseaux d’automates stochastiques est un modèle attractif pour représenter des systèmes complexes comportant plusieurs composants ayant des interactions entre eux. Chaque composant est modélisé par un automate dont les arcs sont étiquetés par des probabilités et des synchronisations portant sur plusieurs automates. A chaque automate et à chaque transition sont associées des matrices qui permettent grâce à l’algèbre tensorielle de dériver la matrice de transition de la chaîne de Markov sous-jacente. En guise d’illustration, les auteurs présentent deux stratégies de gestion de tampons qui pourraient être utilisées dans un nœudAtm. Chaque stratégie gère deux niveaux de priorité différents qui exigent des taux de perte différents. La première stratégie est basée sur un mécanisme d’écrasement où une cellule de haute priorité remplace une cellule de basse priorité quand le tampon est plein. La seconde stratégie entraîne la destruction de toutes les cellules de basse priorité lorsque l’utilisateur envoie à chaque nœud une requête de transmission d’une rafale importante de cellules. Dans les deux cas, ils calculent les probabilités de perte des cellules de chaque type sous différentes hypothèses. The Cesame project: formal design of high speed multimedia cooperative systems The project Cesame, a collaborativeCnet andCnrs project, aims to develop an adequate methodology, supported by formal techniques and tools, for designing and implementing high speed multimedia cooperative systems. This paper, the first of this special issue of the Annals of Telecommunications, dedicated to Cesame, presents its main purposes and significant results. The rationale of the project is given first. From its global objectives, the set of studies that are under development are presented and the main results, a subset of which only appears in this issue, are summarised. Directions of ongoing work are also given.RésuméLe projet Cesame — conception formelle de systèmes hauts débits multimédias coopératifs — conduit en collaboration entre leCnet et leCnrs, a pour but de développer une nouvelle méthodologie, basée sur des techniques et des outils formels, adaptée à la conception et à la réalisation des futurs systèmes multimédias coopératifs à haut débit. Cet article, le premier de ce numéro des Annales concernant Cesame, en présente les objectifs généraux et les principaux résultats obtenus. La motivation et le contexte global du projet sont d’abord exposés. Ensuite, à partir de ces considérations générales, l’ensemble des études en cours de développement sont données et les résultats correspondants, un sous-ensemble desquels seulement apparaît dans ce numéro, sont résumés. Les axes généraux des travaux à venir sont aussi présentés. Transport layer statistical multicast based on the XTP bucket algorithm Multicast or point-to-multipoint transmission is becoming a major issue for supporting distributed multimedia applications. In this paper, we analyze the service provided by theXtp reliable multicast. We discover several problems and drawbacks, such as multiple retransmission of the same data packets or the protocol inefficiency when performing with large group size and non-broadcast networks. To overcome some of these problems, we introduce new constraints at the sender side to prevent any unnecessary retransmissions. We introduce the service semantic calledstatistical reliable to cope with large group size while keeping a high level of reliability (related to error recovery issues). The quality of service provided by this modified protocol is assessed by simulation experiments for two different network environments :Fddi andAtm. We show that the reliability is almost binary, i.e. all reliable or unreliable at all. If the parameters are correctly sized, we can expect to get an all reliable semantic while using the statistical reliable protocol with the benefit of low protocol overhead. We are now working on a modified version of the proposed protocol to specifically adressAtm based networks.RésuméLa transmission point à multipoint est essentielle au développement d’applications réparties multimédias. Le problème est traité au sein des organismes de normalisation et de nombreux projEts afin de spécifier rapidement un service de type dans la couche transport. L’article étudie le protocoleXtp (Xpress Transfer Protocol) avec un algorithme de protection contre les erreurs basé sur une chaîne de seaux. Ce protocole possède des défauts importants tels que des retransmissions multiples redondantes. Des modifications cêté émetteur permettent d’éviter des retransmissions inutiles. Le concept de service statistiquement fiable autorise des groupes de taille importante tout en conservant un niveau élevé de fiabilité au sens des reprises sur erreur. La qualité de service du protocole modifié est évalué par simulation pour des réseauxFfdi etAtm. En effet les paramètres doivent être dimensionnés selon l’application. On s’intéresse au délai de transmission en fonction du nombre de seaux et à la fiabilité en fonction des paramètres du protocole et de l’environnement. La fiabilité est pratiquement binaire (totale ou inacceptable) avec un faible surdébit. Transport layer for cooperative multimedia applications This paper presents work carried out within the Cesame project for the design of a multimedia highspeed distributed transport provider. The term transport provider is used to target a reference framework but does not preclude any standardized reference model. It gives the objectives and relates the main contributions obtained during the first year of the project. The goal of this task is to monitor, select and design services, protocols and mechanisms for defining a transport provider to support distributed multimedia services. As far as architectural aspects are concerned, a refinement of reference models is mandatory, and work on this topic has already been started within several institutions. Moreover, it is worth to mention that the transport provider will have first to run on top ofAtm/Aal networks and is expected on top of other networks.RésuméCet article présente les travaux réalisés dans le projet Cesame en vue de la conception d’un service et d’un protocole de transport pour applications multimédias réparties à haut débit. Le but de ces travaux est de proposer de nouvelles activités dans ce domaine, sélectionner et concevoir des mécanismes de protocoles et définir des services capables de supporter les besoins des nouvelles applications visées. Les travaux réalisés ont déjà conduit à des extensions significatives des solutions existantes. Elles montrent la nécessité de réviser le modèle de référenceOsi utilisé jusqu’à présent. Des activités ont déjà été initialisées dans ce sens, aussi bien au sein d’organismes de normalisation que de projets. Notons également que le réseau support utilisé comme premier objectif cible sera I’Atm, et que cet aspect a une influence sur les orientations choisies. Néanmoins, le cadre plus général des réseaux hétérogènes interconnectés n’est pas exclu, et fait partie de notre domaine de réflexion générale. Toward a formal specification of multimedia synchronization scenarios This paper introduces time stream Pétri nets (Ts treamPn), a model for the formal specification of multimedia synchronization scenarios. This new model extends time Pétri nets to formally describe the timed behaviour of multimedia objects and streams in asynchronous distributed systems. The proposed approach uses time intervals to label the arcs exiting from the places of the net, and typed transitions to define different firing rules. This model allows a complete and accurate specification of synchronization constraints between multimedia streams and can be used at different levels of granularity.RésuméCet article introduit un modèle formel pour la spécification de scénarios de synchronisation mettant en jeu des flux d’informations multimédias. Ce nouveau modèle appelé « time stream Pétri net » (TsstreamPn) repose sur un formalisme de type réseau de Pétri et associe des intervalles temporels aux arcs entrant sur les transitions. Différentes règles de tir peuvent être associées aux transitions d’unTstreamPn. Ces règles de tir permettent une spécification complète, précise et à différents niveaux de granularité de la synchronisation intra-et inter-flux multimédias. Temporal modelling of real-time communication protocols based on a process/channel approach The design of temporally-predictable real-time software is a major issue in a wide range of computer applications. This paper focuses on the temporal modelling of communication protocols in real-time OSI-based computer networks, and discusses a method which can form the foundation of a tool which gives true temporal representations of such systems. The proposed approach, implemented using the power of a concurrent object-oriented programming language (STRAND), utilises a modelling methodology based on an advanced process/channel model. The paper suggests that the techniques can be applied to a range of problems, illustrated here by an example of an OSI protocol. When is partial trace equivalence adequate? Two processes arepartial trace equivalent iff they can perform the same sequences of actions in isolation. Partial trace equivalence is perhaps the simplest possible notion of process equivalence. In general, it is too simple: it is not usually an adequate semantics. We investigate the circumstances under which it is adequate, which are surprisingly rich. We give two substantial classes of languages for which partial traces are adequate. In one class, partial trace equivalence suffices for total correctness, and operations such as true sequencing are possible; but all processes are determinate and silent moves are not possible. The other class — which includes many standard process calculi, such as CCS and CSP — admits indeterminacy and silent moves, but partial traces only suffice for partial correctness and true sequencing is not definable. On the stochastic timed Pétri nets model and its application to the DQDB protocol The goal of this paper is twofold : at first, to present the stochastic timed Pétri nets model by emphasizing its ability to express the main characteristics of real time distributed systems (parallelism, synchronization by message exchange, time attributes and in particular time constraints) and to allow both qualitative and quantitative analysis (concept of randomized states graph); second, to show a modeling methodology based on this model that allows a rigorous modeling of theDqdb protocol (Qa access, bwb mechanism role,Pa access influence). A new contribution to theQa mechanism has been done (1).RésuméL’objet de cet article est de présenter : en premier lieu, le modèle de réseaux de Pétri temporisés stochastiques qui permet d’une part, d’exprimer les principales caractéristiques des systèmes distribués en temps réel (parallélisme, synchronisation par échange de messages, attributs temporels et enparticulier les contraintes temporelles) et d’autre part, la possibilité d’analyses qualitative et quantitative (concept de graphe d’états probabilisé); et en deuxième lieu, une méthodologie de modélisation basée sur ce modèle permettant une analyse rigoureuse du protocoleDqdb (accèsQa, mécanismeBwb, influence de l’accèsPa). Une contribution nouvelle, concernant l’accèsQa a été faite.