Component based metric for evaluating availability of an information system: an empirical evaluation The aim of the paper is to empirically evaluate the quantitative Availability metric derived from the dependencies among the individual measurable components of an information system. The Availability metric is twofold, based on the operating program and the network delay metric of the information system (for the local bound component composition the availability metric is purely based on the software/operating program, for the remote bound component composition the metric incorporates the delay metric of the network). The metric is used for measuring Availability of an information system from the security perspective, the measurements may be done at the system-design level or for a developed system the metric is applied to the individual working components (software/program code. The system to be evaluated is a network based video monitoring system EES and all the measurements are done using the source code of the system. The steps mentioned in the availability evaluation algorithm are followed in the evaluation process of the system and the final output of the algorithm is the availability score IAV(SyS) for the EES system. The score gives an indication of security of the system with the current design. Review of different classes of RFID authentication protocols Radio-frequency identification (RFID) is an up-and-coming technology. The major limitations of RFID technology are security and privacy concerns. Many methods, including encryption, authentication and hardware techniques, have been presented to overcome security and privacy problems. This paper focuses on authentication protocols. The combination of RFID technology being popular but unsecure has led to an influx of mutual authentication protocols. Authentication protocols are classified as being fully fledged, simple, lightweight or ultra-lightweight. Since 2002, much important research and many protocols have been presented, with some of the protocols requiring further development. The present paper reviews in detail recently proposed RFID mutual authentication protocols, according to the classes of the authentication protocols. The protocols were compared mainly in terms of security, the technique that they are based on, protocols that the presented protocol has been compared with, and finally, the method of verifying the protocol. Important points of the comparisons were collected in two tables. A resource allocation algorithm for throughput maximization with fairness increase based on virtual PRB in MIMO-OFDMA systems This paper deals with a new resource allocation algorithm in downlink MIMO-OFDMA systems. The objective is to maximize the system throughput with respect to fairness criteria since some users may experience bad channel conditions for a long time. Known to be NP-hard, the original optimization problem is divided into two sub-problems where radio resource allocation and power allocation are performed separately. Firstly, a recursive PRB allocation algorithm is performed aiming at maximizing the system throughput. In LTE systems, 41% of sub-carriers are considered unused which introduces spectral efficiency loss. As solution, the eNodeB aggregates the unused sub-carriers by each user to construct a “virtual” PRB to be allocated to seldom served user for fairness and throughput increase. Secondly, power allocation is performed to select a more appropriate MCS. The Analytical Model for Distributed Computer System Parameters Control Based on Multi-factoring Estimations In this paper the approach and mechanisms for the complex analysis of the Distributed Computer System (DCS) parameters taking into account several criteria DCS functioning to select an efficient configuration of DCS resources are suggested. There are the analytical evaluations of DCS parameters such as: performance, security, reliability, data transfer rate, depending on the DCS dimension (number of nodes) taking into account the specific of their realization. The complex analytical model for the DCS parameters is suggested. The model allows estimate the parameters of DCS, depending on the number of nodes. The suggested model allows evaluate the impact of the number of nodes on the parameters of its functionality. In addition, this model on the design phase allows determine the DCS parameters for a certain number of DCS nodes. The suggested model allows set a certain level for the normalized DCS parameters, which should meet the all four parameters of the DCS, and to get the set of nodes, which should form the DCS cluster. Optimization energy consumption with multiple mobile sinks using fuzzy logic in wireless sensor networks Each sensor in WSNs receives data from the limited area under its coverage. The received data is processed by the sensor; then, it is wirelessly transmitted to the sink. Sensors’ energy consumption and the energy hole problem are considered as outstanding challenge of these networks. That is, since sensors use batteries with limited lifetimes and sensors which are closer to the sink transmit more data than remoter sensors, hence, they run up their energies sooner than other sensor nodes. Consequently, optimizing energy consumption is regarded as one of the most critical issues throughout a network’s operational lifetime. In this paper, by dividing a respective area into several smaller areas and using a multiple mobile sink (MS), we proposed an unequal clustering method via fuzzy logic which leads to the reduction of distances among sensors with respect to the movement direction of sink. As a result, the sizes of clusters are reduced. Accordingly, such a reduction in the sizes of clusters and the smart selection of the route by the MS eliminates energy hole issue. Regarding the metrics of FND and HNA, it was found that the proposed method optimized energy consumption for 19%. Hence, it was able to fix energy hole problem in WSNs. A generic framework for optimizing performance metrics by tuning parameters of clustering protocols in WSNs Wireless sensor network (WSN) is a key technology trend in emerging internet of things paradigms which are commonly used for application areas such as smart-cities, smart-grids, wearables, and connected health. There is a wealth of literature which considers various cluster-based routing protocols such as LEACH, HEED, and UHEED where these protocols are compared in terms of the network lifetime and/or the total number of packets successfully received by the base station under various operational conditions. While existing studies present various approaches to form WSN clusters in the most efficient way, various parameters are manually-assigned their values such as the radius of the cluster, the number of nodes in the cluster, and the number of clusters that should be formed to reach the base station. The choice of correct parameters is essential for reaching the most efficient configuration, however existing studies do not specify a systematic way for tuning these parameters. In other words, the optimization of cluster-based WSNs through fine tuning of related system parameters is not considered in the existing studies. We believe that presenting a generic approach to tune the parameters of clustering algorithms in order to optimize the performance metrics of WSNs is a significant contribution. In this study a systematic and an efficient method is presented to tune the parameters of clustering and routing protocols. Instead of brute force, or trial and error approaches, simulated annealing and K-beams algorithms are adopted together with discrete event system simulator OMNET++ with Castalia Framework. Results are presented comparatively with brute force approach in order to show the efficiency of the new approach in finding the optimum configuration in terms of energy efficiency as well as the rate of successfully received packets. A fuzzy geographical routing approach to support real-time multimedia transmission for vehicular ad hoc networks Vehicular ad hoc networks known by their greatly active topology have given rise to new challenges related to routing protocols, issues of less concern in infrastructure-based networks or even in mobile ad hoc networks. Indeed, the high revocability of network topology makes the satisfaction of driver’s requirements very arduous, especially with multimedia applications that need strict quality of service (QoS) support. The main purpose of this paper is to promote real time video traffic by maximizing user gratification while keeping a good QoS. Thus, based on the well-known greedy perimeter stateless routing (GPSR) protocol, we propose a new approach called fuzzy geographical routing (FzGR) that incorporates two fuzzy logic usages. The first takes into consideration three input parameters of QoS: the delay, the size of buffer and the throughput, while it outputs a single relevant metric to prioritize the next-hop with lower concern. The other fuzzy system aims at preserving the concept of basic GPSR by considering the distance measure between each next-hop and the final destination. The proposal has been evaluated and compared to the GPSR using a rigorous metrics analysis regarding QoS and quality of experience. Our extensive experimental results using several simulators (e.g., NS-2, VanetMobiSim and Evalvid), show that FzGR has the ability to increase the performance of the network. Technological aspects of WBANs for health monitoring: a comprehensive review According to the World Health Organization, most of the world population is affected by chronic diseases, obesity, cardiovascular diseases and diabetes while another dominant problem is of aging population. Thus, it is desirable to have cost effective solutions for health monitoring, especially for countries that have minimum conventionally trained healthcare staff and infrastructure. Healthcare has shifted from hospital dominant services to patient dominant services which has thrived WBANs to provide ubiquitous health monitoring by virtue of wearable or implantable sensor nodes that commonly monitor biological signals. As the society becomes more health conscious, WBANs have the potential to revolutionize the way people integrate their health and information technology. Hence, WBANs are desired to strengthen conventional healthcare systems. Notwithstanding the current achievements, technological advances, proposed solutions and commercialized products; WBANs still experience many obstacles in their foolproof adoption. This paper surveys the plethora of WBAN applications and network architecture in detail used for data collection, data transmission and data analysis that form sensor analyst system in the realm of Internet of Things. Wireless communicational technologies are also discussed in this paper. Also, we have categorized the routing protocols and have provided with their critical qualitative analysis. Towards the end we discuss several projects in the field of WBANs and some open research areas. These findings on how the sensor nodes, newest routing protocols and data analysis techniques influence ubiquitous health monitoring sets this survey apart from the already existing surveys on WBANs. Towards overhead mitigation in state-free geographic forwarding protocols for wireless sensor networks Routing has been the most consumptive of all processes engaged in the Wireless Sensor Network communications, thus improving this consumptive process by minimizing the number of overhead bits transmitted is vital. This paper investigates the State-free Geographic Forwarding (SGF) protocols, which employ the cross-layering concept that combines the tasks of the routing and Medium Access Control (MAC) layer to minimize energy consumption. Unfortunately, the numerous SGF protocols proposed in the past utilize a modified variant of the basic 802.11 Distributed Coordinated Function MAC protocol for their routing operations due to its ability to mitigate the hidden terminal problem using the four-way handshake mechanism. The mechanism, however, incurs a substantial amount of overhead, which subsequently affects the end-to-end delay and energy consumption of the network. In line with these, a Directional Compact Geographic Forwarding (DCGF) approach is proposed to mitigate the excessive overhead generated due to the repeated subjection of a multi-hop network to the four-way handshake mechanism. The proposed DCGF utilizes a smart antenna and Quality of Service (QoS) aware aggregation approach to mitigate the spread in a broadcast received and multiple unicast transmissions, respectively. The simulation results show that the proposed DCGF significantly outperforms its base protocol (Dynamic Window Secure Implicit Geographic Forwarding) in terms of message overhead, energy consumed and end-to-end delay. Identify Congested Links with Network Tomography Under Multipath Routing Identifying congested links accurately to ensure the Service Level Agreements is an important but challenging task, since it is costly or even practically unfeasible to monitor massive interior links directly for large networks. Network tomography has been proposed to overcome this problem by using end-to-end (path) measurements. However, most of existing tomographic methods only focus on the loss performance degradation, while paying much less attention the fact that network congestion will also greatly worsen the delay performance. Nevertheless, most of them normally work under single-path routing, which may also get violated in today’s Internet as multipath routing is increasingly common. In this paper, we consider the problem of using end-to-end measurements to identify congested links when multipath routing is employed in a non-tree network. Firstly, we use both link delay variances and link loss rates to model the system constraints between end- to-end paths and the interior links, and transfer the issue of congested link identification as an optimization problem. By theoretically demonstrating that the link delay variances are identifiable from the end-to-end delay measurements with certain topology conditions, we further prove that the above optimization problem is a Non-deterministic Polynomial-time hard (NP-hard) problem. Then in order to solve such an NP-hard problem, two greedy algorithms based on bool and additive congestion statuses are proposed. Lastly, simulation studies show that with extra delay constraints, our proposed algorithms are able to achieve better identification performances than existing methods under multipath routing. An improved algorithm for dispatching the minimum number of electric charging vehicles for wireless sensor networks The very limited sensor battery energy greatly hinders the large-scale, long-term deployments of wireless sensor networks. This paper studies the problem of scheduling the minimum charging vehicles to charge lifetime-critical sensors in a wireless rechargeable sensor network, by utilizing the breakthrough wireless charging technology. Existing studies still employ a number of charging vehicles to charge sensors. The purchase cost of a charging vehicle however is not inexpensive. To further reduce the number of employed charging vehicles, we propose a novel approximation algorithm, by exploring the combinatorial properties of the problem. The techniques exploited in this paper are essentially different from that in existing studies. Not only do we show that the approximation ratio of the proposed algorithm is much better than that of the state-of-the-art, but also extensive experimental results demonstrate that the number of scheduled charging vehicles by the proposed algorithm is at least 10% less than that by the existing algorithms and the total travel energy consumption of the charging vehicles is also smaller than that by the existing algorithms.
 Combinatorial Optimization: Comparison of Heuristic Algorithms in Travelling Salesman Problem The Travelling Salesman Problem (TSP) is an NP-hard problem with high number of possible solutions. The complexity increases with the factorial of n nodes in each specific problem. Meta-heuristic algorithms are an optimization algorithm that able to solve TSP problem towards a satisfactory solution. To date, there are many meta-heuristic algorithms introduced in literatures which consist of different philosophies of intensification and diversification. This paper focuses on 6 heuristic algorithms: Nearest Neighbor, Genetic Algorithm, Simulated Annealing, Tabu Search, Ant Colony Optimization and Tree Physiology Optimization. The study in this paper includes comparison of computation, accuracy and convergence. Using the TSP Solution Strategy for Cloudlet Scheduling in Cloud Computing Cloudlet scheduling in cloud computing is one of the most issues that face the cloud computing environment. This paper presents a new efficient approach, called Traveling Salesman Approach for Cloudlet Scheduling (TSACS), to solve the cloudlet-scheduling problem. The main idea is to convert the cloudlet-scheduling problem into an instance of the Traveling Salesman Problem (TSP) and then apply one of the TSP solution strategies to solve the problem. The proposed approach consists of three phases: clustering phase, converting phase, and assignment phase. In the clustering phase, the proposed approach converts the large size cloudlet-scheduling problem into a small size cluster-scheduling problem to minimize computation time complexity of the proposed approach. In the converting phase, the approach forms the cluster-scheduling problem as an instance of the TSP. In the assignment phase, the approach schedules the clusters into the available virtual machines by using the nearest neighbor algorithm. The proposed approach is evaluated by using the CloudSim and the results are compared with that obtained by the most recent algorithms. The results show that the proposed approach enhances the overall system performance in terms of schedule length, balancing degree, and time complexity. In addition, the proposed TSACS overcomes the oscillation problem of the existing cloudlet-scheduling algorithms. Performance analysis of cooperative spectrum monitoring in cognitive radio network The imperfect spectrum monitoring (SM) is a major obstacle to detect the emergence of primary user (PU) quickly during the cognitive users’ (CUs’) data transmission which results data-loss and introduces the interference at PU. The cooperation in CUs for SM is an effective solution to improve its performance.
 Therefore, in this paper, a scenario, where CUs can cooperate with each other for SM is presented and have analyzed the effect of cooperation on various performance metrics namely, the data-loss, interference efficiency, and energy efficiency. An algorithm is illustrated for the computation of data-loss under various conditions of the traffic intensity of PU and probability of SM error. Moreover, the closed-form expressions of these metrics are derived for the cooperative and non-cooperative SM. Further, the simulation results are presented for various scenarios of traffic intensity, probability of SM error and channel gain between the CUs’ transmitter to PU receiver. Furthermore, the Monte-Carlo simulation results are exploited to consider the random nature of the PUs’ traffic intensity as well as to support the numerically simulated results. Patterns of knowledge sharing in an online affinity space for diabetes Our research explores how people learn as part of everyday contexts and settings and specifically, we explore the discourse of an online affinity space for diabetics, where participants engage in knowledge sharing and storytelling around disease management. We frame the analyses by examining participants’ meaning making discourse for advancing knowledge and practices situated in everyday, practical activity. Social network analyses were conducted to visualize the structure of the community. Analyses of discourse in the affinity space revealed three primary patterns of knowledge sharing: (a) sharing information; (b) extending perspectives; and (c) communicating repertoires of practice. Our analyses describe recurring narratives, discourse patterns, and constructions, which can be seen as part of the cultural model that defines the diabetes affinity space. We found that personalized storytelling, which included sharing of personal experiences and data such as blood glucose levels, acted as a primary pattern of language use. Our results contribute to an understanding of the role of discourse in supporting personal and community practices and learning in online affinity spaces, as well as implications for the design of technology in supporting knowledge sharing in such spaces. Comprehensive review for energy efficient hierarchical routing protocols on wireless sensor networks In recent years, wireless sensor networks (WSNs) have played a major role in applications such as tracking and monitoring in remote environments. Designing energy efficient protocols for routing of data events is a major challenge due to the dynamic topology and distributed nature of WSNs. Main aim of the paper is to discuss hierarchical routing protocols in order to improve the energy efficiency and network lifetime. This paper provides a discussion about hierarchical energy efficient routing protocols based on classical and swarm intelligence approach. The routing protocols belonging to both categories can be summarized according to energy efficiency, data aggregation, location awareness, QoS, scalability, load balancing, fault tolerance, query based and multipath. A systematic literature review has been conducted for hierarchical energy efficient routing protocols reported from 2012 to 2017. This survey provides a technical direction for researchers on how to develop routing protocols. Finally, research gaps in the reviewed protocols and the potential future aspects have been discussed.Graphical Abstract Link quality evaluation of a wireless sensor network in metal marine environments Wireless sensor networks (WSN) are finding increasing use in all-metal marine environments such as ships, oil and gas rigs, freight container terminals, and marine energy platforms. However, wireless propagation in an all-metal environment with ducting and sealed doors between compartments is difficult to model, and the operating machinery further complicates wireless network planning. This makes it necessary to characterize the performance of the physical wireless links in the actual operating environments. However, little has been reported in the literature on methodologies for measuring the full range of physical link quality indicators. In this paper, we present a methodology for doing this that we have verified by the deployment of a 2.4 GHz network of 18 nodes in three different all-metal scenarios: a cluster of freight containers, a full-sized shore-based working ship’s engine room training facility, and an operational ship’s engine room. The output variables included the key link quality indicators of packet delivery ratio (PDR), RSSI, and LQI for every possible link, as well as the performance of every node. We believe that this is the first time that this full range of physical link quality indicators has been measured in this type of application environment. We found that in all three scenarios the network performed with over 90% PDR average. However, as the scenarios become more complex, the communications become more unpredictable, yielding a wider transition zone, indicating that although a WSN could operate in these scenarios under different conditions, a pre-deployment practical study is essential for each new scenario. Predicting trading interactions in an online marketplace through location-based and online social networks Link prediction is a prominent research direction e.g., for inferring upcoming interactions to be used in recommender systems. Although this problem of predicting links between users has been extensively studied in the past, research investigating this issue simultaneously in multiplex networks is rather rare so far. This is the focus of this paper. We investigate the extent to which trading interactions between sellers and buyers within an online marketplace platform can be predicted based on three different but overlapping networks—an online social network, a location-based social network and a trading network. In particular, we conducted the study in the context of the virtual world Second Life. For that, we crawled according data of the online social network, user information of the location-based social network obtained by specialized bots, and we extracted purchases of the trading network. Overall, we generated and used 57 topological and homophilic features in different constellations to predict trading interactions between user pairs. We focused on both unsupervised as well as supervised learning methods. For supervised learning, we achieved accuracy values up to $$92.5\%$$92.5%, for unsupervised learning we obtained nDCG values up to over $$97\%$$97% and MAP values up to $$75\%$$75%. 
Indoor navigation systems based on data mining techniques in internet of things: a survey Internet of Things (IoT) is turning into an essential part of daily life, and numerous IoT-based scenarios will be seen in future of modern cities ranging from small indoor situations to huge outdoor environments. In this era, navigation continues to be a crucial element in both outdoor and indoor environments, and many solutions have been provided in both cases. On the other side, recent smart objects have produced a substantial amount of various data which demands sophisticated data mining solutions to cope with them. This paper presents a detailed review of previous studies on using data mining techniques in indoor navigation systems for the loT scenarios. We aim to understand what type of navigation problems exist in different IoT scenarios with a focus on indoor environments and later on we investigate how data mining solutions can provide solutions on those challenges. Breaking anonymity of some recent lightweight RFID authentication protocols Due to their impressive advantages, Radio Frequency IDentification (RFID) systems are ubiquitously found in various novel applications. These applications are usually in need of quick and accurate authentication or identification. In many cases, it has been shown that if such systems are not properly designed, an adversary can cause security and privacy concerns for end-users. In order to deal with these concerns, impressive endeavors have been made which have resulted in various RFID authentications being proposed. In this study, we analyze three lightweight RFID authentication protocols proposed in Wireless Personal Communications (2014), Computers & Security (2015) and Wireless Networks (2016). We show that none of the studied protocols provides the desired security and privacy required by the end-users. We present various security and privacy attacks such as secret parameter reveal, impersonation, DoS, traceability, and forward traceability against the studied protocols. Our attacks are mounted in the Ouafi–Phan RFID formal privacy model which is a modified version of well-known Juels–Weis privacy model. The Postdigital Human: Making the History of the Future  Reducing the site survey using fingerprint refinement for cost-efficient indoor location Recently, RSS fingerprint-based location has been considered as a low-complexity solution for indoor localization. However, constructing a fingerprint map requires a great amount of manual effort to achieve a high location accuracy. In this paper, we present a refinement method to reduce the necessary manual effort without degrading the location accuracy. This method transforms a coarse-gained fingerprint map containing only a small number of offline samples into a high-density fingerprint map by augmenting the map with artificial samples. In particular, a local-to-local strategy is proposed to improve the accuracy of artificial samples. Furthermore, we propose a judgment criterion to determine whether a fingerprint map should continue to be refined when it has reached a certain density and which refined fingerprint map can achieve the best location accuracy. Extensive experimental results show that our proposed method can significantly improve the location accuracy without additional manual effort compared with the original fingerprint map. Mobility analysis of CoMP-based ultra-dense networks with stochastic geometry methods This paper conducts mobility analysis in Coordinated multipoint (CoMP) based ultra-dense networks (UDNs) where channel state information (CSI) is outdated due to feedback delay. To depict the impact of mobility on CoMP-based UDNs, related analyses are carried out from two perspectives. For one thing, we define CoMP handover probability as the probability that the serving cluster doesn’t remain the best candidate during the movement and further give its theoretical expression with stochastic geometry methods. For another, coverage probability is evaluated by considering the effect of outdated CSI caused by mobility. Furthermore, to capture the comprehensive effect of mobility on network performance, we propound the effective coverage probability (ECP) incorporating the above two effects. Numerical results illustrate that with the increase of users’ velocity, CoMP handover probability increases while coverage probability decreases but can be compensated by relatively larger cluster size schemes or denser access points deployment. Also, our proposed performance metric ECP reveals the tradeoff between CoMP handover probability and coverage probability, which depends on cluster size and network sensitivity to handover failure. Fuzzy self organizing maps-based DDoS mitigation mechanism for software defined networking in cloud computing The characteristic features of cloud computing deployment make it highly vulnerable to distributed denial of service (DDoS) attacks. The recent advancement in software-defined networking (SDN) enhances the possibilities for defeating DDoS attacks in cloud computing environments. This option to improve the probability of defeating DDoS attacks is made feasible through the striking features of SDN that include their capability for software-oriented traffic investigation, network global dimension, dynamically updating forwarding rules and centralized point of control. This paper presents a Fuzzy self organizing maps-based DDOS mitigation (FSOMDM) technique that is ideally and suitably designed for improving the SDN capabilities of cloud computing. FSOMDM is the enhanced neural network model that effectively replaces the neurons of the traditional Kohonen neural network model through updating fuzzy rules. The property of software-oriented traffic investigation is utilized in this process and the fuzzy rule is used for exploring the dimension of input space from which a single valued output is derived for enabling the mitigation of DDoS. In addition, FSOMDM incorporates an attack-response process that possesses the significance of dropping attack flows through its enforcement in the control plane of SDN. The performance investigation of FSOMDM confirms its significance by facilitating nearly 94% of classifier accuracy evaluated in terms of true positive rate (TPR). Performance evaluation of TCP-BIAD in high-speed, long-distance networks In this paper, the performance of Binary Increase Adaptive Decrease (TCP-BIAD) congestion control algorithm in high-speed long-distance networks is evaluated. As its name implies, this TCP variant is a combination of an enhanced binary increase algorithm during the congestion avoidance phase with the adaptive decrease mechanism of TCP Westwood after a packet loss episode. We also propose a mathematical analysis of the TCP-BIAD paradigm to study the steady-state throughput provided by TCP-BIAD and investigate the intra-protocol friendliness between TCP-BIAD and Additive Increase/Multiplicative Decrease algorithms. Our analysis shows that TCP-BIAD algorithm is exponentially stable, while maintaining an adequately fair and friendly behavior with respect to co-existing TCP-Reno flows. Finally, our results are validated with respect to other TCP variants such as BIC-TCP, CUBIC, HighSpeed TCP, HTCP, Hybla and TCP-Reno by means of computer simulations in networks with large bandwidth-delay products and low sensitivity to RTT values. Area coverage of heterogeneous wireless sensor networks in support of Internet of Things demands As the Internet of Things (IoT) evolves, more and more Wireless Sensor Networks (WSNs) are being deployed in the real world. Connected vehicles, smart grids, smart cities, smart healthcare, networks of robots, and disaster recovery networks are some examples. In WSNs, the area coverage is one of the most important quality of service metrics. A WSN without enough area coverage yields incorrect results. So calculating the covered area of a WSN is mandatory. Previous studies have used a simple approach: all nodes send their location to the sink, and it calculates the covered area centrally which makes huge unnecessary communication overhead. In our previous work titled Distributed Exact Coverage Rate Calculation, we calculated the covered area of a homogenous WSN in a distributed manner. In this paper, we provide a Heterogeneous Distributed Precise Coverage Rate (HDPCR) mechanism that calculates the covered area of a Heterogeneous Wireless Sensor Network by using a localized mechanism.
 With the use of boundary detection mechanisms, the HDPCR detects the boundary of the network and calculates its area. HDPCR also detects holes and calculates their area precisely. By subtracting these two calculated values, the covered area of the network can be computed. Many related studies have evaluated the coverage rate approximately with error and require more calculations to reduce the error rate. HDPCR calculates the coverage rate precisely without an error rate using simple arithmetic calculations. The exhaustive simulation also shows the superiority of HDPCR as compared to the previous approaches.
 Near-miss situation based visual analysis of SIEM rules for real time network security monitoring Security information and event management (SIEM) systems are generally used to monitor the network for malicious activities. These systems are capable of detecting a wide range of malicious activities in the network using built-in rules to generate alerts on malicious activities. Although SIEM systems provide comprehensive reports about each alert including relevant details such as, severity score, events, and events counts. However, a key limitation of SIEM systems is not presenting the rule’s status in real time before an alert is raised. This paper presents a novel visual tool that enables security analyst to grasp visually, and in real time a complete overview of SIEM rules execution, and alert circumstances that may happen in advance based on near-miss situation. Apart from the real time rules analysis, it also enables security analysts to explore the reasoning behind the alerts in an organized and efficient manner via security questions. The essence of the approach is to evaluate and visualize the current status of each rule execution according to pre-compiled conditions in real time. We demonstrate the utility of our approach using IBM QRadar events data to support the informative analysis of different rules in real time, and security questions based insight about the rules via story page. Optimum bandwidth allocation in wireless networks using differential evolution Wireless networking is experiencing a tremendous growth in new standards of communication and computer applications. Currently, wireless networks exist in various forms, providing different facilities. However, due to some limitations as compared with wired counterparts, wireless networks face several major challenges and one of them is optimum bandwidth allocation. The focus of optimum bandwidth allocation is to reduce the losses and satisfying quality of service (QoS) requirements. In wireless networks, the term bandwidth allocation is attributed as the distribution of bandwidth resources among different users, which affects the serviceability of the entire system. Though many studies related to bandwidth allocation have been reported already, however, only sub-optimal solutions have been provided so far. In this research, we proposed to use the differential evolution (DE) algorithm to allocate bandwidth through a bandwidth reservation scheme in the Cellular IP network, in order to improve the QoS at an acceptable level. DE belongs to a class of evolutionary algorithms (EA), like particle swarm optimization and genetic algorithm. A DE-based method is used which looks for any free bandwidth in the cell or in adjacent cells and provides it to the cell where required. In case, it fails to find the free available bandwidth then it will search the bandwidth which is standby for non real-time users and allocates it to the real-time users that will help in improving the QoS in terms of connection/call dropping probability for real-time users. Simulation results show that the proposed method performs better as compared to previously used EA models for bandwidth allocation. A methodology for ensuring fair allocation of CSOC effort for alert investigation A Cyber Security Operations Center (CSOC) often sells services by entering into a service level agreement (SLA) with various customers (organizations) whose network traffic is monitored through sensors. The sensors produce data that are processed by automated systems (such as the intrusion detection system) that issue alerts. All alerts need further investigation by human analysts. The alerts are triaged into high-, medium-, and low-priority alerts, and the high-priority alerts are investigated first by cybersecurity analysts—a process known as priority queueing. In unexpected situations such as (i) higher than expected high-priority alert generation from some sensors, (ii) not enough analysts at the CSOC in a given time interval, and (iii) a new type of alert, which increases the time to analyze alerts from some sensors, the priority queueing mechanism leads to two major issues. The issues are: (1) some sensors with normal levels of alert generation are being analyzed less than those with excessive high-priority alerts, with the potential for complete starvation of alert analysis for sensors with only medium- or low-priority alerts, and (2) the above ad hoc allocation of CSOC effort to sensors with excessive high-priority alerts over other sensors results in SLA violations, and there is no enforcement mechanism to ensure the matching between the SLA and the actual service provided by a CSOC. This paper develops a new dynamic weighted alert queueing mechanism (DWQ) which relates the CSOC effort as per SLA to the actual allocated in practice, and ensures via a technical enforcement system that the total CSOC effort is proportionally divided among customers such that fairness is guaranteed in the long run. The results indicate that the DWQ mechanism outperforms priority queueing method by not only analyzing high-priority alerts first but also ensuring fairness in CSOC effort allocated to all its customers and providing a starvation-free alert investigation process. A comprehensive survey on network anomaly detection Nowadays, there is a huge and growing concern about security in information and communication technology among the scientific community because any attack or anomaly in the network can greatly affect many domains such as national security, private data storage, social welfare, economic issues, and so on. Therefore, the anomaly detection domain is a broad research area, and many different techniques and approaches for this purpose have emerged through the years. In this study, the main objective is to review the most important aspects pertaining to anomaly detection, covering an overview of a background analysis as well as a core study on the most relevant techniques, methods, and systems within the area. Therefore, in order to ease the understanding of this survey’s structure, the anomaly detection domain was reviewed under five dimensions: (1) network traffic anomalies, (2) network data types, (3) intrusion detection systems categories, (4) detection methods and systems, and (5) open issues. The paper concludes with an open issues summary discussing presently unsolved problems, and final remarks. A Novel Model of Sybil Attack in Cluster-Based Wireless Sensor Networks and Propose a Distributed Algorithm to Defend It Today, Wireless Sensor Networks are widely employed in various applications including military, environment, medical and urban applications. Thus, security establishment in such networks is of great importance. One of the dangerous attacks against these networks is Sybil attack. In this attack, malicious node propagates multiple fake identities simultaneously which affects routing protocols and many other operations like voting, reputation evaluation, and data aggregation. In this paper, first, a novel model of Sybil attack in cluster-based sensor networks is proposed. In the proposed attack model, a malicious node uses each of its Sybil identity to join each cluster in the network. Thus, the malicious node joins many clusters of the network simultaneously. In this paper, also a distributed algorithm based on Received Signal Strength Indicator and positioning using three points to defend against the novel attack model is proposed. The proposed algorithm is implemented and its efficiency in terms of true detection rate, false detection rate, and communication overhead is evaluated through a series of experiments. Experiment results show that the proposed algorithm is able to detect 99.8% of Sybil nodes with 0.008% false detection rate (in average). Additionally, the proposed algorithm is compared with other algorithms in terms of true detection rate and false detection rate which shows that the proposed algorithm performs desirably. Internet of Things: information security challenges and solutions Keeping up with the burgeoning Internet of Things (IoT) requires staying up to date on the latest network attack trends in dynamic and complicated cyberspace, and take them into account while developing holistic information security (IS) approaches for the IoT. Due to multiple vulnerabilities in the IoT foundations, many targeted attacks are continuing to evolve. This survey of related work in the very specialized field of IS assurance for the IoT develops a taxonomy of typical attacks against IoT assets (with special attention to IoT device protection). Based on this taxonomy, the key directions for countering these attacks are defined. According to the modern demand for the IoT and big IS-related data processing, we propose applying the Security Intelligence approach. The results obtained, when compared with the related work and numerous analogues, are based on the following research methodology: view the IoT as a security object to be protected, leading to understanding its vulnerabilities and possible attacks against the IoT exploiting these vulnerabilities, and from there approaches to protecting the IoT. A few areas of the future research, among which the IoT operational resilience and usage of the blockchain technology seem to us the most interesting, are indicated. Content-aware point-of-interest recommendation based on convolutional neural network Point-of-interest (POI) recommendation has become an important approach to help people discover attractive locations. But the extreme sparsity of the user-POI matrix creates a severe challenge. To address this challenge, researchers have begun to explore the review content information for POI recommendations. Existing methods are based on bag-of-words or embedding techniques which leads to a shallow understanding of user preference. In order to capture valuable information about user preference, we propose a content-aware POI recommendation based on convolutional neural network (CPC). We utilize a convolutional neural network as the foundation of a unified POI recommendation framework and introduce the three types of content information, including POI properties, user interests and sentiment indications. The experimental results indicate that convolutional neural network is very capable of capturing semantic and sentiment information from review content and demonstrate that the relevant information in reviews can improve POI recommendation performance on location-based social networks. Targets Classification Based on Multi-sensor Data Fusion and Supervised Learning for Surveillance Application In surveillance application scenarios, like border security and area monitoring, potential targets to be detected may be either an unarmed person, a soldier carrying ferrous weapon or a vehicle. Detection is the first phase of a monitoring process, followed by the target classification phase and finally their tracking if required. This work focuses on classification step, where we introduce our classification approach not too resource-intensive, easy to implement and suitable for large scale environment. For that, we used probabilistic reasoning techniques to address multi sensing data correlation and take advantage of multi-sensor data fusion, then, based on adopted fusion architecture, we implemented our trained classification model in a fusion node, to make the classification more accurate. Speedy leader election to avoid application discontinuity in cognitive radio networks In cognitive radio networks (CRN), secondary user (SU) nodes operate in primary users’ unused spectrum bands. Thus, the link between SU nodes may be short lived due to (largely) unpredictable appearance of PU despite SU’s being capable of multiple channel access. Further, the nodes may suffer frequent disconnection due to node mobility and spectrum mobility. A network is considered reliable if SU’s have been carefully synchronized to ensure timely use of the available channel(s). Many computing applications require a leader node to carry out efficient coordination among the participant nodes. In this paper, we propose a diffusion computation based leader election protocol for CRN. We apply a handover mechanism for control transfer. Our handover mechanism can avoid the premature termination of some applications and thus enhances system throughput. The objective is to find maximum Id node as leader in a connected component. In extent, we validate our algorithm using simulation results and include illustration for correctness proof. Optimum Temporal Coverage with Rotating Directional Sensors Advances in directional sensors technology and impressive development of wireless sensor networks, created a new class of wireless sensor networks called directional sensor networks. According to the nature of directional nodes, the coverage problem in directional sensor networks is substantial. The coverage measurement in the directional sensor network can be positional or temporal. In temporal coverage, directional sensors periodically repeat rotating around themselves. Therefore in each period of time, targets that exist in the radius of sensor nodes are covered in the interval of time. In this model, when a target has not been covered by sensors in any interval of time, it is said that the target has remained in dark. Temporal coverage model is defined by minimizing dark time for all targets. This paper presents two solutions for solving the temporal coverage problem. The first solution formulates the problem of temporal coverage as an integer linear programming (ILP) optimization problem. By using this method, the optimal solution can be achieved for temporal coverage problem. Due to NP-Hardness of temporal coverage problem and since ILP is a centralized method, we develop a heuristics solution, namely distributed initial orientation algorithm (DIOA). This algorithm uses local information and tries to be near-optimal. Simulation results show that in ILP, we have up to 14.19% reduction on average sum of dark time and in DIOA we have up to 6.74%. Additionally, the number of perfect temporal coverage (0-dark time) in ILP method improves up to 69.29% and in DIOA we have up to 25.23% improvements compared to related algorithms. Using Information Centric Networking in Internet of Things: A Survey Internet of Things (IoT) is increasingly deployed in different domains and environments including smart homes, smart cities, healthcare, industry 4.0, and smart agriculture, by connecting a large number of physical objects to deliver a new class of applications. The rising number of these connected objects and their heterogeneity have raised new research directions and challenges regarding their communications, scalability and the large amount of data that generate. As a result, new communication technologies have been proposed to be applied in these environments and applications, mainly to consider their main inherent properties which are the information that generate and handle, and the content that disseminate. Among the adopted techniques and recently integrated into the IoT is the Information Centric Networking (ICN) paradigm. The choice of integration of ICN in the context of IoT is mainly motivated by all the advantages it represents, in particular content caching and decoupling senders and receivers. In this paper, we provide a detailed analysis of the motivations behind using ICN in IoT environments and a survey of existing research work that have already applied ICN as a communication support for IoT applications. The Queue Geo/G/1/N + 1 Revisited This paper presents an alternative steady-state solution to the discrete-time Geo/G/1/N + 1 queueing system using roots. The analysis has been carried out for a late-arrival system using the imbedded Markov chain method, and the solutions for the early arrival system have been obtained from those of the late-arrival system. Using roots of the associated characteristic equation, the distributions of the numbers in the system at various epochs are determined. We find a unified approach for solving both finite- and infinite- buffer systems. We investigate the measures of effectiveness and provide numerical illustrations. We establish that, in the limiting case, the results thus obtained converge to the results of the continuous-time counterparts. The applications of discrete-time queues in modeling slotted digital computer and communication systems make the contributions of this paper relevant. Network adapter architectures in network on chip: comprehensive literature review Network on Chip (NoC) is a new distributed, scalable, packet switched-based on chip which has been suggested as perfect solution for traditional centralized, non-scalable bus-based systems on chip (SoC) to handle issues like out-of order transactions, higher latencies, and end-to-end flow control. The NoC provides parallel and multi-core processing platform and is constructed from a set of Routers (R), Links (L), Intellectual Property (IP) cores, and Network Adapters (NA). The NA as individual hardware entity makes it possible IP cores with different data width and frequency connected to NoC. In other words, by decoupling computation from communication the NA allows IP Core modules and interconnects to be designed independently from each other. The design of NA impacts directly on NoC based SoCs critical parameters such as power dissipation, latency, throughput, and silicon area. This paper presents the comprehensive review of state-of-the-art architectures and the developments of NA which have been proposed in literature. Moreover, three type of parameters namely design (design goal, building components, Quality of Service (QoS), Core Interface Protocol (CIP), Security consideration, and Design for Test (DfT)), performance (power dissipation, latency, area, and throughput), and evaluation parameters (evaluation platform, clock frequency, technology scale) which have impact on NA architectures are evaluated and highlighted in comparative tables and figures. Furthermore, all the concepts that are considered in the design of NA is classified. Finally, concluding remarks and future research direction are provided. Least Mobility High Power (LMHP) Dynamic Routing for QoS Development in Manet The problem of routing in mobile adhoc network has been approached in different methods. However, they suffer to achieve the required performance in quality of service. The mobile nodes spent most of the energy on routing because of cooperative transmission. To improve the performance of mobile adhoc network, an efficient LMHP routing algorithm is proposed in this paper. The source node discovers the route by sending LMHP route discovery (LMHP-RD) message to all its neighbors, identified in the neighbor discovery phase. The neighbors reply the LMHP-route request (RREQ) packet to the source node which contains power and displacement information about the intermediate nodes. The source node collects the information about the routes available along with power and displacement details. Using the identified information, the source node computes the transmission completeness weight for each route. Based on computed transmission completeness weight, the method selects a single route with maximum weight to perform data transmission. This method improves the throughput performance and increases the lifetime of the network. The proposed system is developed and simulated in NS2 and the performance has been analyzed based on three metrics Throughput, pocket delivery ratio and latency ratio. The simulated results show that the power consumption is relatively low in the proposed method, comparing the available techniques. Hybrid gradient descent cuckoo search (HGDCS) algorithm for resource scheduling in IaaS cloud computing environment Resource scheduling is a procedure for the distribution of resources over time to perform a required task and a decision making process in cloud computing. Optimal resource scheduling is a great challenge and considered to be an NP-hard problem due to the fluctuating demand of cloud users and dynamic nature of resources. In this paper, we formulate a new hybrid gradient descent cuckoo search (HGDCS) algorithm based on gradient descent (GD) approach and cuckoo search (CS) algorithm for optimizing and resolving the problems related to resource scheduling in Infrastructure as a Service (IaaS) cloud computing. This work compares the makespan, throughput, load balancing and performance improvement rate of existing meta-heuristic algorithms with proposed HGDCS algorithm applicable for cloud computing. In comparison with existing meta-heuristic algorithms, proposed HGDCS algorithm performs well for almost in both cases (Case-I and Case-II) with all selected datasets and workload archives. HGDCS algorithm is comparatively and statistically more effective than ACO, ABC, GA, LCA, PSO, SA and original CS algorithms in term of problem solving ability in accordance with results obtained from simulation and statistical analysis. Modeling and improving the throughput of vehicular networks using cache enabled RSUs Newly emerged applications in vehicular networks demand high throughput to transfer large amount of data through both Vehicle-to-Vehicle and Vehicle-to-Infrastructure links. One solution which recently draws researchers attention to itself for improving the throughput in this type of network is to deploy some Road-Side-Units (RSUs) in the streets with storage capability and store the data closer to the end users. Consequently, vehicles are able to download their inquired contents from these local RSUs instead of the base station. This will decrease the network traffic of the base station and also the average delay each vehicle has to wait to receive his requested files. The main issue to implement this distributed approach in this type of environment compared to other types of networks is that the fast moving vehicles make the topology of the network highly dynamic. Also due to limited storage capacity of the caches in the RSUs, we should decide on how to distribute the contents in the RSUs to maximize the number of locally satisfied vehicles. In this paper, we address the cache content placement problem in vehicular networks and model it using a game theoretic approach. We show that the proposed game model is a special case of generalized covering games. Considering the hit ratio of the caches as the performance metric in our model, we propose a method to distributively optimize this metric using the RSU’s local information. In addition, we propose a combinatorial approach to find efficient file placements in the RSUs using Markov approximation. Empirical evaluations on realistic trace-based simulations show an improvement of 7.5% in the average hit ratio of the proposed method compared to other well-known cache content placement approaches. Newly emerged applications in vehicular networks demand high throughput to transfer large amount of data through both Vehicle-to-Vehicle and Vehicle-to-Infrastructure links. To improve the network throughput, we deploy some Road-Side-Units (RSUs) in the streets with storage capability and store the data closer to the end users. Consequently, vehicles are able to download their inquired contents from these local RSUs instead of the base station. The main issue to implement this distributed approach is that the fast moving vehicles make the topology of the network highly dynamic. Also due to limited storage capacity of the caches in the RSUs, we should decide on how to distribute the contents in the RSUs to maximize the number of locally satisfied vehicles. In this paper, we address the cache content placement problem in vehicular networks and model it using game theoretic approach and Combinatorial approach. We show that the proposed game model is a special case of generalized covering games. Considering the hit ratio of the caches as the performance metric in our model, we propose a method to distributively optimize this metric using the RSU’s local information. In addition, we propose a Combinatorial approach to find efficient file placements in the RSUs using Markov approximation. Empirical evaluations on realistic trace-based simulations show an improvement of 7.5% in the average hit ratio of the proposed method compared to other well-known cache content placement approaches. End-user traffic policing for QoS assurance in polyservice RINA networks Looking at the ever-increasing amount of heterogeneous distributed applications supported on current data transport networks, it seems evident that best-effort packet delivery falls short to supply their actual needs. Multiple approaches to Quality of Service (QoS) differentiation have been proposed over the years, but their usage has always been hindered by the rigidness of the TCP/IP-based Internet model, which does not even allow for applications to express their QoS needs to the underlying network. In this context, the Recursive InterNetwork Architecture (RINA) has appeared as a clean-slate network architecture aiming to replace the current Internet based on TCP/IP. RINA provides a well-defined QoS support across layers, with standard means for layers to inform of the different QoS guarantees that they can support. Besides, applications and other processes can express their flow requirements, including different QoS-related measures, like delay and jitter, drop probability or average traffic usage. Greedy end-users, however, tend to request the highest quality for their flows, forcing providers to apply intelligent data rate limitation procedures at the edge of their networks. In this work, we propose a new rate limiting policy that, instead of enforcing limits on a per QoS class basis, imposes limits on several independent QoS dimensions. This offers a flexible traffic control to RINA network providers, while enabling end-users freely managing their leased resources. The performance of the proposed policy is assessed in an experimental RINA network test-bed and its performance compared against other policies, either RINA-specific or adopted from TCP/IP. Results show that the proposed policy achieves an effective traffic control for high QoS traffic classes, while also letting lower QoS classes to take profit of the capacity initially reserved for the former ones when available. Round robin, distributed and centralized relay selection for cognitive radio networks in the presence of Nakagami fading channels In this paper, we investigate the performance of different relay selection techniques for Cognitive Radio Networks (CRN). The network contains a primary transmitter $$P_T$$PT, a primary receiver ($$P_R$$PR), a secondary source and two secondary destinations. In the first transmission phase, the secondary source transmits a signal to the two secondary destinations only when it generate interference to $$P_R$$PR less than $$\beta $$β. In the secondary phase, one destination acts as relay and help the other destination. The generated interference by the chosen relay should be less than a prefixed threshold $$\beta $$β. If the two destinations generate a lot of interference, there is no cooperation. If a single destination generate interference less than $$\beta $$β, this node acts as relay. If the two destinations generate low interference, we use centralized (CRS), distributed (DRS) or round robin relay selection (RRRS). Centralized Relay Selection (CRS) chooses the relay having the highest end-to-end Signal to Noise Ratio (SNR). In DRS, a relay is chosen if its SNR is greater than threshold T. The value of T is optimized to have the best performance. RRRS activates both nodes with the same probability i.e. 0.5 without using the value of SNR. Most of previous studies dealt with best relay selection for CRN. Our main contribution is to suggest DRS for CRN and to optimize threshold T. We also derive the Bit Error Probability (BEP) of DRS, CRS and RRRS. Framework of an Intelligent, Multi Nodal and Secured RF Based Wireless Home Automation System for Multifunctional Devices The impact of home automation on domestic lifestyles is incredible as it was before on industry and its benefits will be accessible to all sectors of society. With the help of home automation, it is possible to control dozens of domestic equipment and appliances will include security, heating, lighting, cooking, washing appliances, energy management, audio and video systems as well as a number of new appliances such as health monitoring, home publishing. This paper presents a design and prototype implementation of new home automation system that can be controlled by radio frequency (RF) and can be able to communicate with any household appliance as well as robot in the range between of 10 and 15 m. Frequency of 433 MHz is used to communicate with transmitter and receiver to run all type of applications both in ac and dc. We are facing some challenges in section A and to overcome those challenges, we also proposed an intelligent, multi nodal and secured home automation system described in section B and show the comparison between RF based wireless home automation and intelligent multi nodal secured home automation. A study on novel filtering and relationship between input-features and target-vectors in a deep learning model for stock price prediction From past to present, the prediction of stock price in stock market has been a knotty problem. Many researchers have made various attempts and studies to predict stock prices. The prediction of stock price in stock market has been of concern to researchers in many disciplines, including economics, mathematics, physics, and computer science. This study intends to learn fluctuation of stock prices in stock market by using recently spotlighted techniques of deep learning to predict future stock price. In previous studies, we have used price-based input-features to measure performance changes in deep learning models. Results of this studies have revealed that the performance of stock price models would change according to varied input-features configured based on stock price. Therefore, we have concluded that more novel input-feature in deep learning model is needed to predict patterns of stock price fluctuation more precisely. In this paper, for predicting stock price fluctuation, we design deep learning model using 715 novel input-features configured on the basis of technical analyses. The performance of the prediction model was then compared to another model that employed simple price-based input-features. Also, rather than taking randomly collected set of stocks, stocks of a similar pattern of price fluctuation were filtered to identify the influence of filtering technique on the deep learning model. Finally, we compared and analyzed the performances of several models using different configuration of input-features and target-vectors. SMEER: Secure Multi-tier Energy Efficient Routing Protocol for Hierarchical Wireless Sensor Networks Energy consumption and the secure transmission are the increasing fields of research challenge in wireless sensor network (WSN) applications. Heterogeneous WSN is an efficient network strategy that has sensor nodes with different processing, memory power, and transmission capacity. In order to provide effective transmission for this type of network, clustering associated with secure routing is enabled to transfer the data packets safely to the endpoint. Data gathering and clustering help to group the network and control transmission overhead during data transmission. Hybridization of K-means clustering algorithm with Ant Lion Optimizer for grouping of nodes and optimal CH selection is utilized for better energy efficiency. Thus, a Miscegenation of Ant Lion optimizer within K-means for clustering and Spherical grid based multi-curve Elliptic curve cryptographic routing (MALOKSER) is determined for effective clustering and secure routing of data packets within time to the base station. The main aim of our work is to enhance network security and energy savage in the wireless network communication system. Elliptic curve cryptography with spherical grid multi-tier routing ensure secure transmission by encrypting the messages with two different keys and forward the packets in a spherical format. The performance is evaluated under metrics such as packet deliver ratio, minimum energy consumptions, communication overheads, throughput and end to end delay with the existing standards shows better results. This proves the proposed technique can actively reduce the energy utilization with an efficient and safe routing of data over the network. Robust connectivity maintenance for fallible robots Multi-robot systems are promising tools for many hazardous real-world problems. In particular, the practical application of swarm robotics was identified as one of the grand challenges of the next decade. As swarms enter the real world, they have to deal with the inevitable problems of hardware, software, and communication failure, especially for long-term deployments. Communication is a key element for effective collaboration, and the ability of robots to communicate is expressed by the swarm’s connectivity. In this paper, we analyze a set of techniques to assess, control, and enforce connectivity in the context of fallible robots. Past research has addressed the issue of connectivity but, for the most part, without making system reliability a constitutional part of the model. We introduce a controller for connectivity maintenance in the presence of faults and discuss the optimization of its parameters and performance. We validate our approach in simulation and via physical robot experiments. Distributed self optimization techniques for heterogeneous network environments using active antenna tilt systems Active antenna systems in 4G and upcoming 5G networks offer the ability to electronically steer an antenna beam in any desired direction. This unique feature makes them a suitable candidate for realizing self organizing network (SON) architectures in 5G for optimizing of key performance indicators like throughput, file transfer time etc. In this paper, we aim to analyse the effect of increasing number of input variables and complexity of learning techniques on the performance of the network. We compare performance of simple stochastic cellular learning automata (SCLA) technique with only one input to comparatively complex Q-learning technique with two or more inputs. We use FTP flow based 5G network simulator for our work. The SON architecture model proposed, is distributed with optional inter cell communication. Simulation results reveal that increasing complexity of learning process does not necessarily benefit the system performance. The simple SCLA technique shows more robust performance compared to Q-learning case. However, within the same technique increasing the number of input variables does benefit the system, indicating that a complex technique can ultimately prove beneficial in complicated scenarios provided it is able to quickly process and adapt to the environment. Q-FRPML: QoS-Centric Fault-Resilient Routing Protocol for Mobile-WSN Based Low Power Lossy Networks Considering the significance of mobile-Wireless Sensor Networks (WSNs) under Low Power Lossy Network (LLN) Conditions, in this paper a highly robust and QoS-Centric Fault-Resilient Routing Protocol for Mobile-WSN in LLN (Q-FRPML) has been proposed. Unlike classical routing approaches such as Routing Protocol for 6LowPAN based LLNs (RPL), our proposed Q-FRPML protocol contributes multiple novelties including received signal strength indicator (RSSI) based mobile node positioning for fault-resilient communication, proactive node management, RSSI and ETX objective functions based best parent node selection, link layer adaptive fault-resilient alternate path formation for QoS centric communication over mobile-WSNs. Q-FRPML protocol is implemented in parallel to the link layer of the classical RPL IEEE 802.15.4 protocol stack that once detecting any link-outage executes best parent node selection and alternate path formation to assure reliable data delivery. In this process, Q-FRPML avoids continuous network discovery that significantly reduces signaling overheads and energy consumption. Contiki-Cooja based simulation results have revealed that the proposed Q-FRPML protocol outperforms state-of-art native RPL or S-RPL protocol in terms of higher packet delivery ratio, lower packet loss ratio and end-to-end delay under varying network or load conditions. Though, Q-FRPML protocol has been applied in parallel to the native RPL, it preserves backward compatibility and hence can be applied in real-time mobile-WSN based QoS centric communication purposes.